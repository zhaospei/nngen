start_play_tune ( GstSidDec * siddec ) <nl>  <nl> gst_segment_init (& segment , GST_FORMAT_TIME ); <nl> gst_pad_push_event ( siddec -> srcpad , gst_event_new_segment (& segment )); <nl> + siddec -> total_bytes = 0 ; <nl>  <nl> res = gst_pad_start_task ( siddec -> srcpad , <nl> ( GstTaskFunction ) play_loop , siddec -> srcpad , NULL );
gst_mpeg2dec_handle_frame ( GstVideoDecoder * decoder , <nl> gst_buffer_ref ( buf ); <nl> if (! gst_buffer_map ( buf , & minfo , GST_MAP_READ )) { <nl> GST_ERROR_OBJECT ( mpeg2dec , " Failed to map input buffer "); <nl> + gst_buffer_unref ( buf ); <nl> return GST_FLOW_ERROR ; <nl> } <nl> 
do_ldmtool_diskgroup_volumes ( const char * diskgroup ) <nl> reply_with_error ("% s ", err ); <nl> return NULL ; <nl> } <nl> - free ( err ); <nl>  <nl> return parse_json_get_object_string_list ( out , " volumes ", <nl> __func__ , " ldmtool show diskgroup ");
submit_counters ( struct thread_data * t , struct core_data * c , struct pkg_data * p ) <nl>  <nl> /* SMI */ <nl> if ( do_smi ) <nl> - turbostat_submit ( name , " current ", NULL , t -> smi_count ); <nl> + turbostat_submit ( name , " count ", NULL , t -> smi_count ); <nl>  <nl> /* submit per - core data only for 1st thread in core */ <nl> if (!( t -> flags & CPU_IS_FIRST_THREAD_IN_CORE ))
static int wh_write_command ( const data_set_t * ds , const value_list_t * vl , /* {{ <nl> } <nl> assert ( command_len < cb -> send_buffer_free ); <nl>  <nl> + /* Make scan - build happy . */ <nl> + assert ( cb -> send_buffer != NULL ); <nl> + <nl> /* ` command_len + 1 ' because ` command_len ' does not include the <nl> * trailing null byte . Neither does ` send_buffer_fill '. */ <nl> memcpy ( cb -> send_buffer + cb -> send_buffer_fill ,
static int rrd_shutdown ( void ) <nl> rrd_cache_flush (- 1 ); <nl> pthread_mutex_unlock (& cache_lock ); <nl>  <nl> + /* Wait for all the values to be written to disk before returning . */ <nl> + if ( queue_thread != 0 ) <nl> + { <nl> + pthread_join ( queue_thread , NULL ); <nl> + queue_thread = 0 ; <nl> + DEBUG (" rrdtool plugin : queue_thread exited ."); <nl> + } <nl> + <nl> pthread_mutex_lock (& queue_lock ); <nl> do_shutdown = 1 ; <nl> pthread_cond_signal (& queue_cond );
errcode_t profile_open_file ( const_profile_filespec_t filespec , <nl> } <nl> if ( data ) { <nl> data -> refcount ++; <nl> + data -> last_stat = 0 ; /* Make sure to stat when updating . */ <nl> k5_mutex_unlock (& g_shared_trees_mutex ); <nl> retval = profile_update_file_data ( data , NULL ); <nl> free ( expanded_filename );
krb5_get_realm_domain ( realm , domain ) <nl> krb5_xfree ( realmlist [ 0 ]); <nl> krb5_xfree ( realmlist ); <nl> } <nl> - * domain = NULL ; <nl> + if (( retdomain = malloc ( strlen ( realm ) + 2 )) == NULL ) <nl> + return ENOMEM ; <nl> + strcpy ( retdomain , "."); <nl> + strcat ( retdomain , realm ); /* return the realm as the domain <nl> + if lookup fails */ <nl> + * domain = retdomain ; <nl> return 0 ; <nl> } <nl> continue ;
void RandomBytesCheck ( RandomBytesRequest * req , Local < Value > argv [ 2 ]) { <nl> Buffer * buffer = Buffer :: New ( req -> data_ , req -> size_ , RandomBytesFree , NULL ); <nl> argv [ 0 ] = Local < Value >:: New ( Null ()); <nl> argv [ 1 ] = Local < Object >:: New ( buffer -> handle_ ); <nl> + req -> data_ = NULL ; <nl> } <nl> + free ( req -> data_ ); <nl> } <nl>  <nl> 
const char * cl_strerror ( int clerror ) <nl> return " Null argument passed while initialized is required "; <nl> case CL_EIO : <nl> return " Input / Output error "; <nl> + case CL_EFORMAT : <nl> + return " Bad format or broken data "; <nl> default : <nl> return " Unknown error code "; <nl> }
static xmlNode * inject_node_state ( cib_t * cib_conn , char * node ) <nl> rc = cib_conn -> cmds -> query ( cib_conn , xpath , & cib_object , cib_xpath | cib_sync_call | cib_scope_local ); <nl> } <nl>  <nl> + crm_free ( xpath ); <nl> CRM_ASSERT ( rc == cib_ok ); <nl> return cib_object ; <nl> }
get_rsc_restart_list ( lrm_rsc_t * rsc , lrm_op_t * op ) <nl> } <nl>  <nl> metadata = string2xml ( metadata_str ); <nl> + if ( metadata == NULL ) { <nl> + crm_err (" Metadata for % s ::% s :% s is not valid XML ", <nl> + rsc -> provider , rsc -> class , rsc -> type ); <nl> + return NULL ; <nl> + } <nl> + <nl> actions = find_xml_node ( metadata , " actions ", TRUE ); <nl>  <nl> xml_child_iter_filter (
common_apply_stickiness ( resource_t * rsc , node_t * node , pe_working_set_t * data_se <nl> value = g_hash_table_lookup ( node -> details -> attrs , fail_attr ); <nl> if ( value != NULL ) { <nl> crm_debug ("% s : % s ", fail_attr , value ); <nl> - fail_count = crm_parse_int ( value , " 0 "); <nl> + fail_count = char2score ( value ); <nl> } <nl> crm_free ( fail_attr ); <nl> 
bool ParseHDKeypath ( std :: string keypath_str , std :: vector < uint32_t >& keypath ) <nl> return false ; <nl> } <nl> uint32_t number ; <nl> - ParseUInt32 ( item , & number ); <nl> + if (! ParseUInt32 ( item , & number )) { <nl> + return false ; <nl> + } <nl> path |= number ; <nl>  <nl> keypath . push_back ( path );
static int valid_entry_name ( const char * filename ) <nl> (* filename != '.' || <nl> ( strcmp ( filename , ".") != 0 && <nl> strcmp ( filename , "..") != 0 && <nl> - strcmp ( filename , DOT_GIT ) != 0 )); <nl> + strcasecmp ( filename , DOT_GIT ) != 0 )); <nl> } <nl>  <nl> static int entry_sort_cmp ( const void * a , const void * b )
cmsPipeline * DefaultICCintents ( cmsContext ContextID , <nl> // Concatenate to the output LUT <nl> if (! cmsPipelineCat ( Result , Lut )) <nl> goto Error ; <nl> + <nl> cmsPipelineFree ( Lut ); <nl> + Lut = NULL ; <nl>  <nl> // Update current space <nl> CurrentColorSpace = ColorSpaceOut ; <nl> cmsPipeline * DefaultICCintents ( cmsContext ContextID , <nl>  <nl> Error : <nl>  <nl> - cmsPipelineFree ( Lut ); <nl> + if ( Lut != NULL ) cmsPipelineFree ( Lut ); <nl> if ( Result != NULL ) cmsPipelineFree ( Result ); <nl> return NULL ; <nl> 
static void lookup_hostname ( struct hostinfo * hi ) <nl> char ** ap ; <nl> static char addrbuf [ HOST_NAME_MAX + 1 ]; <nl>  <nl> - hent = gethostbyname ( hostname . buf ); <nl> + hent = gethostbyname ( hi -> hostname . buf ); <nl> if ( hent ) { <nl> ap = hent -> h_addr_list ; <nl> memset (& sa , 0 , sizeof sa );
static void find_deltas ( struct object_entry ** list , unsigned * list_size , <nl> * depth , leaving it in the window is pointless . we <nl> * should evict it first . <nl> */ <nl> - if ( entry -> delta && depth <= n -> depth ) <nl> + if ( entry -> delta && max_depth <= n -> depth ) <nl> continue ; <nl>  <nl> /*
static void show_line ( struct grep_opt * opt , char * bol , char * eol , <nl>  <nl> * eol = '\ 0 '; <nl> while ( next_match ( opt , bol , eol , ctx , & match , eflags )) { <nl> + if ( match . rm_so == match . rm_eo ) <nl> + break ; <nl> printf ("%.* s % s %.* s % s ", <nl> ( int ) match . rm_so , bol , <nl> opt -> color_match ,
int send_pack ( struct send_pack_args * args , <nl> ref -> status = REF_STATUS_NONE ; <nl> if ( args -> stateless_rpc ) <nl> close ( out ); <nl> + if ( git_connection_is_socket ( conn )) <nl> + shutdown ( fd [ 0 ], SHUT_WR ); <nl> if ( use_sideband ) <nl> finish_async (& demux ); <nl> return - 1 ;
static int cmd_log ( int argc , const char ** argv , char ** envp ) <nl> prepare_revision_walk (& rev ); <nl> setup_pager (); <nl> while (( commit = get_revision (& rev )) != NULL ) { <nl> - if ( commit_format != CMIT_FMT_ONELINE && shown ) <nl> + if ( shown && do_diff && commit_format != CMIT_FMT_ONELINE ) <nl> putchar ('\ n '); <nl> fputs ( commit_prefix , stdout ); <nl> if ( abbrev_commit && abbrev )
int main ( int argc , const char ** argv ) <nl> else <nl> revs . header_prefix = " commit "; <nl> } <nl> + else if ( revs . verbose_header ) <nl> + /* Only -- header was specified */ <nl> + revs . commit_format = CMIT_FMT_RAW ; <nl>  <nl> list = revs . commits ; <nl> 
void verify_non_filename ( const char * prefix , const char * arg ) <nl> if (! lstat ( name , & st )) <nl> die (" ambiguous argument '% s ': both revision and filename \ n " <nl> " Use '--' to separate filenames from revisions ", arg ); <nl> - if ( errno != ENOENT ) <nl> + if ( errno != ENOENT && errno != ENOTDIR ) <nl> die ("'% s ': % s ", arg , strerror ( errno )); <nl> } <nl> 
static void print_summary ( const char * prefix , const unsigned char * sha1 ) <nl> rev . show_root_diff = 1 ; <nl> rev . commit_format = get_commit_format (" format :% h : % s "); <nl> rev . always_show_header = 0 ; <nl> + diff_setup_done (& rev . diffopt ); <nl>  <nl> printf (" Created % scommit ", initial_commit ? " initial " : ""); <nl> 
void master_service_deinit ( struct master_service ** _service ) <nl> lib_signals_deinit (); <nl> io_loop_destroy (& service -> ioloop ); <nl>  <nl> + if ( service -> listener_names != NULL ) <nl> + p_strsplit_free ( default_pool , service -> listener_names ); <nl> i_free ( service -> listeners ); <nl> i_free ( service -> getopt_str ); <nl> i_free ( service -> name );
static bool server_connection_input_one ( struct server_connection * conn ) <nl> return FALSE ; <nl>  <nl> /* check logs */ <nl> - ( void ) server_connection_print_log ( conn ); <nl> + if ( conn -> log_input != NULL ) <nl> + ( void ) server_connection_print_log ( conn ); <nl>  <nl> switch ( conn -> state ) { <nl> case SERVER_REPLY_STATE_DONE :
static int raw_sync ( struct raw_mailbox * mbox ) <nl> MAIL_INDEX_SYNC_FLAG_FLUSH_DIRTY | <nl> MAIL_INDEX_SYNC_FLAG_REQUIRE_CHANGES ; <nl>  <nl> + if ( mail_index_view_get_messages_count ( mbox -> box . view ) > 0 ) { <nl> + /* already - synced index was opened via <nl> + mail - index - alloc - cache . */ <nl> + return 0 ; <nl> + } <nl> + <nl> ret = mail_index_sync_begin ( mbox -> box . index , & index_sync_ctx , <nl> & sync_view , & trans , sync_flags ); <nl> if ( ret <= 0 ) {
static bool outofmem = FALSE ; <nl>  <nl> static union { <nl> struct stack_block block ; <nl> - unsigned char data [ 128 ]; <nl> + unsigned char data [ 512 ]; <nl> } outofmem_area ; <nl>  <nl> static void data_stack_last_buffer_reset ( bool preserve_data ATTR_UNUSED ) <nl> static void free_blocks ( struct stack_block * block ) <nl> unused_block = block ; <nl> } else { <nl> # ifndef USE_GC <nl> - free ( block ); <nl> + if ( block != & outofmem_area . block ) <nl> + free ( block ); <nl> # endif <nl> } <nl> 
int rfc822_parse_phrase ( struct rfc822_parser_context * ctx , string_t * str ) <nl> obs - phrase = word *( word / "." / CFWS ) <nl> */ <nl>  <nl> + if ( ctx -> data == ctx -> end ) <nl> + return 0 ; <nl> if (* ctx -> data == '.') <nl> return - 1 ; <nl> 
cmd_append_handle_args ( struct client_command_context * cmd , <nl> /* invalid keywords - delay failure */ <nl> client_send_box_error ( cmd , ctx -> box ); <nl> ctx -> failed = TRUE ; <nl> + keywords = NULL ; <nl> } <nl> } <nl> 
void sdbox_update_header ( struct sdbox_mailbox * mbox , <nl> mail_index_update_header_ext ( trans , mbox -> hdr_ext_id , 0 , <nl> & new_hdr , sizeof ( new_hdr )); <nl> } <nl> + memcpy ( mbox -> mailbox_guid , new_hdr . mailbox_guid , <nl> + sizeof ( mbox -> mailbox_guid )); <nl> } <nl>  <nl> static int sdbox_mailbox_create_indexes ( struct mailbox * box ,
imapc_command_begin ( imapc_command_callback_t * callback , void * context ) <nl> struct imapc_command * cmd ; <nl> pool_t pool ; <nl>  <nl> + i_assert ( callback != NULL ); <nl> + <nl> pool = pool_alloconly_create (" imapc command ", 2048 ); <nl> cmd = p_new ( pool , struct imapc_command , 1 ); <nl> cmd -> pool = pool ;
void program_client_program_input ( struct program_client * pclient ) <nl> } <nl> if ( program_client_input_pending ( pclient )) <nl> return ; <nl> - if (! input -> eof ) { <nl> + if ( pclient -> program_input != NULL && ! input -> eof ) { <nl> program_client_fail ( pclient , <nl> PROGRAM_CLIENT_ERROR_IO ); <nl> return ;
static void hook_build_update ( struct hook_build_context * ctx , void * _vlast ) <nl> void (** vlast )() = _vlast ; <nl> struct hook_stack * stack ; <nl>  <nl> + if ( ctx -> tail -> vfuncs == vlast ) { <nl> + /* no vfuncs overridden */ <nl> + return ; <nl> + } <nl> + <nl> /* ctx -> vfuncs_stack -> vfuncs points to the root vfuncs , <nl> ctx -> vfuncs_stack -> next -> vfuncs points to the first super function <nl> that is being called , and so on .
void auth_client_request_abort ( struct auth_client_request ** _request ) <nl>  <nl> auth_client_send_cancel ( request -> conn -> client , request -> id ); <nl> call_callback ( request , AUTH_REQUEST_STATUS_ABORT , NULL , NULL ); <nl> + pool_unref (& request -> pool ); <nl> } <nl>  <nl> unsigned int auth_client_request_get_id ( struct auth_client_request * request )
uint64_t mail_index_transaction_get_highest_modseq ( struct mail_index_transaction <nl> new_highest_modseq ++; <nl> } <nl> if ( array_is_created (& t -> updates ) && <nl> - transaction_flag_updates_have_non_internal ( t ) > 0 ) <nl> + transaction_flag_updates_have_non_internal ( t )) <nl> new_highest_modseq ++; <nl> if ( array_is_created (& t -> keyword_updates )) { <nl> new_highest_modseq +=
int mountpoint_get ( const char * path , pool_t pool , struct mountpoint * point_r ) <nl> if ( device_path == NULL ) <nl> return 0 ; <nl>  <nl> + memset ( point_r , 0 , sizeof (* point_r )); <nl> point_r -> device_path = p_strdup ( pool , device_path ); <nl> point_r -> mount_path = p_strdup ( pool , mount_path ); <nl> point_r -> type = p_strdup ( pool , type );
static void <nl> read_ident_reply ( rb_fde_t * F , void * data ) <nl> { <nl> struct auth_client * auth = data ; <nl> - char buf [ IDENT_BUFSIZE + 1 ]; /* buffer to read auth reply into */ <nl> + char buf [ IDENT_BUFSIZE + 1 ] = { 0 }; /* buffer to read auth reply into */ <nl> ident_message message = REPORT_FAIL ; <nl> char * s = NULL ; <nl> char * t = NULL ;
int cert_stuff ( struct connectdata * conn , <nl> EVP_PKEY_free ( pktmp ); <nl> } <nl>  <nl> -# if ! defined ( OPENSSL_NO_RSA ) <nl> +# if ! defined ( OPENSSL_NO_RSA ) && ! defined ( OPENSSL_IS_BORINGSSL ) <nl> { <nl> /* If RSA is used , don ' t check the private key if its flags indicate <nl> * it doesn ' t support it . */
static CURLcode smb_connect ( struct connectdata * conn , bool * done ) <nl>  <nl> ( void ) done ; <nl>  <nl> + /* Check we have a username and password to authenticate with */ <nl> + if (! conn -> bits . user_passwd ) <nl> + return CURLE_LOGIN_DENIED ; <nl> + <nl> /* Initialize the connection state */ <nl> memset ( smbc , 0 , sizeof (* smbc )); <nl> smbc -> state = SMB_CONNECTING ;
static void read_tcp_data ( ares_channel channel , fd_set * read_fds , time_t now ) <nl> * what ' s left to read of it ). <nl> */ <nl> count = recv ( server -> tcp_socket , <nl> - ( void *)( server -> tcp_lenbuf + server -> tcp_buffer_pos ), <nl> - 2 - server -> tcp_buffer_pos , 0 ); <nl> + ( void *)( server -> tcp_lenbuf + server -> tcp_lenbuf_pos ), <nl> + 2 - server -> tcp_lenbuf_pos , 0 ); <nl> if ( count <= 0 ) <nl> { <nl> handle_error ( channel , i , now );
void Curl_sasl_digest_cleanup ( struct digestdata * digest ) <nl> * This is used to generate an already encoded NTLM type - 1 message ready for <nl> * sending to the recipient . <nl> * <nl> -* Note : This is a simple wrapper of the NTLM function which means that any <nl> -* SASL based protocols don ' t have to include the NTLM functions directly . <nl> -* <nl> * Parameters : <nl> * <nl> * userp [ in ] - The user name in the format User or Domain \ User .
static CURLcode ssh_statemach_act ( struct connectdata * conn , bool * block ) <nl> figure out a " real " bitmask */ <nl> sshc -> orig_waitfor = data -> req . keepon ; <nl>  <nl> + /* since we don ' t really wait for anything at this point , we want the <nl> + state machine to move on as soon as possible so we set a very short <nl> + timeout here */ <nl> + Curl_expire ( data , 1 ); <nl> + <nl> state ( conn , SSH_STOP ); <nl> } <nl> break ;
static CURLcode imap_disconnect ( struct connectdata * conn ) <nl>  <nl> Curl_pp_disconnect (& imapc -> pp ); <nl>  <nl> + free ( imapc -> mailbox ); <nl> + <nl> return CURLE_OK ; <nl> } <nl> 
CURLcode http_auth_headers ( struct connectdata * conn , <nl> if (! data -> state . authstage ) { <nl> if ( conn -> bits . httpproxy && conn -> bits . proxy_user_passwd ) <nl> Curl_http_auth_stage ( data , 407 ); <nl> - else <nl> + else if ( conn -> bits . user_passwd ) <nl> Curl_http_auth_stage ( data , 401 ); <nl> + else <nl> + return CURLE_OK ; /* no authentication with no user or password */ <nl> } <nl>  <nl> /* To prevent the user + password to get sent to other than the original
# include < stdlib . h > <nl> # include < stdio . h > <nl> # include " pbs_error . h " <nl> +# include " momctl . h " <nl>  <nl> extern int flush_rc ; <nl> extern char * string_read ;
int read_config ( <nl> return ( 0 ); <nl> } <nl>  <nl> + void free_pwnam ( struct passwd * pwdp , char * buf ) <nl> + {}
# include "../../ mem / mem . h " <nl> # include "../../ md5utils . h " <nl> # include "../../ ip_addr . h " <nl> +# include "../../ parser / parse_uri . h " <nl>  <nl> # include " config . h " <nl> # include " lock . h "
static int mod_init ( void ) <nl> */ <nl> static int child_init ( int rank ) <nl> { <nl> + if ( rank == PROC_INIT ) { <nl> + return 0 ; <nl> + } <nl> _apy_process_rank = rank ; <nl> PyOS_AfterFork (); <nl> return apy_init_script ( rank );
static struct timeval time_from_string ( str * time_value ) <nl> return time_error ; <nl> } <nl>  <nl> - return ( struct timeval ) { atoi ( zero_terminated_value ), <nl> - atoi ( dot_address + 1 )}; <nl> + time_res -> tv_sec = strtol ( zero_terminated_value , ( char **) NULL , 10 ); <nl> + time_res -> tv_usec = strtol ( dot_address + 1 , ( char **) NULL , 10 ); <nl> + return 0 ; <nl> } <nl>  <nl> /* set the duration in the dialog struct */
static void set_format ( WAVEFORMATEXTENSIBLE * wformat , WORD bytepersample , <nl> wformat -> Format . nAvgBytesPerSec = samplerate * block_align ; <nl> wformat -> Format . nBlockAlign = block_align ; <nl> wformat -> Format . wBitsPerSample = bytepersample * 8 ; <nl> - wformat -> Format . cbSize = <nl> - 22 ; /* must be at least 22 for WAVE_FORMAT_EXTENSIBLE */ <nl> + wformat -> Format . cbSize = sizeof ( WAVEFORMATEXTENSIBLE ) - sizeof ( WAVEFORMATEX ); <nl> if ( bytepersample == 4 ) <nl> wformat -> SubFormat = mp_KSDATAFORMAT_SUBTYPE_IEEE_FLOAT ; <nl> else
bool fbotex_change ( struct fbotex * fbo , GL * gl , struct mp_log * log , int w , int h , <nl>  <nl> GLenum filter = fbo -> tex_filter ; <nl>  <nl> + fbotex_uninit ( fbo ); <nl> + <nl> * fbo = ( struct fbotex ) { <nl> . gl = gl , <nl> . rw = w ,
static void handle_stream ( demuxer_t * demuxer , int i ) <nl> sh_sub -> frame_based = 23 . 976 ; <nl> } <nl> } <nl> + <nl> + if ( matches_avinputformat_name ( priv , " ass ")) <nl> + sh_sub -> is_utf8 = true ; <nl> + <nl> break ; <nl> } <nl> case AVMEDIA_TYPE_ATTACHMENT : {
void gl_video_render_frame ( struct gl_video * p , struct vo_frame * frame , int fbo ) <nl> GL * gl = p -> gl ; <nl> struct video_image * vimg = & p -> image ; <nl>  <nl> + if ( fbo && !( gl -> mpgl_caps & MPGL_CAP_FB )) { <nl> + MP_FATAL ( p , " Rendering to FBO requested , but no FBO extension found !\ n "); <nl> + return ; <nl> + } <nl> + <nl> p -> broken_frame = false ; <nl>  <nl> gl -> BindFramebuffer ( GL_FRAMEBUFFER , fbo );
static void uninit ( struct dec_audio * da ) <nl> av_freep (& lavf_ctx -> pb -> buffer ); <nl> av_freep (& lavf_ctx -> pb ); <nl> avformat_free_context ( lavf_ctx ); <nl> + spdif_ctx -> lavf_ctx = NULL ; <nl> } <nl> } <nl> 
int mpcodecs_config_vo ( sh_video_t * sh , int w , int h , unsigned int preferred_outf <nl> } <nl> } <nl>  <nl> + if ( video_out -> get_info ) <nl> { const vo_info_t * info = video_out -> get_info (); <nl> mp_msg ( MSGT_CPLAYER , MSGL_INFO ," VO : [% s ] % dx % d => % dx % d % s % s % s % s % s \ n ", info -> short_name , <nl> sh -> disp_w , sh -> disp_h ,
static bool resize_d3d ( d3d_priv * priv ) <nl> return 0 ; <nl> } <nl>  <nl> - if (! priv -> d3d_device ) <nl> + if (! priv -> d3d_device || ! priv -> image_format ) <nl> return 1 ; <nl>  <nl> if (! create_d3d_surfaces ( priv ))
static int update_display_size ( struct vo * vo ) <nl> } <nl> p -> sc = gl_sc_create ( p -> egl . gl , vo -> log , vo -> global ), <nl> p -> osd = mpgl_osd_init ( p -> egl . gl , vo -> log , vo -> osd ); <nl> + p -> osd_change_counter = - 1 ; // force initial overlay rendering <nl>  <nl> p -> display_fps = 0 ; <nl> TV_GET_STATE_RESP_T tvstate ;
static int d_check_file ( struct demuxer * demuxer , enum demux_check check ) <nl> * p = ( struct priv ) { <nl> . track = track , <nl> }; <nl> + demuxer -> priv = p ; <nl>  <nl> struct sh_stream * sh = new_sh_stream ( demuxer , STREAM_SUB ); <nl> sh -> sub -> track = track ;
int init_audio_codec ( sh_audio_t * sh_audio ) <nl> sh_audio -> sample_format = AFMT_S16_LE ; <nl> # endif <nl> sh_audio -> samplerate = 0 ; <nl> + sh_audio -> channels = 0 ; <nl> sh_audio -> i_bps = 0 ; // input rate ( bytes / sec ) <nl> sh_audio -> o_bps = 0 ; // output rate ( bytes / sec ) <nl> 
AcpiTbInstallTableWithOverride ( <nl> * DESCRIPTION : This function is called to verify and install an ACPI table . <nl> * When this function is called by " Load " or " LoadTable " opcodes , <nl> * or by AcpiLoadTable () API , the " Reload " parameter is set . <nl> - * After sucessfully returning from this function , table is <nl> + * After successfully returning from this function , table is <nl> * " INSTALLED " but not " VALIDATED ". <nl> * <nl> ******************************************************************************/
OpcDoPld ( <nl> { <nl> UINT8 * Buffer ; <nl> ACPI_PARSE_OBJECT * Node ; <nl> - ACPI_PLD_INFO PldInfo = { 0 }; <nl> + ACPI_PLD_INFO PldInfo ; <nl> ACPI_PARSE_OBJECT * NewOp ; <nl>  <nl>  <nl> OpcDoPld ( <nl> return ; <nl> } <nl>  <nl> + ACPI_MEMSET (& PldInfo , 0 , sizeof ( ACPI_PLD_INFO )); <nl> + <nl> Node = Op -> Asl . Child ; <nl> while ( Node ) <nl> {
static GSList * gd_vc_gfx_init ( GtkDisplayState * s , VirtualConsole * vc , <nl>  <nl> if ( dpy_ui_info_supported ( vc -> gfx . dcl . con )) { <nl> gtk_menu_item_activate ( GTK_MENU_ITEM ( s -> zoom_fit_item )); <nl> + s -> free_scale = true ; <nl> } <nl>  <nl> return group ;
static void cloop_close ( BlockDriverState * bs ) <nl> { <nl> BDRVCloopState * s = bs -> opaque ; <nl> if ( s -> n_blocks > 0 ) { <nl> - free ( s -> offsets ); <nl> + g_free ( s -> offsets ); <nl> } <nl> - free ( s -> compressed_block ); <nl> - free ( s -> uncompressed_block ); <nl> + g_free ( s -> compressed_block ); <nl> + g_free ( s -> uncompressed_block ); <nl> inflateEnd (& s -> zstream ); <nl> } <nl> 
uint32_t lm4549_write_samples ( lm4549_state * s , uint32_t left , uint32_t right ) <nl> This model supports 16 - bit playback . <nl> */ <nl>  <nl> - if ( s -> buffer_level >= LM4549_BUFFER_SIZE ) { <nl> + if ( s -> buffer_level > LM4549_BUFFER_SIZE - 2 ) { <nl> DPRINTF (" write_sample Buffer full \ n "); <nl> return 0 ; <nl> }
static void framebuffer_update_request ( VncState * vs , int incremental , <nl> return ; <nl> } <nl>  <nl> + vs -> force_update = 1 ; <nl> vnc_set_area_dirty ( vs -> dirty , width , height , x , y , w , h ); <nl> } <nl> 
ssize_t v9fs_list_xattr ( FsContext * ctx , const char * path , <nl>  <nl> /* Get the actual len */ <nl> xattr_len = llistxattr ( rpath ( ctx , path ), value , 0 ); <nl> + if ( xattr_len <= 0 ) { <nl> + return xattr_len ; <nl> + } <nl>  <nl> /* Now fetch the xattr and find the actual size */ <nl> orig_value = qemu_malloc ( xattr_len );
static void decode_opc ( CPUState * env , DisasContext * ctx ) <nl> gen_goto_tb ( ctx , 1 , ctx -> pc + 4 ); <nl> gen_set_label ( l1 ); <nl> } <nl> + <nl> + if ( unlikely ( qemu_loglevel_mask ( CPU_LOG_TB_OP ))) <nl> + tcg_gen_debug_insn_start ( ctx -> pc ); <nl> + <nl> op = MASK_OP_MAJOR ( ctx -> opcode ); <nl> rs = ( ctx -> opcode >> 21 ) & 0x1f ; <nl> rt = ( ctx -> opcode >> 16 ) & 0x1f ;
static int cpu_post_load ( void * opaque , int version_id ) <nl> } <nl> } <nl>  <nl> - return cpu_post_load ( env , version_id ); <nl> + tlb_flush ( env , 1 ); <nl> + return 0 ; <nl> } <nl>  <nl> const VMStateDescription vmstate_cpu = {
static int unpack ( const struct optstruct * opts ) <nl> name [ sizeof ( name )- 1 ]='\ 0 '; <nl> } <nl>  <nl> + if ( cl_cvdverify ( name ) != CL_SUCCESS ) { <nl> + mprintf ("! unpack : % s is not a valid CVD \ n ", name ); <nl> + return - 1 ; <nl> + } <nl> + <nl> if ( cli_cvdunpack ( name , ".") == - 1 ) { <nl> mprintf ("! unpack : Can ' t unpack file % s \ n ", name ); <nl> return - 1 ;
const char * cl_strerror ( int clerror ) <nl> return " Can ' t map file into memory "; <nl> case CL_EMEM : <nl> return " Can ' t allocate memory "; <nl> + case CL_ETIMEOUT : <nl> + return " Time limit reached "; <nl> /* internal ( needed for debug messages ) */ <nl> case CL_EMAXREC : <nl> return " CL_EMAXREC ";
wwwconnect ( const char * server , const char * proxy , int pport , char * ip , <nl> } <nl> else <nl> i ++; <nl> - mirman_update ( addr , rp -> ai_family , mdat , 2 ); <nl> + if ( mdat ) <nl> + mirman_update ( addr , rp -> ai_family , mdat , 2 ); <nl> continue ; <nl> } <nl> else
int cli_parse_add ( struct cli_matcher * root , const char * virname , const char * hex <nl> if (( n = cli_strtok ( pt , 2 , "-"))) { /* strict check */ <nl> error = 1 ; <nl> free ( n ); <nl> + break ; <nl> } <nl> } <nl> }
static int valid_pmbr ( struct fdisk_context * cxt ) <nl> goto check_hybrid ; <nl> } <nl> } <nl> - check_hybrid : <nl> + <nl> if ( ret != GPT_MBR_PROTECTIVE ) <nl> goto done ; <nl> + check_hybrid : <nl> for ( i = 0 ; i < 4 ; i ++) { <nl> if (( pmbr -> partition_record [ i ]. os_type != EFI_PMBR_OSTYPE ) && <nl> ( pmbr -> partition_record [ i ]. os_type != 0x00 ))
static void print_value ( int output , int num , const char * devname , <nl> print_udev_format ( name , value ); <nl>  <nl> } else if ( output & OUTPUT_EXPORT_LIST ) { <nl> + if ( num == 1 && devname ) <nl> + printf (" DEVNAME =% s \ n ", devname ); <nl> fputs ( name , stdout ); <nl> fputs ("=", stdout ); <nl> safe_print ( value , valsz );
static void <nl> xbsd_write_bootstrap ( void ) <nl> { <nl> char * bootdir = BSD_LINUX_BOOTDIR ; <nl> - char path [ MAXPATHLEN ]; <nl> + char path [ sizeof ( BSD_LINUX_BOOTDIR ) + 1 + 2 + 4 ]; /* BSD_LINUX_BOOTDIR + / + { sd , wd } + boot */ <nl> char * dkbasename ; <nl> struct xbsd_disklabel dl ; <nl> char * d , * p , * e ;
int openDatabase ( char * prefix , char * dbpath , rpmdb * rpmdbp , int mode , <nl> int i ; <nl> struct flock lockinfo ; <nl>  <nl> + /* we should accept NULL as a valid prefix */ <nl> + if (! prefix ) prefix =""; <nl> + <nl> i = strlen ( dbpath ); <nl> if ( dbpath [ i - 1 ] != '/') { <nl> filename = alloca ( i + 2 );
static int installArchive ( char * prefix , int fd , struct fileToInstall * files , <nl> kill ( SIGTERM , child ); <nl> } <nl>  <nl> - if ( write ( p [ 1 ], buf , bytesRead ) != bytesRead ) { <nl> + if ( bytesRead && write ( p [ 1 ], buf , bytesRead ) != bytesRead ) { <nl> cpioFailed = 1 ; <nl> childDead = 1 ; <nl> kill ( SIGTERM , child );
static void removeIndexEntry ( dbIndex * dbi , char * key , dbIndexRecord rec , <nl> case 2 : <nl> break ; /* error message already generated from dbindex . c */ <nl> } <nl> + <nl> + freeDBIndexRecord ( matches ); <nl> } <nl>  <nl> int rpmdbRemove ( rpmdb db , unsigned int offset , int tolerant ) { <nl> int rpmdbRemove ( rpmdb db , unsigned int offset , int tolerant ) { <nl>  <nl> unblockSignals (); <nl>  <nl> + freeHeader ( h ); <nl> + <nl> return 0 ; <nl> } <nl> 
int mailbox_rename_cleanup ( struct mailbox ** mailboxptr , int isinbox ) <nl> */ <nl> int mailbox_copyfile ( const char * from , const char * to , int nolink ) <nl> { <nl> - int flags = 0 ; <nl> + int flags = COPYFILE_MKDIR ; <nl> if ( nolink ) flags |= COPYFILE_NOLINK ; <nl> - return cyrus_copyfile ( from , to , flags ); <nl> + <nl> + if ( cyrus_copyfile ( from , to , flags )) <nl> + return IMAP_IOERROR ; <nl> + <nl> + return 0 ; <nl> } <nl>  <nl> /* ---------------------------------------------------------------------- */
int meth_acl ( struct transaction_t * txn , void * params ) <nl> else if (! xmlStrcmp ( priv -> name , <nl> BAD_CAST " read ")) <nl> rights |= DACL_READ ; <nl> + else if (! xmlStrcmp ( priv -> name , <nl> + BAD_CAST " read - free - busy ")) <nl> + rights |= DACL_READFB ; <nl> else if (! xmlStrcmp ( priv -> name , <nl> BAD_CAST " write ")) <nl> rights |= DACL_WRITE ;
void moduleHandleBlockedClients ( void ) { <nl> if ( bc -> privdata && bc -> free_privdata ) <nl> bc -> free_privdata ( bc -> privdata ); <nl> zfree ( bc ); <nl> - if ( c != NULL ) unblockClient ( bc -> client ); <nl> + if ( c != NULL ) unblockClient ( c ); <nl>  <nl> /* Lock again before to iterate the loop . */ <nl> pthread_mutex_lock (& moduleUnblockedClientsMutex );
static int handle_metadata ( RTMPContext * rt , RTMPPacket * pkt ) <nl> pts = cts ; <nl> ts += cts - pts ; <nl> pts = cts ; <nl> + if ( size + 3 + 4 > pkt -> data + pkt -> size - next ) <nl> + break ; <nl> bytestream_put_byte (& p , type ); <nl> bytestream_put_be24 (& p , size ); <nl> bytestream_put_be24 (& p , ts );
static int audio_decode_frame ( VideoState * is , double * pts_ptr ) <nl> /* free the current packet */ <nl> if ( pkt -> data ) <nl> av_free_packet ( pkt ); <nl> + memset ( pkt_temp , 0 , sizeof (* pkt_temp )); <nl>  <nl> if ( is -> paused || is -> audioq . abort_request ) { <nl> return - 1 ;
static int setup_hwaccel ( AVCodecContext * avctx , <nl> return AVERROR ( ENOMEM ); <nl> } <nl>  <nl> + avctx -> hwaccel = hwa ; <nl> if ( hwa -> init ) { <nl> ret = hwa -> init ( avctx ); <nl> if ( ret < 0 ) { <nl> av_freep (& avctx -> internal -> hwaccel_priv_data ); <nl> + avctx -> hwaccel = NULL ; <nl> return ret ; <nl> } <nl> } <nl>  <nl> - avctx -> hwaccel = hwa ; <nl> - <nl> return 0 ; <nl> } <nl> 
static void init_input_filter ( FilterGraph * fg , AVFilterInOut * in ) <nl> char * p ; <nl> int file_idx = strtol ( in -> name , & p , 0 ); <nl>  <nl> - if ( file_idx < 0 || file_idx > nb_input_files ) { <nl> + if ( file_idx < 0 || file_idx >= nb_input_files ) { <nl> av_log ( NULL , AV_LOG_FATAL , " Invalid file index % d in filtegraph description % s .\ n ", <nl> file_idx , fg -> graph_desc ); <nl> exit_program ( 1 );
static int tls_open ( URLContext * h , const char * uri , int flags , AVDictionary ** op <nl> struct addrinfo hints = { 0 }, * ai = NULL ; <nl> const char * proxy_path ; <nl> int use_proxy ; <nl> -# if CONFIG_OPENSSL <nl> +# if CONFIG_OPENSSL && ! CONFIG_GNUTLS <nl> BIO * bio ; <nl> # endif <nl> 
static int filter_frame ( AVFilterLink * inlink , AVFrame * in ) <nl> direct = 1 ; <nl> out = in ; <nl> } else { <nl> + direct = 0 ; <nl> out = ff_get_video_buffer ( outlink , outlink -> w , outlink -> h ); <nl> if (! out ) { <nl> av_frame_free (& in );
static int process_line ( URLContext * h , char * line , int line_count , <nl> # ifdef DEBUG <nl> printf (" http_code =% d \ n ", s -> http_code ); <nl> # endif <nl> + /* error codes are 4xx and 5xx */ <nl> + if ( s -> http_code >= 400 && s -> http_code < 600 ) <nl> + return - 1 ; <nl> } else { <nl> while (* p != '\ 0 ' && * p != ':') <nl> p ++;
static int mp3_read_probe ( AVProbeData * p ) <nl>  <nl> max_frames = 0 ; <nl> buf = buf0 ; <nl> - end = buf + p -> buf_size - sizeof ( uint32_t ); <nl> + end = p -> buf + p -> buf_size - sizeof ( uint32_t ); <nl>  <nl> for (; buf < end ; buf = buf2 + 1 ) { <nl> buf2 = buf ;
static int oma_read_header ( AVFormatContext * s , <nl>  <nl> ff_id3v2_read ( s , ID3v2_EA3_MAGIC ); <nl> ret = avio_read ( s -> pb , buf , EA3_HEADER_SIZE ); <nl> + if ( ret < EA3_HEADER_SIZE ) <nl> + return - 1 ; <nl>  <nl> if ( memcmp ( buf , (( const uint8_t []){' E ', ' A ', ' 3 '}), 3 ) || buf [ 4 ] != 0 || buf [ 5 ] != EA3_HEADER_SIZE ) { <nl> av_log ( s , AV_LOG_ERROR , " Couldn ' t find the EA3 header !\ n ");
static int mxf_get_sorted_table_segments ( MXFContext * mxf , int * nb_sorted_segment <nl> if ( mxf -> metadata_sets [ i ]-> type == IndexTableSegment ) <nl> nb_segments ++; <nl>  <nl> + if (! nb_segments ) <nl> + return AVERROR_INVALIDDATA ; <nl> + <nl> * sorted_segments = av_mallocz ( nb_segments * sizeof (** sorted_segments )); <nl> unsorted_segments = av_mallocz ( nb_segments * sizeof (* unsorted_segments )); <nl> if (! sorted_segments || ! unsorted_segments ) {
const char * zmq_strerror ( int errnum_ ) <nl> return " Address in use "; <nl> case EADDRNOTAVAIL : <nl> return " Address not available "; <nl> + case ECONNREFUSED : <nl> + return " Connection refused "; <nl> + case EINPROGRESS : <nl> + return " Operation in progress "; <nl> # endif <nl> case EMTHREAD : <nl> return " Number of preallocated application threads exceeded ";
int read_mainconfig ( int reload ) <nl> if ( mainconfig . reject_delay > mainconfig . cleanup_delay ) { <nl> mainconfig . reject_delay = mainconfig . cleanup_delay ; <nl> } <nl> + if ( mainconfig . reject_delay < 0 ) mainconfig . reject_delay = 0 ; <nl>  <nl> /* <nl> * Initialize the old " bind_address " and " port ", first .
static void msn_close ( struct gaim_connection * gc ) <nl> g_slist_free ( md -> msgq ); <nl> } <nl>  <nl> + g_free ( md -> grouplist ); <nl> + <nl> g_free ( md ); <nl> } <nl> 
int jabber_si_handle_request ( struct im_connection * ic , struct xt_node * node , st <nl> requestok = FALSE ; <nl> } <nl>  <nl> - * s = '/'; <nl> + if ( s ) <nl> + * s = '/'; <nl> } <nl> - else <nl> + <nl> + if ( ! requestok ) <nl> { <nl> reply = jabber_make_error_packet ( node , " item - not - found ", " cancel ", NULL ); <nl> if (! jabber_write_packet ( ic , reply ))
WSLUA_METAMETHOD Columns__newindex ( lua_State * L ) { <nl>  <nl> for ( cn = colnames ; cn -> name ; cn ++) { <nl> if ( g_str_equal ( cn -> name , colname ) ) { <nl> - col_set_str ( cols -> cinfo , cn -> id , text ); <nl> + col_add_str ( cols -> cinfo , cn -> id , text ); <nl> return 0 ; <nl> } <nl> }
dissect_gryphon_message ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , <nl> /* <nl> * Indicate what kind of message this is . <nl> */ <nl> - col_set_str ( pinfo -> cinfo , COL_INFO , val_to_str ( frmtyp , frame_type , "- Invalid -")); <nl> + col_set_str ( pinfo -> cinfo , COL_INFO , val_to_str_const ( frmtyp , frame_type , "- Invalid -")); <nl> } <nl>  <nl> if ( tree == NULL )
tvb_captured_length ( const tvbuff_t * tvb ) <nl> static inline gint <nl> _tvb_captured_length_remaining ( const tvbuff_t * tvb , const gint offset ) <nl> { <nl> - guint abs_offset , rem_length ; <nl> + guint abs_offset = 0 , rem_length ; <nl> int exception ; <nl>  <nl> exception = compute_offset_and_remaining ( tvb , offset , & abs_offset , & rem_length );
static int FieldInfo_get_range ( lua_State * L ) { <nl> r -> tvb = ep_new ( struct _wslua_tvb ); <nl>  <nl> r -> tvb -> ws_tvb = fi -> ds_tvb ; <nl> + r -> tvb -> expired = FALSE ; <nl> + r -> tvb -> need_free = FALSE ; <nl> r -> offset = fi -> start ; <nl> r -> len = fi -> length ; <nl> 
WirelessFrame :: WirelessFrame ( QWidget * parent ) : <nl>  <nl> WirelessFrame ::~ WirelessFrame () <nl> { <nl> + ws80211_free_interfaces ( interfaces_ ); <nl> delete ui ; <nl> } <nl> 
dissect_vmlab ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) <nl> guint8 attributes ; <nl> guint8 portgroup ; <nl>  <nl> - guint16 encap_proto ; <nl> + volatile guint16 encap_proto ; <nl>  <nl> col_set_str ( pinfo -> cinfo , COL_PROTOCOL , " VMLAB "); <nl> col_clear ( pinfo -> cinfo , COL_INFO );
PHP_METHOD ( Phar , copy ) <nl> } <nl> } <nl>  <nl> - if ( phar_path_check (& newfile , & newfile_len , & pcr_error ) > pcr_is_ok ) { <nl> + if ( phar_path_check (& newfile , ( int *) & newfile_len , & pcr_error ) > pcr_is_ok ) { <nl> zend_throw_exception_ex ( spl_ce_UnexpectedValueException , 0 TSRMLS_CC , <nl> " file \"% s \" contains invalid characters % s , cannot be copied from \"% s \" in phar % s ", newfile , pcr_error , oldfile , phar_obj -> archive -> fname ); <nl> RETURN_FALSE ;
int call_user_function_ex ( HashTable * function_table , zval ** object_pp , zval * fun <nl>  <nl> zend_ptr_stack_n_push (& EG ( argument_stack ), 2 , ( void *) ( long ) param_count , NULL ); <nl>  <nl> + EG ( function_state_ptr ) = & function_state ; <nl> + <nl> if ( function_state . function -> type == ZEND_USER_FUNCTION ) { <nl> calling_symbol_table = EG ( active_symbol_table ); <nl> if ( symbol_table ) {
PHP_FUNCTION ( oci_password_change ) <nl> WRONG_PARAM_COUNT ; <nl> } <nl>  <nl> + convert_to_string_ex ( user_param ); <nl> + convert_to_string_ex ( pass_old_param ); <nl> + convert_to_string_ex ( pass_new_param ); <nl> + <nl> user = Z_STRVAL_PP ( user_param ); <nl> pass_old = Z_STRVAL_PP ( pass_old_param ); <nl> pass_new = Z_STRVAL_PP ( pass_new_param );
static sdlParamPtr get_param ( sdlFunctionPtr function , char * param_name , int inde <nl> } else { <nl> ht = function -> responseParameters ; <nl> } <nl> + <nl> + if ( ht == NULL ) { <nl> + return NULL ; <nl> + } <nl>  <nl> if ( param_name != NULL ) { <nl> if ( zend_hash_find ( ht , param_name , strlen ( param_name ), ( void **)& tmp ) != FAILURE ) {
int phar_get_entry_data ( phar_entry_data ** ret , char * fname , int fname_len , char <nl> if ( entry -> link ) { <nl> phar_entry_info * link = phar_get_link_source ( entry TSRMLS_CC ); <nl> if (! link ) { <nl> + efree (* ret ); <nl> return FAILURE ; <nl> } <nl> (* ret )-> zero = phar_get_fp_offset ( link TSRMLS_CC );
SAPI_API SAPI_POST_HANDLER_FUNC ( rfc1867_post_handler ) <nl> int llen = 0 ; <nl> int upload_cnt = INI_INT (" max_file_uploads "); <nl>  <nl> - if ( SG ( request_info ). content_length > SG ( post_max_size )) { <nl> + if ( SG ( post_max_size ) > 0 && SG ( request_info ). content_length > SG ( post_max_size )) { <nl> sapi_module . sapi_error ( E_WARNING , " POST Content - Length of % ld bytes exceeds the limit of % ld bytes ", SG ( request_info ). content_length , SG ( post_max_size )); <nl> return ; <nl> }
PHP_FUNCTION ( grapheme_substr ) <nl> length += iter_val ; <nl> } <nl>  <nl> - if ( UBRK_DONE == sub_str_end_pos ) { <nl> + if ( UBRK_DONE == sub_str_end_pos && length < 0 ) { <nl>  <nl> intl_error_set ( NULL , U_ILLEGAL_ARGUMENT_ERROR , " grapheme_substr : length not contained in string ", 1 TSRMLS_CC ); <nl> 
flatpak_builtin_ls_remote ( int argc , char ** argv , GCancellable * cancellable , GEr <nl> if ( deploy_data == NULL ) <nl> continue ; <nl>  <nl> + if ( g_strcmp0 ( flatpak_deploy_data_get_origin ( deploy_data ), remote ) != 0 ) <nl> + continue ; <nl> + <nl> if ( g_strcmp0 ( flatpak_deploy_data_get_commit ( deploy_data ), checksum ) == 0 ) <nl> continue ; <nl> }
char ** crypto_cert_subject_alt_name ( X509 * xcert , int * count , int ** lengths ) <nl> * lengths = NULL ; <nl> return NULL ; <nl> } <nl> + GENERAL_NAMES_free ( subject_alt_names ); <nl>  <nl> return strings ; <nl> }
int LLVMFuzzerTestOneInput ( const uint8_t * data , size_t size ) { <nl>  <nl> ll = l + strspn ( l , WHITESPACE ); <nl>  <nl> - if ( HAS_FEATURE_MEMORY_SANITIZER && startswith ( ll , " ListenNetlink =")) { <nl> + if ( HAS_FEATURE_MEMORY_SANITIZER && startswith ( ll , " ListenNetlink ")) { <nl> /* ListenNetlink causes a false positive in msan , <nl> * let ' s skip this for now . */ <nl> log_notice (" Skipping test because ListenNetlink = is present ");
_public_ int sd_pid_notify_with_fds ( pid_t pid , int unset_environment , const char <nl> goto finish ; <nl> } <nl>  <nl> + if ( strlen ( e ) > sizeof ( sockaddr . un . sun_path )) { <nl> + r = - EINVAL ; <nl> + goto finish ; <nl> + } <nl> + <nl> fd = socket ( AF_UNIX , SOCK_DGRAM | SOCK_CLOEXEC , 0 ); <nl> if ( fd < 0 ) { <nl> r = - errno ;
static void item_free ( Item * i ) { <nl> free ( i -> uid_path ); <nl> free ( i -> gid_path ); <nl> free ( i -> description ); <nl> + free ( i -> home ); <nl> free ( i ); <nl> } <nl> 
static int check_unit ( DBusConnection * bus , char ** args , unsigned n ) { <nl> if (! arg_quiet ) <nl> puts ( state ); <nl>  <nl> - if ( streq ( state , " active ") || startswith ( state , " active -")) <nl> + if ( streq ( state , " active ") || startswith ( state , " reloading ")) <nl> r = 0 ; <nl>  <nl> dbus_message_unref ( m );
static void output_units_list ( const struct unit_info * unit_infos , unsigned c ) { <nl>  <nl> n_shown ++; <nl>  <nl> - if ( streq ( u -> load_state , " error ")) { <nl> + if ( streq ( u -> load_state , " error ") || <nl> + streq ( u -> load_state , " not - found ")) { <nl> on_loaded = on = ansi_highlight_red ( true ); <nl> off_loaded = off = ansi_highlight_red ( false ); <nl> } else
static void font_copy_to_all_vcs ( int fd ) { <nl> return ; <nl> } <nl>  <nl> - for ( i = 1 ; i <= 15 ; i ++) { <nl> + for ( i = 1 ; i <= 63 ; i ++) { <nl> char vcname [ strlen ("/ dev / vcs ") + DECIMAL_STR_MAX ( int )]; <nl> _cleanup_close_ int vcfd = - 1 ; <nl> struct console_font_op cfo = {};
This file is part of systemd . <nl>  <nl> Copyright 2010 Kay Sievers <nl> + Copyright 2016 Michal Soltys < soltys @ ziu . info > <nl>  <nl> systemd is free software ; you can redistribute it and / or modify it <nl> under the terms of the GNU Lesser General Public License as published by
bool ignore_file ( const char * filename ) { <nl> assert ( filename ); <nl>  <nl> if ( endswith ( filename , "~")) <nl> - return false ; <nl> + return true ; <nl>  <nl> return ignore_file_allow_backup ( filename ); <nl> }
int main ( int argc , char * argv []) { <nl> finish : <nl> pager_close (); <nl>  <nl> + strv_free ( arg_file ); <nl> + <nl> return r < 0 ? EXIT_FAILURE : EXIT_SUCCESS ; <nl> }
struct acpi_fpdt_boot { <nl> }; <nl>  <nl> int acpi_get_boot_usec ( usec_t * loader_start , usec_t * loader_exit ) { <nl> - _cleanup_free_ char * buf ; <nl> + _cleanup_free_ char * buf = NULL ; <nl> struct acpi_table_header * tbl ; <nl> size_t l ; <nl> struct acpi_fpdt_header * rec ;
static int swap_add_device_links ( Swap * s ) { <nl> if (! s -> what ) <nl> return 0 ; <nl>  <nl> + if (! s -> from_fragment ) <nl> + return 0 ; <nl> + <nl> if ( is_device_path ( s -> what )) <nl> return unit_add_node_link ( UNIT ( s ), s -> what , UNIT ( s )-> manager -> running_as == SYSTEMD_SYSTEM ); <nl> else
int parse_timestamp ( const char * t , usec_t * usec ) { <nl>  <nl> x = time ( NULL ); <nl> assert_se ( localtime_r (& x , & tm )); <nl> + tm . tm_isdst = - 1 ; <nl>  <nl> if ( streq ( t , " now ")) <nl> goto finish ;
static int output_cat ( sd_journal * j , OutputMode mode , unsigned line , <nl>  <nl> r = sd_journal_get_data ( j , " MESSAGE ", & data , & l ); <nl> if ( r < 0 ) { <nl> + /* An entry without MESSAGE =? */ <nl> + if ( r == - ENOENT ) <nl> + return 0 ; <nl> + <nl> log_error (" Failed to get data : % s ", strerror (- r )); <nl> return r ; <nl> }
imath_rsa_public_decrypt ( int flen , const unsigned char * from , <nl> mp_int_clear (& us ); <nl>  <nl> /* head zero was skipped by mp_int_to_unsigned */ <nl> + if (* p == 0 ) <nl> + return - 7 ; <nl> if (* p != 1 ) <nl> return - 6 ; <nl> size --; p ++;
create_and_write_cookie ( char * xauthfile , <nl> struct in_addr loopback ; <nl> struct hostent * h ; <nl>  <nl> - k_gethostname ( hostname , sizeof ( hostname )); <nl> + gethostname ( hostname , sizeof ( hostname )); <nl> loopback . s_addr = htonl ( INADDR_LOOPBACK ); <nl>  <nl> auth . family = FamilyLocal ;
void winpr_HexDump ( const char * tag , int level , const BYTE * data , int length ) <nl> const BYTE * p = data ; <nl> int i , line , offset = 0 ; <nl> const size_t llen = ( length > WINPR_HEXDUMP_LINE_LENGTH ) ? WINPR_HEXDUMP_LINE_LENGTH : length ; <nl> - size_t blen = 5 + llen * 5 ; <nl> + size_t blen = 7 + WINPR_HEXDUMP_LINE_LENGTH * 5 ; <nl> size_t pos = 0 ; <nl> char * buffer = malloc ( blen ); <nl> 
int WLog_ParseFilters () <nl> g_Filters = calloc ( g_FilterCount , sizeof ( wLogFilter )); <nl>  <nl> if (! g_Filters ) <nl> + { <nl> + free ( strs ); <nl> return - 1 ; <nl> + } <nl>  <nl> for ( count = 0 ; count < g_FilterCount ; count ++) <nl> { <nl> status = WLog_ParseFilter (& g_Filters [ count ], strs [ count ]); <nl>  <nl> if ( status < 0 ) <nl> + { <nl> + free ( strs ); <nl> return - 1 ; <nl> + } <nl> } <nl>  <nl> free ( strs );
BOOL tls_accept ( rdpTls * tls , const char * cert_file , const char * privatekey_file ) <nl>  <nl> BOOL tls_disconnect ( rdpTls * tls ) <nl> { <nl> + if (! tls ) <nl> + return FALSE ; <nl> + <nl> if ( tls -> ssl ) <nl> SSL_shutdown ( tls -> ssl ); <nl> 
BOOL freerdp_client_detect_command_line ( int argc , char ** argv , DWORD * flags ) <nl> return compatibility ; <nl>  <nl> /* Check , if this may be windows style syntax ... */ <nl> - if ( windows_cli_count && ( windows_cli_count >= posix_cli_count )) <nl> + if ( windows_cli_count && ( windows_cli_count >= posix_cli_count ) || ( windows_cli_status <= COMMAND_LINE_STATUS_PRINT )) <nl> { <nl> + windows_cli_count = 1 ; <nl> * flags = COMMAND_LINE_SEPARATOR_COLON ; <nl> * flags |= COMMAND_LINE_SIGIL_SLASH | COMMAND_LINE_SIGIL_PLUS_MINUS ; <nl> }
wReference * ReferenceTable_GetFreeEntry ( wReferenceTable * referenceTable ) <nl> new_size = referenceTable -> size * 2 ; <nl> new_ref = ( wReference *) realloc ( referenceTable -> array , <nl> sizeof ( wReference ) * new_size ); <nl> + if (! new_ref ) <nl> + return NULL ; <nl>  <nl> referenceTable -> size = new_size ; <nl> referenceTable -> array = new_ref ;
BOOL ValidFileNameComponent ( LPCWSTR lpFileName ) <nl> { <nl> LPCWSTR c = NULL ; <nl>  <nl> + if (! lpFileName ) <nl> + return FALSE ; <nl> + <nl> /* CON */ <nl> if (( lpFileName [ 0 ] != L '\ 0 ' && ( lpFileName [ 0 ] == L ' C ' || lpFileName [ 0 ] == L ' c ')) && <nl> ( lpFileName [ 1 ] != L '\ 0 ' && ( lpFileName [ 1 ] == L ' O ' || lpFileName [ 1 ] == L ' o ')) &&
BOOL rdp_server_establish_keys ( rdpRdp * rdp , wStream * s ) <nl> if ( rand_len != key_len + 8 ) <nl> { <nl> WLog_ERR ( TAG , " invalid encrypted client random length "); <nl> + free ( client_random ); <nl> goto end ; <nl> } <nl>  <nl> crypt_client_random = calloc ( 1 , rand_len ); <nl> if (! crypt_client_random ) <nl> + { <nl> + free ( client_random ); <nl> goto end ; <nl> + } <nl> + <nl> Stream_Read ( s , crypt_client_random , rand_len ); <nl>  <nl> mod = rdp -> settings -> RdpServerRsaKey -> Modulus ;
gdImageScaleTwoPass ( const gdImagePtr src , const unsigned int new_width , <nl> }/* if */ <nl>  <nl> if ( src != tmp_im ) { <nl> - gdFree ( tmp_im ); <nl> + gdImageDestroy ( tmp_im ); <nl> }/* if */ <nl>  <nl> return dst ;
public : <nl> ROOT :: NewFunc_t GetNew () const ; <nl> ROOT :: NewArrFunc_t GetNewArray () const ; <nl> Int_t GetNmethods (); <nl> -# ifdef __CINT__ <nl> - TClass ** GetPersistentRef () const { return fPersistentRef ; } <nl> -# else <nl> TClass * const * GetPersistentRef () const { return fPersistentRef ; } <nl> -# endif <nl> TRealData * GetRealData ( const char * name ) const ; <nl> TVirtualRefProxy * GetReferenceProxy () const { return fRefProxy ; } <nl> const ROOT :: Detail :: TSchemaRuleSet * GetSchemaRules () const ;
XrdSysMutex XrdOucAppleBonjour :: SingletonMutex ; <nl>  <nl> XrdOucAppleBonjour :: XrdOucAppleBonjour () <nl> { <nl> - putenv (" AVAHI_COMPAT_NOWARN = 1 "); <nl> + char * env = new char [ 22 ]; <nl> + strcpy ( env , " AVAHI_COMPAT_NOWARN = 1 "); <nl> + putenv ( env ); <nl> } <nl>  <nl> XrdOucAppleBonjour ::~ XrdOucAppleBonjour () { }
static float wv_get_value_float ( WavpackFrameContext * s , uint32_t * crc , int S ) <nl> uint32_t u ; <nl> } value ; <nl>  <nl> - int sign ; <nl> + unsigned int sign ; <nl> int exp = s -> float_max_exp ; <nl>  <nl> if ( s -> got_extra_bits ) {
static int ea_read_header ( AVFormatContext * s ) <nl> ea -> audio_codec = 0 ; <nl> return 1 ; <nl> } <nl> - if ( ea -> bytes <= 0 ) { <nl> + if ( ea -> bytes <= 0 || ea -> bytes > 2 ) { <nl> av_log ( s , AV_LOG_ERROR , <nl> " Invalid number of bytes per sample : % d \ n ", ea -> bytes ); <nl> ea -> audio_codec = AV_CODEC_ID_NONE ;
static int vlc_decode_block ( MimicContext * ctx , int num_coeffs , int qscale ) <nl>  <nl> coeff = vlcdec_lookup [ num_bits ][ value ]; <nl> if ( pos < 3 ) <nl> - coeff <<= 4 ; <nl> + coeff *= 16 ; <nl> else /* TODO Use >> 10 instead of / 1001 */ <nl> coeff = ( coeff * qscale ) / 1001 ; <nl> 
void av_opt_freep_ranges ( AVOptionRanges ** rangesp ) <nl> int i ; <nl> AVOptionRanges * ranges = * rangesp ; <nl>  <nl> + if (! ranges ) <nl> + return ; <nl> + <nl> for ( i = 0 ; i < ranges -> nb_ranges * ranges -> nb_components ; i ++) { <nl> AVOptionRange * range = ranges -> range [ i ]; <nl> av_freep (& range -> str );
# include " cabac_functions . h " <nl> # include " hevc . h " <nl>  <nl> -# define CABAC_MAX_BIN 100 <nl> +# define CABAC_MAX_BIN 31 <nl>  <nl> /** <nl> * number of bin by SyntaxElement .
int main ( int argc , char ** argv ){ <nl> FILE * f [ 2 ]; <nl> int i , pos ; <nl> int siglen , datlen ; <nl> - int bestpos ; <nl> + int bestpos = 0 ; <nl> double bestc = 0 ; <nl> double sigamp = 0 ; <nl> int16_t * signal , * data ;
static int mxf_read_close ( AVFormatContext * s ) <nl>  <nl> for ( i = 0 ; i < mxf -> nb_index_tables ; i ++) { <nl> av_freep (& mxf -> index_tables [ i ]. segments ); <nl> + av_freep (& mxf -> index_tables [ i ]. ptses ); <nl> av_freep (& mxf -> index_tables [ i ]. fake_index ); <nl> } <nl> av_freep (& mxf -> index_tables );
static av_cold int encode_init ( AVCodecContext * avctx ) <nl> // case PIX_FMT_YUV444P : <nl> // case PIX_FMT_YUV422P : <nl> case PIX_FMT_YUV420P : <nl> - case PIX_FMT_GRAY8 : <nl> +// case PIX_FMT_GRAY8 : <nl> // case PIX_FMT_YUV411P : <nl> // case PIX_FMT_YUV410P : <nl> s -> colorspace_type = 0 ;
int Configure ( void ** ctxp , int argc , char * argv []) <nl> if ( argc > 1 ) <nl> { <nl> * ctxp = av_mallocz ( sizeof ( ContextInfo )); <nl> - if ( ctxp != NULL && argc > 1 ) <nl> + if ( * ctxp != NULL && argc > 1 ) <nl> { <nl> ContextInfo * info = ( ContextInfo *)* ctxp ; <nl> info -> rw = rwpipe_open ( argc - 1 , & argv [ 1 ] );
static int rv10_decode_frame ( AVCodecContext * avctx , <nl> offset + FFMAX ( size , size2 ) > buf_size ) <nl> return AVERROR_INVALIDDATA ; <nl>  <nl> - if ( rv10_decode_packet ( avctx , buf + offset , size , size2 ) > 8 * size ) <nl> + if (( ret = rv10_decode_packet ( avctx , buf + offset , size , size2 )) < 0 ) <nl> + return ret ; <nl> + <nl> + if ( ret > 8 * size ) <nl> i ++; <nl> } <nl> 
static void destroy_buffers ( SANMVideoContext * ctx ) <nl> ctx -> frm0_size = <nl> ctx -> frm1_size = <nl> ctx -> frm2_size = 0 ; <nl> + init_sizes ( ctx , 0 , 0 ); <nl> } <nl>  <nl> static av_cold int init_buffers ( SANMVideoContext * ctx )
fixup_vorbis_headers ( AVFormatContext * as , struct oggvorbis_private * priv , <nl> for ( i = 0 ; i < 3 ; i ++) { <nl> memcpy (& ptr [ offset ], priv -> packet [ i ], priv -> len [ i ]); <nl> offset += priv -> len [ i ]; <nl> + av_freep (& priv -> packet [ i ]); <nl> } <nl> * buf = av_realloc (* buf , offset + FF_INPUT_BUFFER_PADDING_SIZE ); <nl> return offset ;
int ff_dca_xll_decode_audio ( DCAContext * s , AVFrame * frame ) <nl> } <nl> for ( i = 0 ; i < chset -> channels ; i ++) { <nl> int param_index = params -> seg_type ? 0 : i ; <nl> - int bits = params -> pancABIT0 [ param_index ]; <nl> int part0 = params -> nSamplPart0 [ param_index ]; <nl> + int bits = part0 ? params -> pancABIT0 [ param_index ] : 0 ; <nl> int * sample_buf = s -> xll_sample_buf + <nl> ( in_channel + i ) * s -> xll_smpl_in_seg ; <nl> 
static av_always_inline void pred_8x16_motion ( const H264Context * const h , <nl> if ( IS_INTERLACED ( type )) { \ <nl> refn >>= 1 ; \ <nl> AV_COPY32 ( mvbuf [ idx ], mvn ); \ <nl> - mvbuf [ idx ][ 1 ] <<= 1 ; \ <nl> + mvbuf [ idx ][ 1 ] *= 2 ; \ <nl> mvn = mvbuf [ idx ]; \ <nl> } \ <nl> } \
static int decode_header ( EXRContext * s ) <nl> channel -> xsub = xsub ; <nl> channel -> ysub = ysub ; <nl>  <nl> - s -> current_channel_offset += 1 << current_pixel_type ; <nl> + if ( current_pixel_type == EXR_HALF ) { <nl> + s -> current_channel_offset += 2 ; <nl> + } else {/* Float or UINT32 */ <nl> + s -> current_channel_offset += 4 ; <nl> + } <nl> } <nl>  <nl> /* Check if all channels are set with an offset or if the channels
static av_cold int adpcm_encode_init ( AVCodecContext * avctx ) <nl> goto error ; <nl> } <nl>  <nl> - avctx -> coded_frame = avcodec_alloc_frame (); <nl> + if (!( avctx -> coded_frame = avcodec_alloc_frame ())) <nl> + goto error ; <nl>  <nl> return 0 ; <nl> error :
static av_always_inline void RENAME ( decode_line )( FFV1Context * s , int w , <nl> } <nl>  <nl> if ( sign ) <nl> - diff = - diff ; <nl> + diff = -( unsigned ) diff ; <nl>  <nl> sample [ 1 ][ x ] = av_mod_uintp2 ( RENAME ( predict )( sample [ 1 ] + x , sample [ 0 ] + x ) + ( SUINT ) diff , bits ); <nl> }
int av_stream_add_side_data ( AVStream * st , enum AVPacketSideDataType type , <nl> } <nl> } <nl>  <nl> - tmp = av_realloc_array ( st -> side_data , st -> nb_side_data + 1 , sizeof (* tmp )); <nl> + if (( unsigned ) st -> nb_side_data + 1 >= INT_MAX / sizeof (* st -> side_data )) <nl> + return AVERROR ( ERANGE ); <nl> + <nl> + tmp = av_realloc ( st -> side_data , st -> nb_side_data + 1 * sizeof (* tmp )); <nl> if (! tmp ) { <nl> return AVERROR ( ENOMEM ); <nl> }
static void clear_context ( MpegEncContext * s ) <nl>  <nl> s -> parse_context . buffer = NULL ; <nl> s -> parse_context . buffer_size = 0 ; <nl> + s -> parse_context . overread = 0 ; <nl> s -> bitstream_buffer = NULL ; <nl> s -> allocated_bitstream_buffer_size = 0 ; <nl> s -> picture = NULL ;
int ff_read_riff_info ( AVFormatContext * s , int64_t size ) <nl> AV_WL32 ( key , chunk_code ); <nl>  <nl> if ( avio_read ( pb , value , chunk_size ) != chunk_size ) { <nl> - av_freep ( key ); <nl> - av_freep ( value ); <nl> + av_free ( value ); <nl> av_log ( s , AV_LOG_ERROR , " premature end of file while reading INFO tag \ n "); <nl> return AVERROR_INVALIDDATA ; <nl> }
reload : <nl> /* If we need to reload the playlist again below ( if <nl> * there ' s still no more segments ), switch to a reload <nl> * interval of half the target duration . */ <nl> - reload_interval = v -> target_duration * 500000 ; <nl> + reload_interval = v -> target_duration * 500000LL ; <nl> } <nl> if ( v -> cur_seq_no < v -> start_seq_no ) { <nl> av_log ( NULL , AV_LOG_WARNING ,
static int avi_read_seek ( AVFormatContext * s , int stream_index , <nl> continue ; <nl>  <nl> // av_assert1 ( st2 -> codecpar -> block_align ); <nl> - av_assert0 ( fabs ( av_q2d ( st2 -> time_base ) - ast2 -> scale / ( double ) ast2 -> rate ) < av_q2d ( st2 -> time_base ) * 0 . 00000001 ); <nl> index = av_index_search_timestamp ( st2 , <nl> av_rescale_q ( timestamp , <nl> st -> time_base ,
resync : <nl> /* for AC3 , needs to swap bytes */ <nl> if ( st -> codec -> codec_id == CODEC_ID_AC3 ) { <nl> ptr = pkt -> data ; <nl> - for ( j = 0 ; j < len ; j += 2 ) { <nl> + for ( j = 0 ; j < pkt -> size ; j += 2 ) { <nl> FFSWAP ( int , ptr [ 0 ], ptr [ 1 ]); <nl> ptr += 2 ; <nl> }
static void decode ( AVCodecContext * dec_ctx , AVFrame * frame , AVPacket * pkt , <nl>  <nl> /* the picture is allocated by the decoder . no need to <nl> free it */ <nl> - snprintf ( buf , sizeof ( buf ), filename , dec_ctx -> frame_number ); <nl> + snprintf ( buf , sizeof ( buf ), "% s -% d ", filename , dec_ctx -> frame_number ); <nl> pgm_save ( frame -> data [ 0 ], frame -> linesize [ 0 ], <nl> frame -> width , frame -> height , buf ); <nl> }
static av_cold int dirac_decode_end ( AVCodecContext * avctx ) <nl> static inline int coeff_unpack_golomb ( GetBitContext * gb , int qfactor , int qoffset ) <nl> { <nl> int coeff = dirac_get_se_golomb ( gb ); <nl> - const int sign = FFSIGN ( coeff ); <nl> + const unsigned sign = FFSIGN ( coeff ); <nl> if ( coeff ) <nl> coeff = sign *(( sign * coeff * qfactor + qoffset ) >> 2 ); <nl> return coeff ;
static av_cold int wmv2_encode_init ( AVCodecContext * avctx ){ <nl> ff_wmv2_common_init ( w ); <nl>  <nl> avctx -> extradata_size = 4 ; <nl> - avctx -> extradata = av_mallocz ( avctx -> extradata_size + 10 ); <nl> + avctx -> extradata = av_mallocz ( avctx -> extradata_size + FF_INPUT_BUFFER_PADDING_SIZE ); <nl> + if (! avctx -> extradata ) <nl> + return AVERROR ( ENOMEM ); <nl> encode_ext_header ( w ); <nl>  <nl> return 0 ;
int attribute_align_arg avcodec_open2 ( AVCodecContext * avctx , const AVCodec * code <nl> avctx -> time_base = av_inv_q ( av_mul_q ( avctx -> framerate , ( AVRational ){ avctx -> ticks_per_frame , 1 })); <nl> # endif <nl> } <nl> + if ( codec -> priv_data_size > 0 && avctx -> priv_data && codec -> priv_class ) { <nl> + av_assert0 (*( const AVClass **) avctx -> priv_data == codec -> priv_class ); <nl> + } <nl> + <nl> end : <nl> ff_unlock_avcodec (); <nl> if ( options ) {
enum OutputFormat { <nl> # define MPEG_BUF_SIZE ( 16 * 1024 ) <nl>  <nl> # define QMAT_SHIFT_MMX 16 <nl> -# define QMAT_SHIFT 22 <nl> +# define QMAT_SHIFT 21 <nl>  <nl> # define MAX_FCODE 7 <nl> # define MAX_MV 2048
int av_packet_ref ( AVPacket * dst , const AVPacket * src ) <nl> if ( ret < 0 ) <nl> goto fail ; <nl> memcpy ( dst -> buf -> data , src -> data , src -> size ); <nl> - } else <nl> + } else { <nl> dst -> buf = av_buffer_ref ( src -> buf ); <nl> + if (! dst -> buf ) <nl> + goto fail ; <nl> + } <nl>  <nl> dst -> size = src -> size ; <nl> dst -> data = dst -> buf -> data ;
static int cinepak_decode_strip ( CinepakContext * s , <nl> while (( data + 4 ) <= eod ) { <nl> chunk_id = BE_16 (& data [ 0 ]); <nl> chunk_size = BE_16 (& data [ 2 ]) - 4 ; <nl> + if ( chunk_size < 0 ) <nl> + return - 1 ; <nl> + <nl> data += 4 ; <nl> chunk_size = (( data + chunk_size ) > eod ) ? ( eod - data ) : chunk_size ; <nl> 
static int rtsp_read_header ( AVFormatContext * s ) <nl> return ret ; <nl>  <nl> rt -> real_setup_cache = ! s -> nb_streams ? NULL : <nl> - av_mallocz ( 2 * s -> nb_streams * sizeof (* rt -> real_setup_cache )); <nl> + av_mallocz_array ( s -> nb_streams , 2 * sizeof (* rt -> real_setup_cache )); <nl> if (! rt -> real_setup_cache && s -> nb_streams ) <nl> return AVERROR ( ENOMEM ); <nl> rt -> real_setup = rt -> real_setup_cache + s -> nb_streams ;
static av_cold int decode_close_mp3on4 ( AVCodecContext * avctx ) <nl> int i ; <nl>  <nl> for ( i = 0 ; i < s -> frames ; i ++) <nl> - av_free ( s -> mp3decctx [ i ]); <nl> + av_freep (& s -> mp3decctx [ i ]); <nl>  <nl> return 0 ; <nl> }
static void fill_coding_method_array ( sb_int8_array tone_level_idx , <nl> for ( j = 0 ; j < 64 ; j ++) <nl> acc += tone_level_idx_temp [ ch ][ sb ][ j ]; <nl>  <nl> - multres = 0x66666667 * ( acc * 10 ); <nl> + multres = 0x66666667LL * ( acc * 10 ); <nl> esp_40 = ( multres >> 32 ) / 8 + (( multres & 0xffffffff ) >> 31 ); <nl> for ( ch = 0 ; ch < nb_channels ; ch ++) <nl> for ( sb = 0 ; sb < 30 ; sb ++)
int ff_http_do_new_request ( URLContext * h , const char * uri ) <nl> if ( ret < 0 ) <nl> return ret ; <nl>  <nl> + if ( s -> willclose ) <nl> + return AVERROR_EOF ; <nl> + <nl> s -> end_chunked_post = 0 ; <nl> s -> chunkend = 0 ; <nl> s -> off = 0 ;
static int draw_text ( AVFilterContext * ctx , AVFilterBufferRef * picref , <nl> if ( dtext -> tc_opt_string ) { <nl> char tcbuf [ AV_TIMECODE_STR_SIZE ]; <nl> av_timecode_make_string (& dtext -> tc , tcbuf , dtext -> frame_id ++); <nl> + av_free ( buf ); <nl> buf = av_asprintf ("% s % s ", dtext -> text , tcbuf ); <nl> } <nl> 
static inline void tm2_apply_deltas ( TM2Context * ctx , int * Y , int stride , int * de <nl> } <nl> } <nl>  <nl> - static inline void tm2_high_chroma ( int * data , int stride , int * last , int * CD , int * deltas ) <nl> + static inline void tm2_high_chroma ( int * data , int stride , int * last , unsigned * CD , int * deltas ) <nl> { <nl> int i , j ; <nl> for ( j = 0 ; j < 2 ; j ++) {
static inline void skip_bits1 ( GetBitContext * s ) <nl> */ <nl> static inline unsigned int get_bits_long ( GetBitContext * s , int n ) <nl> { <nl> + av_assert2 ( n >= 0 && n <= 32 ); <nl> if (! n ) { <nl> return 0 ; <nl> } else if ( n <= MIN_CACHE_BITS ) {
static inline int mpeg2_fast_decode_block_non_intra ( MpegEncContext * s , <nl> } <nl>  <nl> block [ j ] = level ; <nl> - if ((( int32_t ) GET_CACHE ( re , & s -> gb )) <= ( int32_t ) 0xBFFFFFFF ) <nl> + if ((( int32_t ) GET_CACHE ( re , & s -> gb )) <= ( int32_t ) 0xBFFFFFFF || i >= 64 ) <nl> break ; <nl> + <nl> UPDATE_CACHE ( re , & s -> gb ); <nl> } <nl> end :
int ff_thread_decode_frame ( AVCodecContext * avctx , <nl> FrameThreadContext * fctx = avctx -> internal -> thread_ctx ; <nl> int finished = fctx -> next_finished ; <nl> PerThreadContext * p ; <nl> - int err , ret ; <nl> + int err , ret = 0 ; <nl>  <nl> /* release the async lock , permitting blocked hwaccel threads to <nl> * go forward while we are in this function */
static inline uint64_t get_bits64 ( GetBitContext * s , int n ) <nl> */ <nl> static inline int get_sbits_long ( GetBitContext * s , int n ) <nl> { <nl> + // sign_extend ( x , 0 ) is undefined <nl> + if (! n ) <nl> + return 0 ; <nl> + <nl> return sign_extend ( get_bits_long ( s , n ), n ); <nl> } <nl> 
void ff_slice_thread_free ( AVCodecContext * avctx ) <nl> pthread_mutex_destroy (& c -> current_job_lock ); <nl> pthread_cond_destroy (& c -> current_job_cond ); <nl> pthread_cond_destroy (& c -> last_job_cond ); <nl> - av_free ( c -> workers ); <nl> + av_freep (& c -> workers ); <nl> av_freep (& avctx -> internal -> thread_ctx ); <nl> } <nl> 
int ff_h263_decode_mb ( MpegEncContext * s , <nl> } <nl>  <nl> if ( IS_DIRECT ( mb_type )){ <nl> + if (! s -> pp_time ) <nl> + return AVERROR_INVALIDDATA ; <nl> s -> mv_dir = MV_DIR_FORWARD | MV_DIR_BACKWARD | MV_DIRECT ; <nl> mb_type |= ff_mpeg4_set_direct_mv ( s , 0 , 0 ); <nl> } else {
FF_ENABLE_DEPRECATION_WARNINGS <nl> } <nl> } <nl>  <nl> + if ( avctx -> slices > 1 && <nl> + ( avctx -> codec_id == AV_CODEC_ID_FLV1 || avctx -> codec_id == AV_CODEC_ID_H261 )) { <nl> + av_log ( avctx , AV_LOG_ERROR , " Multiple slices are not supported by this codec \ n "); <nl> + return AVERROR ( EINVAL ); <nl> + } <nl> + <nl> if ( s -> avctx -> thread_count > 1 && <nl> s -> codec_id != AV_CODEC_ID_MPEG4 && <nl> s -> codec_id != AV_CODEC_ID_MPEG1VIDEO &&
int ff_jpeg2000_init_component ( Jpeg2000Component * comp , <nl> // update precincts size : 2 ^ n value <nl> reslevel -> log2_prec_width = codsty -> log2_prec_widths [ reslevelno ]; <nl> reslevel -> log2_prec_height = codsty -> log2_prec_heights [ reslevelno ]; <nl> + if (! reslevel -> log2_prec_width || ! reslevel -> log2_prec_height ) { <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl>  <nl> /* Number of bands for each resolution level */ <nl> if ( reslevelno == 0 )
static int aasc_decode_frame ( AVCodecContext * avctx , <nl> AascContext * s = avctx -> priv_data ; <nl> int compr , i , stride , psize ; <nl>  <nl> + if ( buf_size < 4 ) { <nl> + av_log ( avctx , AV_LOG_ERROR , " frame too short \ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> + <nl> s -> frame . reference = 3 ; <nl> s -> frame . buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE ; <nl> if ( avctx -> reget_buffer ( avctx , & s -> frame )) {
static void copy_bits ( PutBitContext * pb , <nl> rmn_bits = rmn_bytes = get_bits_left ( gb ); <nl> if ( rmn_bits < nbits ) <nl> return ; <nl> + if ( nbits > pb -> size_in_bits - put_bits_count ( pb )) <nl> + return ; <nl> rmn_bits &= 7 ; rmn_bytes >>= 3 ; <nl> if (( rmn_bits = FFMIN ( rmn_bits , nbits )) > 0 ) <nl> put_bits ( pb , rmn_bits , get_bits ( gb , rmn_bits ));
static void rv34_pred_4x4_block ( RV34DecContext * r , uint8_t * dst , int stride , int <nl> if ( itype == VERT_LEFT_PRED ) itype = VERT_LEFT_PRED_RV40_NODOWN ; <nl> } <nl> if (! right && up ){ <nl> - topleft = dst [- stride + 3 ] * 0x01010101 ; <nl> + topleft = dst [- stride + 3 ] * 0x01010101u ; <nl> prev = ( uint8_t *)& topleft ; <nl> } <nl> r -> h . pred4x4 [ itype ]( dst , prev , stride );
static int seek_test ( const char * input_filename , const char * start , const char * <nl> return AVERROR ( ENOMEM ); <nl> } <nl>  <nl> - result = compute_crc_of_packets ( fmt_ctx , video_stream , ctx , fr , i , j , 1 ); <nl> + result = compute_crc_of_packets ( fmt_ctx , video_stream , ctx , fr , 0 , 0 , 1 ); <nl> if ( result != 0 ) <nl> return - 1 ; <nl> 
static int compute_mask ( int step , uint32_t * mask ) <nl> ret = AVERROR ( ENOMEM ); <nl> goto end ; <nl> } <nl> - counter = av_mallocz ( counter_size ); <nl> + counter = av_mallocz ( sizeof ( uint32_t *) * ( 2 * step + 1 )); <nl> if (! counter ) { <nl> ret = AVERROR ( ENOMEM ); <nl> goto end ;
static int parse_tonal ( DCALbrDecoder * s , int group ) <nl> break ; // End of subframe <nl>  <nl> freq += diff - 2 ; <nl> - if ( freq >> ( 5 - group ) > s -> nsubbands * 4 - 5 ) { <nl> + if ( freq >> ( 5 - group ) > s -> nsubbands * 4 - 6 ) { <nl> av_log ( s -> avctx , AV_LOG_ERROR , " Invalid spectral line offset \ n "); <nl> return - 1 ; <nl> }
static void mpc8_parse_seektable ( AVFormatContext * s , int64_t off ) <nl> av_log ( s , AV_LOG_ERROR , " No seek table at given position \ n "); <nl> return ; <nl> } <nl> + if ( size < 0 || size >= INT_MAX / 2 ) { <nl> + av_log ( s , AV_LOG_ERROR , " Bad seek table size \ n "); <nl> + return ; <nl> + } <nl> if (!( buf = av_malloc ( size + FF_INPUT_BUFFER_PADDING_SIZE ))) <nl> return ; <nl> avio_read ( s -> pb , buf , size );
static int read_access_unit ( AVCodecContext * avctx , void * data , <nl> int ret ; <nl>  <nl> if ( buf_size < 4 ) <nl> - return 0 ; <nl> + return AVERROR_INVALIDDATA ; <nl>  <nl> length = ( AV_RB16 ( buf ) & 0xfff ) * 2 ; <nl> 
static int nist_read_header ( AVFormatContext * s ) <nl> { <nl> char buffer [ 32 ], coding [ 32 ] = " pcm ", format [ 32 ] = " 01 "; <nl> int bps = 0 , be = 0 ; <nl> - int32_t header_size ; <nl> + int32_t header_size = - 1 ; <nl> AVStream * st ; <nl>  <nl> st = avformat_new_stream ( s , NULL );
static int query_formats ( AVFilterContext * ctx ) <nl> main_formats = ff_make_format_list ( main_pix_fmts_rgb ); <nl> overlay_formats = ff_make_format_list ( overlay_pix_fmts_rgb ); <nl> break ; <nl> + default : <nl> + av_assert0 ( 0 ); <nl> } <nl>  <nl> ff_formats_ref ( main_formats , & ctx -> inputs [ MAIN ]-> out_formats );
static int mpeg4_decode_sprite_trajectory ( Mpeg4DecContext * ctx , GetBitContext * g <nl> int a = 2 << s -> sprite_warping_accuracy ; <nl> int rho = 3 - s -> sprite_warping_accuracy ; <nl> int r = 16 / a ; <nl> - int alpha = 0 ; <nl> + int alpha = 1 ; <nl> int beta = 0 ; <nl> int w = s -> width ; <nl> int h = s -> height ;
PCA * ff_pca_init ( int n ){ <nl> if ( n <= 0 ) <nl> return NULL ; <nl>  <nl> - pca = av_mallocz ( sizeof ( PCA )); <nl> + pca = av_mallocz ( sizeof (* pca )); <nl> pca -> n = n ; <nl> pca -> z = av_malloc ( sizeof (* pca -> z ) * n ); <nl> pca -> count = 0 ;
static int ff_vp56_decode_mbs ( AVCodecContext * avctx , void * data , <nl> int ret = vp56_decode_mb ( s , mb_row , mb_col , is_alpha ); <nl> if ( ret < 0 ) { <nl> damaged = 1 ; <nl> - if (! s -> have_undamaged_frame ) { <nl> + if (! s -> have_undamaged_frame || ! avctx -> error_concealment ) { <nl> s -> discard_frame = 1 ; <nl> return AVERROR_INVALIDDATA ; <nl> }
int ff_jpegls_decode_picture ( MJpegDecodeContext * s , int near , <nl> else <nl> shift = point_transform + ( 16 - s -> bits ); <nl>  <nl> + if ( shift >= 16 ) { <nl> + ret = AVERROR_INVALIDDATA ; <nl> + goto end ; <nl> + } <nl> + <nl> if ( s -> avctx -> debug & FF_DEBUG_PICT_INFO ) { <nl> av_log ( s -> avctx , AV_LOG_DEBUG , <nl> " JPEG - LS params : % ix % i NEAR =% i MV =% i T (% i ,% i ,% i ) "
static inline int get_ur_golomb_jpegls ( GetBitContext * gb , int k , int limit , int <nl> } else { <nl> int i ; <nl> for ( i = 0 ; SHOW_UBITS ( re , gb , 1 ) == 0 ; i ++){ <nl> + if ( get_bits_left ( gb )<= 0 ) <nl> + return - 1 ; <nl> LAST_SKIP_BITS ( re , gb , 1 ); <nl> UPDATE_CACHE ( re , gb ); <nl> }
recover : <nl> pes_flags = avio_rb16 ( pb ); <nl> pes_header_data_length = avio_r8 ( pb ); <nl>  <nl> + if ( avio_feof ( pb )) { <nl> + return AVERROR_EOF ; <nl> + } <nl> + <nl> if ( pes_signal != 1 || pes_header_data_length == 0 ) { <nl> pva_log ( s , AV_LOG_WARNING , " expected non empty signaled PES packet , " <nl> " trying to recover \ n ");
int ff_j2k_dwt_init ( DWTContext * s , uint16_t border [ 2 ][ 2 ], int decomp_levels , int <nl> int i , j , lev = decomp_levels , maxlen , <nl> b [ 2 ][ 2 ]; <nl>  <nl> - if ( decomp_levels >= FF_DWT_MAX_DECLVLS ) <nl> + if (( unsigned ) decomp_levels >= FF_DWT_MAX_DECLVLS ) <nl> return AVERROR_INVALIDDATA ; <nl> s -> ndeclevels = decomp_levels ; <nl> s -> type = type ;
static int vobsub_read_header ( AVFormatContext * s ) <nl>  <nl> while (* p == ' ') <nl> p ++; <nl> - av_log ( s , AV_LOG_DEBUG , " IDX stream [% d ] name =% s \ n ", st -> id , p ); <nl> + av_log ( s , AV_LOG_DEBUG , " IDX stream [% d ] name =% s \ n ", stream_id , p ); <nl> av_strlcpy ( alt , p , sizeof ( alt )); <nl> header_parsed = 1 ; <nl> 
static av_always_inline av_const int avpriv_isnan ( double x ) <nl> uint64_t v = av_double2int ( x ); <nl> if (( v & 0x7ff0000000000000 ) != 0x7ff0000000000000 ) <nl> return 0 ; <nl> - return v & 0x000fffffffffffff ; <nl> + return ( v & 0x000fffffffffffff ) && 1 ; <nl> } <nl>  <nl> # define isnan ( x ) \
static void search_for_ms_mips ( AACEncContext * s , ChannelElement * cpe ) <nl> # endif /* HAVE_INLINE_ASM */ <nl>  <nl> void ff_aac_coder_init_mips ( AACEncContext * c ) { <nl> -# if HAVE_INLINE_ASM <nl> +# if 0 // HAVE_INLINE_ASM <nl> AACCoefficientsEncoder * e = c -> coder ; <nl> int option = c -> options . aac_coder ; <nl> 
void mpeg1_init_vlc ( MpegEncContext * s ) <nl> static int done = 0 ; <nl>  <nl> if (! done ) { <nl> + done = 1 ; <nl>  <nl> init_vlc (& dc_lum_vlc , 9 , 12 , <nl> vlc_dc_lum_bits , 1 , 1 ,
static int64_t mmsh_seek ( URLContext * h , int64_t pos , int whence ) <nl> MMSContext * mms = & mmsh -> mms ; <nl>  <nl> if ( pos == 0 && whence == SEEK_CUR ) <nl> - return mms -> asf_header_read_size + mms -> remaining_in_len + mmsh -> chunk_seq * mms -> asf_packet_len ; <nl> + return mms -> asf_header_read_size + mms -> remaining_in_len + mmsh -> chunk_seq * ( int64_t ) mms -> asf_packet_len ; <nl> return AVERROR ( ENOSYS ); <nl> } <nl> 
static av_cold int svq3_decode_init ( AVCodecContext * avctx ) <nl> int offset = ( get_bits_count (& gb )+ 7 )>> 3 ; <nl> uint8_t * buf ; <nl>  <nl> - if (( uint64_t ) watermark_width * 4 > UINT_MAX / watermark_height ) <nl> + if ( watermark_height <= 0 || ( uint64_t ) watermark_width * 4 > UINT_MAX / watermark_height ) <nl> return - 1 ; <nl>  <nl> buf = av_malloc ( buf_len );
int ff_hevc_decode_nal_vps ( HEVCContext * s ) <nl> if ( get_bits_left ( gb ) < 0 ) { <nl> av_log ( s -> avctx , AV_LOG_ERROR , <nl> " Overread VPS by % d bits \ n ", - get_bits_left ( gb )); <nl> - goto err ; <nl> + if ( s -> vps_list [ vps_id ]) <nl> + goto err ; <nl> } <nl>  <nl> if ( s -> vps_list [ vps_id ] &&
static int transcode ( OutputFile * output_files , <nl> int64_t ipts_min ; <nl> double opts_min ; <nl>  <nl> - redo : <nl> ipts_min = INT64_MAX ; <nl> opts_min = 1e100 ; <nl>  <nl> static int transcode ( OutputFile * output_files , <nl> if ( exit_on_error ) <nl> exit_program ( 1 ); <nl> av_free_packet (& pkt ); <nl> - goto redo ; <nl> + continue ; <nl> } <nl>  <nl> discard_packet :
static int gxf_write_packet ( AVFormatContext * s , AVPacket * pkt ) <nl> gxf -> flt_entries_nb + 500 , <nl> sizeof (* gxf -> flt_entries ))) < 0 ) { <nl> gxf -> flt_entries_nb = 0 ; <nl> + gxf -> nb_fields = 0 ; <nl> av_log ( s , AV_LOG_ERROR , " could not reallocate flt entries \ n "); <nl> return err ; <nl> }
static int vc1_decode_frame ( AVCodecContext * avctx , void * data , <nl> goto err ; <nl> } <nl>  <nl> + if (( s -> mb_height >> v -> field_mode ) == 0 ) { <nl> + av_log ( v -> s . avctx , AV_LOG_ERROR , " image too short \ n "); <nl> + goto err ; <nl> + } <nl> + <nl> // process pulldown flags <nl> s -> current_picture_ptr -> f . repeat_pict = 0 ; <nl> // Pulldown flags are only valid when ' broadcast ' has been set .
static int theora_decode_header ( AVCodecContext * avctx , GetBitContext * gb ) <nl>  <nl> fps . num = get_bits_long ( gb , 32 ); <nl> fps . den = get_bits_long ( gb , 32 ); <nl> - if ( fps . num && fps . den ) { <nl> + if ( fps . num > 0 && fps . den > 0 ) { <nl> av_reduce (& avctx -> time_base . num , & avctx -> time_base . den , <nl> fps . den , fps . num , 1 << 30 ); <nl> }
int av_write_trailer ( AVFormatContext * s ) <nl> if ( s -> oformat -> write_trailer ) <nl> ret = s -> oformat -> write_trailer ( s ); <nl>  <nl> - if (!( s -> oformat -> flags & AVFMT_NOFILE )) <nl> - avio_flush ( s -> pb ); <nl> - <nl> fail : <nl> if ( s -> pb ) <nl> avio_flush ( s -> pb );
static int speex_header ( AVFormatContext * s , int idx ) { <nl> if ( frames_per_packet ) <nl> spxp -> packet_size *= frames_per_packet ; <nl>  <nl> - ff_alloc_extradata ( st -> codec , os -> psize ); <nl> + if ( ff_alloc_extradata ( st -> codec , os -> psize ) < 0 ) <nl> + return AVERROR ( ENOMEM ); <nl> memcpy ( st -> codec -> extradata , p , st -> codec -> extradata_size ); <nl>  <nl> avpriv_set_pts_info ( st , 64 , 1 , st -> codec -> sample_rate );
static int av_encode ( AVFormatContext ** output_files , <nl> break ; <nl> case CODEC_TYPE_VIDEO : <nl> data_size = ( ist -> st -> codec . width * ist -> st -> codec . height * 3 ) / 2 ; <nl> + /* XXX : allocate picture correctly */ <nl> + memset (& picture , 0 , sizeof ( picture )); <nl> ret = avcodec_decode_video (& ist -> st -> codec , <nl> & picture , & got_picture , ptr , len ); <nl> ist -> st -> quality = picture . quality ;
static int read_filter_params ( MLPDecodeContext * m , GetBitContext * gbp , <nl> /* TODO : Check validity of state data . */ <nl>  <nl> for ( i = 0 ; i < order ; i ++) <nl> - fp -> state [ i ] = state_bits ? get_sbits ( gbp , state_bits ) << state_shift : 0 ; <nl> + fp -> state [ i ] = state_bits ? get_sbits ( gbp , state_bits ) * ( 1 << state_shift ) : 0 ; <nl> } <nl> } <nl> 
static void term_init ( void ) <nl> # if HAVE_TERMIOS_H <nl> if (! run_as_daemon ){ <nl> struct termios tty ; <nl> - <nl> +# if HAVE_ISATTY <nl> + if ( isatty ( 0 ) && isatty ( 2 )) <nl> +# endif <nl> if ( tcgetattr ( 0 , & tty ) == 0 ) { <nl> oldtty = tty ; <nl> restore_tty = 1 ;
static void mpc8_parse_seektable ( AVFormatContext * s , int64_t off ) <nl> if (!( buf = av_malloc ( size + FF_INPUT_BUFFER_PADDING_SIZE ))) <nl> return ; <nl> avio_read ( s -> pb , buf , size ); <nl> + memset ( buf + size , 0 , FF_INPUT_BUFFER_PADDING_SIZE ); <nl> + <nl> init_get_bits (& gb , buf , size * 8 ); <nl> size = gb_get_v (& gb ); <nl> if ( size > UINT_MAX / 4 || size > c -> samples / 1152 ){
static int wma_decode_block ( WMACodecContext * s ) <nl> coef escape coding */ <nl> total_gain = 1 ; <nl> for (;;) { <nl> + if ( get_bits_left (& s -> gb ) < 7 ) { <nl> + av_log ( s -> avctx , AV_LOG_ERROR , " total_gain overread \ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> a = get_bits (& s -> gb , 7 ); <nl> total_gain += a ; <nl> if ( a != 127 )
static int read_connect ( URLContext * s , RTMPContext * rt ) <nl> return ret ; <nl>  <nl> // Chunk size <nl> - if (( ret = ff_rtmp_packet_create (& pkt , RTMP_SYSTEM_CHANNEL , <nl> + if (( ret = ff_rtmp_packet_create (& pkt , RTMP_NETWORK_CHANNEL , <nl> RTMP_PT_CHUNK_SIZE , 0 , 4 )) < 0 ) <nl> return ret ; <nl> 
int av_dict_set ( AVDictionary ** pm , const char * key , const char * value , <nl> m = * pm = av_mallocz ( sizeof (* m )); <nl>  <nl> if ( tag ) { <nl> - if ( flags & AV_DICT_DONT_OVERWRITE ) <nl> + if ( flags & AV_DICT_DONT_OVERWRITE ) { <nl> + if ( flags & AV_DICT_DONT_STRDUP_KEY ) av_free ( key ); <nl> + if ( flags & AV_DICT_DONT_STRDUP_VAL ) av_free ( value ); <nl> return 0 ; <nl> + } <nl> if ( flags & AV_DICT_APPEND ) <nl> oldval = tag -> value ; <nl> else
typedef struct { <nl>  <nl> typedef struct { <nl> int64_t frames_hdr_strm ; <nl> - int audio_strm_length ; <nl> + int64_t audio_strm_length ; <nl> int packet_count ; <nl> int entry ; <nl> 
int32_t ff_mlp_pack_output ( int32_t lossless_check_data , <nl> ( 1U << output_shift [ mat_ch ]); <nl> lossless_check_data ^= ( sample & 0xffffff ) << mat_ch ; <nl> if ( is32 ) <nl> - * data_32 ++ = sample << 8 ; <nl> + * data_32 ++ = sample * 256 ; <nl> else <nl> * data_16 ++ = sample >> 8 ; <nl> }
static int get_video_frame ( VideoState * is , AVFrame * frame , int64_t * pts , AVPacke <nl> is -> frame_last_dropped_pos = pkt -> pos ; <nl> is -> frame_last_dropped_pts = dpts ; <nl> is -> frame_drops_early ++; <nl> + av_frame_unref ( frame ); <nl> ret = 0 ; <nl> } <nl> }
static int decompress_p ( AVCodecContext * avctx , <nl> return ret ; <nl>  <nl> max += temp << 8 ; <nl> + if ( min > max ) <nl> + return AVERROR_INVALIDDATA ; <nl> + <nl> memset ( s -> blocks , 0 , sizeof (* s -> blocks ) * s -> nbcount ); <nl>  <nl> while ( min <= max ) {
int ff_mov_read_stsd_entries ( MOVContext * c , AVIOContext * pb , int entries ) <nl> avio_rb32 ( pb ); /* reserved */ <nl> avio_rb16 ( pb ); /* reserved */ <nl> dref_id = avio_rb16 ( pb ); <nl> + } else if ( size <= 0 ){ <nl> + av_log ( c -> fc , AV_LOG_ERROR , " invalid size % d in stsd \ n ", size ); <nl> + return - 1 ; <nl> } <nl>  <nl> if ( st -> codec -> codec_tag &&
static void smc_decode_stream ( SmcContext * s ) <nl> row_ptr , image_size ); <nl> return ; <nl> } <nl> + if ( bytestream2_get_bytes_left (& s -> gb ) < 1 ) { <nl> + av_log ( s -> avctx , AV_LOG_ERROR , " input too small \ n "); <nl> + return ; <nl> + } <nl>  <nl> opcode = bytestream2_get_byte (& s -> gb ); <nl> switch ( opcode & 0xF0 ) {
static int img_read_header ( AVFormatContext * s1 ) <nl> s -> img_last = last_index ; <nl> s -> img_number = first_index ; <nl> /* compute duration */ <nl> - st -> start_time = 0 ; <nl> - st -> duration = last_index - first_index + 1 ; <nl> + if (! s -> ts_from_file ) { <nl> + st -> start_time = 0 ; <nl> + st -> duration = last_index - first_index + 1 ; <nl> + } <nl> } <nl>  <nl> if ( s1 -> video_codec_id ) {
static inline void copy ( LZOContext * c , int cnt ) <nl> */ <nl> static inline void copy_backptr ( LZOContext * c , int back , int cnt ) <nl> { <nl> - register const uint8_t * src = & c -> out [- back ]; <nl> register uint8_t * dst = c -> out ; <nl> - if ( src < c -> out_start || src > dst ) { <nl> + if ( dst - c -> out_start < back ) { <nl> c -> error |= AV_LZO_INVALID_BACKPTR ; <nl> return ; <nl> }
static int mxf_read_seek ( AVFormatContext * s , int stream_index , int64_t sample_ti <nl> sample_time = FFMIN ( sample_time , source_track -> original_duration - 1 ); <nl> } <nl>  <nl> - if (( ret = mxf_edit_unit_absolute_offset ( mxf , t , sample_time , & sample_time , & seekpos , 1 )) << 0 ) <nl> + if (( ret = mxf_edit_unit_absolute_offset ( mxf , t , sample_time , & sample_time , & seekpos , 1 )) < 0 ) <nl> return ret ; <nl>  <nl> ff_update_cur_dts ( s , st , sample_time );
static int mov_finalize_stsd_codec ( MOVContext * c , AVIOContext * pb , <nl>  <nl> static int mov_skip_multiple_stsd ( MOVContext * c , AVIOContext * pb , <nl> int codec_tag , int format , <nl> - int size ) <nl> + int64_t size ) <nl> { <nl> int video_codec_id = ff_codec_get_id ( ff_codec_movvideo_tags , format ); <nl> 
static int http_read_stream ( URLContext * h , uint8_t * buf , int size ) <nl>  <nl> av_log ( NULL , AV_LOG_TRACE , " Chunked encoding data size : %" PRId64 "'\ n ", <nl> s -> chunksize ); <nl> - <nl> - if (! s -> chunksize ) <nl> + if ( s -> chunksize < 0 ) <nl> + return AVERROR_INVALIDDATA ; <nl> + else if (! s -> chunksize ) <nl> return 0 ; <nl> break ; <nl> }
static int channelmap_filter_samples ( AVFilterLink * inlink , AVFilterBufferRef * bu <nl> if ( buf -> extended_data == buf -> data ) { <nl> buf -> extended_data = new_extended_data ; <nl> } else { <nl> - buf -> extended_data = new_extended_data ; <nl> av_free ( buf -> extended_data ); <nl> + buf -> extended_data = new_extended_data ; <nl> } <nl> } else if ( buf -> extended_data != buf -> data ) { <nl> av_free ( buf -> extended_data );
static int check_n_master ( AVCodecContext * avctx , int n_master , int bs_xover_band <nl> static int sbr_make_f_master ( AACContext * ac , SpectralBandReplication * sbr , <nl> SpectrumParameters * spectrum ) <nl> { <nl> - unsigned int temp , max_qmf_subbands ; <nl> + unsigned int temp , max_qmf_subbands = 0 ; <nl> unsigned int start_min , stop_min ; <nl> int k ; <nl> const int8_t * sbr_offset_ptr ;
static int tak_decode_frame ( AVCodecContext * avctx , void * data , <nl>  <nl> if ( s -> sample_shift [ chan ] > 0 ) <nl> for ( i = 0 ; i < s -> nb_samples ; i ++) <nl> - decoded [ i ] <<= s -> sample_shift [ chan ]; <nl> + decoded [ i ] *= 1 << s -> sample_shift [ chan ]; <nl> } <nl> } <nl> 
the_end : <nl> } <nl> } <nl> } <nl> - if ( s -> flipped ) { <nl> + if ( s -> flipped && ! s -> rgb ) { <nl> int j ; <nl> avcodec_get_chroma_sub_sample ( s -> avctx -> pix_fmt , & hshift , & vshift ); <nl> av_assert0 ( s -> nb_components == av_pix_fmt_count_planes ( s -> picture_ptr -> format ));
static int mpeg_decode_slice ( MpegEncContext * s , int mb_y , <nl> if ( mb_y == 0 && s -> codec_tag == AV_RL32 (" SLIF ")) { <nl> skip_bits1 (& s -> gb ); <nl> } else { <nl> - for (;;) { <nl> + while ( get_bits_left (& s -> gb ) > 0 ) { <nl> int code = get_vlc2 (& s -> gb , mbincr_vlc . table , MBINCR_VLC_BITS , 2 ); <nl> if ( code < 0 ) { <nl> av_log ( s -> avctx , AV_LOG_ERROR , " first mb_incr damaged \ n ");
static int vorbis_parse ( AVCodecParserContext * s1 , AVCodecContext * avctx , <nl>  <nl> if (! s -> vp && avctx -> extradata && avctx -> extradata_size ) { <nl> s -> vp = av_vorbis_parse_init ( avctx -> extradata , avctx -> extradata_size ); <nl> - if (! s -> vp ) <nl> - goto end ; <nl> } <nl> + if (! s -> vp ) <nl> + goto end ; <nl>  <nl> if (( duration = av_vorbis_parse_frame ( s -> vp , buf , buf_size )) >= 0 ) <nl> s1 -> duration = duration ;
static int vaapi_encode_h264_init_sequence_params ( AVCodecContext * avctx ) <nl>  <nl> vseq -> level_idc = avctx -> level ; <nl>  <nl> - vseq -> max_num_ref_frames = 2 ; <nl> + vseq -> max_num_ref_frames = 1 + ( avctx -> max_b_frames > 0 ); <nl>  <nl> vseq -> picture_width_in_mbs = priv -> mb_width ; <nl> vseq -> picture_height_in_mbs = priv -> mb_height ;
static int escape124_decode_frame ( AVCodecContext * avctx , <nl> cb_size = s -> num_superblocks << cb_depth ; <nl> } <nl> } <nl> + if ( s -> num_superblocks >= INT_MAX >> cb_depth ) { <nl> + av_log ( avctx , AV_LOG_ERROR , " Depth or num_superblocks are too large \ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> + <nl> av_freep (& s -> codebooks [ i ]. blocks ); <nl> s -> codebooks [ i ] = unpack_codebook (& gb , cb_depth , cb_size ); <nl> if (! s -> codebooks [ i ]. blocks )
static int mov_text_decode_frame ( AVCodecContext * avctx , <nl> m -> size_var = 8 ; <nl> // size_var is equal to 8 or 16 depending on the size of box <nl>  <nl> - if ( m -> tracksize + tsmb_size > avpkt -> size ) <nl> + if ( tsmb_size > avpkt -> size - m -> tracksize ) <nl> break ; <nl>  <nl> for ( size_t i = 0 ; i < box_count ; i ++) {
static int adts_aac_read_packet ( AVFormatContext * s , AVPacket * pkt ) <nl> return AVERROR_INVALIDDATA ; <nl> } <nl>  <nl> - return av_append_packet ( s -> pb , pkt , fsize - ADTS_HEADER_SIZE ); <nl> + ret = av_append_packet ( s -> pb , pkt , fsize - ADTS_HEADER_SIZE ); <nl> + if ( ret < 0 ) <nl> + av_packet_unref ( pkt ); <nl> + <nl> + return ret ; <nl> } <nl>  <nl> AVInputFormat ff_aac_demuxer = {
retry : <nl> } else { <nl> level = SHOW_UBITS ( re , & s -> gb , 5 ); <nl> SKIP_CACHE ( re , & s -> gb , 5 ); <nl> - level |= SHOW_SBITS ( re , & s -> gb , 6 )<< 5 ; <nl> + level |= SHOW_SBITS ( re , & s -> gb , 6 ) * ( 1 << 5 ); <nl> SKIP_COUNTER ( re , & s -> gb , 5 + 6 ); <nl> } <nl> }
static void get_attachment ( AVFormatContext * s , AVIOContext * pb , int length ) <nl> st -> codec -> codec_id = AV_CODEC_ID_MJPEG ; <nl> st -> codec -> codec_type = AVMEDIA_TYPE_ATTACHMENT ; <nl> st -> codec -> extradata = av_mallocz ( filesize ); <nl> + st -> id = - 1 ; <nl> if (! st -> codec -> extradata ) <nl> goto done ; <nl> st -> codec -> extradata_size = filesize ;
static int cache_read ( URLContext * h , unsigned char * buf , int size ) <nl> { <nl> Context * c = h -> priv_data ; <nl> CacheEntry * entry , * next [ 2 ] = { NULL , NULL }; <nl> - int r ; <nl> + int64_t r ; <nl>  <nl> entry = av_tree_find ( c -> root , & c -> logical_pos , cmp , ( void **) next ); <nl> 
static int decode_pic_hdr ( IVI45DecContext * ctx , AVCodecContext * avctx ) <nl>  <nl> /* decode subdivision of the planes */ <nl> pic_conf . luma_bands = decode_plane_subdivision (& ctx -> gb ); <nl> + pic_conf . chroma_bands = 0 ; <nl> if ( pic_conf . luma_bands ) <nl> pic_conf . chroma_bands = decode_plane_subdivision (& ctx -> gb ); <nl> ctx -> is_scalable = pic_conf . luma_bands != 1 || pic_conf . chroma_bands != 1 ;
static int tm2_read_stream ( TM2Context * ctx , const uint8_t * buf , int stream_id , i <nl> if ( len == 0 ) <nl> return 4 ; <nl>  <nl> - if ( len >= INT_MAX / 4 - 1 || len < 0 || len > buf_size ) { <nl> + if ( len >= INT_MAX / 4 - 1 || len < 0 || skip > buf_size ) { <nl> av_log ( ctx -> avctx , AV_LOG_ERROR , " Error , invalid stream size .\ n "); <nl> return - 1 ; <nl> }
static void free_stream ( AVStream ** pst ) <nl> av_freep (& st -> index_entries ); <nl> # if FF_API_LAVF_AVCTX <nl> FF_DISABLE_DEPRECATION_WARNINGS <nl> - av_freep (& st -> codec -> extradata ); <nl> - av_freep (& st -> codec -> subtitle_header ); <nl> - av_freep (& st -> codec ); <nl> + avcodec_free_context (& st -> codec ); <nl> FF_ENABLE_DEPRECATION_WARNINGS <nl> # endif <nl> av_freep (& st -> priv_data );
void av_dump_format ( AVFormatContext * ic , <nl> int is_output ) <nl> { <nl> int i ; <nl> - uint8_t * printed = av_mallocz ( ic -> nb_streams ); <nl> + uint8_t * printed = ic -> nb_streams ? av_mallocz ( ic -> nb_streams ) : NULL ; <nl> if ( ic -> nb_streams && ! printed ) <nl> return ; <nl> 
int avpriv_ac3_parse_header ( AC3HeaderInfo ** phdr , const uint8_t * buf , <nl> return AVERROR ( ENOMEM ); <nl> hdr = * phdr ; <nl>  <nl> - init_get_bits8 (& gb , buf , size ); <nl> + err = init_get_bits8 (& gb , buf , size ); <nl> + if ( err < 0 ) <nl> + return AVERROR_INVALIDDATA ; <nl> err = ff_ac3_parse_header (& gb , hdr ); <nl> if ( err < 0 ) <nl> return AVERROR_INVALIDDATA ;
retry : <nl> if ( c -> itunes_metadata && atom . size > 8 ) { <nl> int data_size = avio_rb32 ( pb ); <nl> int tag = avio_rl32 ( pb ); <nl> - if ( tag == MKTAG (' d ',' a ',' t ',' a ')) { <nl> + if ( tag == MKTAG (' d ',' a ',' t ',' a ') && data_size <= atom . size ) { <nl> data_type = avio_rb32 ( pb ); // type <nl> avio_rb32 ( pb ); // unknown <nl> str_size = data_size - 16 ;
static int applehttp_read_header ( AVFormatContext * s , AVFormatParameters * ap ) <nl> /* If this isn ' t a live stream , calculate the total duration of the <nl> * stream . */ <nl> if ( c -> finished ) { <nl> - int duration = 0 ; <nl> + int64_t duration = 0 ; <nl> for ( i = 0 ; i < c -> variants [ 0 ]-> n_segments ; i ++) <nl> duration += c -> variants [ 0 ]-> segments [ i ]-> duration ; <nl> s -> duration = duration * AV_TIME_BASE ;
static int libopenjpeg_decode_frame ( AVCodecContext * avctx , <nl> // Decode the codestream <nl> image = opj_decode_with_info ( dec , stream , NULL ); <nl> opj_cio_close ( stream ); <nl> + if (! image ) { <nl> + av_log ( avctx , AV_LOG_ERROR , " Error decoding codestream .\ n "); <nl> + opj_destroy_decompress ( dec ); <nl> + return - 1 ; <nl> + } <nl>  <nl> pixel_size = av_pix_fmt_descriptors [ avctx -> pix_fmt ]. comp [ 0 ]. step_minus1 + 1 ; <nl> ispacked = libopenjpeg_ispacked ( avctx -> pix_fmt );
int ff_mjpeg_decode_sof ( MJpegDecodeContext * s ) <nl> else s -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P16 ; <nl> s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG ; <nl> if ( pix_fmt_id == 0x42111100 ) { <nl> + if ( s -> bits > 8 ) <nl> + goto unk_pixfmt ; <nl> s -> upscale_h = 6 ; <nl> } else if ( pix_fmt_id == 0x24111100 ) { <nl> + if ( s -> bits > 8 ) <nl> + goto unk_pixfmt ; <nl> s -> upscale_v = 6 ; <nl> } <nl> break ;
static int sbr_make_f_master ( AACContext * ac , SpectralBandReplication * sbr , <nl> max_qmf_subbands = 35 ; <nl> } else if ( sbr -> sample_rate >= 48000 ) <nl> max_qmf_subbands = 32 ; <nl> + else <nl> + av_assert0 ( 0 ); <nl>  <nl> if ( sbr -> k [ 2 ] - sbr -> k [ 0 ] > max_qmf_subbands ) { <nl> av_log ( ac -> avctx , AV_LOG_ERROR ,
static int wsvqa_read_packet ( AVFormatContext * s , <nl> switch ( chunk_type ) { <nl> case SND1_TAG : <nl> /* unpacked size is stored in header */ <nl> - pkt -> duration = AV_RL16 ( pkt -> data ) / wsvqa -> channels ; <nl> + if ( pkt -> data ) <nl> + pkt -> duration = AV_RL16 ( pkt -> data ) / wsvqa -> channels ; <nl> break ; <nl> case SND2_TAG : <nl> /* 2 samples / byte , 1 or 2 samples per frame depending on stereo */
static int decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , AVPac <nl> c -> fmt = buf [ 3 ]; <nl> c -> bw = buf [ 4 ]; <nl> c -> bh = buf [ 5 ]; <nl> + c -> decode_intra = NULL ; <nl> + c -> decode_xor = NULL ; <nl>  <nl> buf += 6 ; <nl> len -= 6 ;
static int tm2_build_huff_table ( TM2Context * ctx , TM2Codes * code ) <nl> huff . val_bits , huff . max_bits ); <nl> return - 1 ; <nl> } <nl> - if (( huff . nodes < 0 ) || ( huff . nodes > 0x10000 )) { <nl> + if (( huff . nodes <= 0 ) || ( huff . nodes > 0x10000 )) { <nl> av_log ( ctx -> avctx , AV_LOG_ERROR , " Incorrect number of Huffman tree nodes : % i \ n ", huff . nodes ); <nl> return - 1 ; <nl> }
static int vqf_read_header ( AVFormatContext * s ) <nl> break ; <nl> default : <nl> st -> codec -> sample_rate = rate_flag * 1000 ; <nl> + if ( st -> codec -> sample_rate <= 0 ) { <nl> + av_log ( s , AV_LOG_ERROR , " sample rate % d is invalid \ n ", st -> codec -> sample_rate ); <nl> + return - 1 ; <nl> + } <nl> break ; <nl> } <nl> 
static int decode_audio_specific_config ( AACContext * ac , <nl> */ <nl> static av_always_inline int lcg_random ( int previous_val ) <nl> { <nl> - return previous_val * 1664525 + 1013904223 ; <nl> + union { unsigned u ; int s ; } v = { previous_val * 1664525u + 1013904223 }; <nl> + return v . s ; <nl> } <nl>  <nl> static av_always_inline void reset_predict_state ( PredictorState * ps )
static inline void xan_wc3_copy_pixel_run ( XanContext * s , AVFrame * frame , <nl> prevframe_index = ( y + motion_y ) * stride + x + motion_x ; <nl> prevframe_x = x + motion_x ; <nl>  <nl> - if ( prev_palette_plane == palette_plane && FFABS ( curframe_index - prevframe_index ) < pixel_count ) { <nl> + if ( prev_palette_plane == palette_plane && FFABS ( motion_x + width * motion_y ) < pixel_count ) { <nl> avpriv_request_sample ( s -> avctx , " Overlapping copy "); <nl> return ; <nl> }
int attribute_align_arg avcodec_decode_audio4 ( AVCodecContext * avctx , <nl> * extended_data are doing it correctly */ <nl> if (* got_frame_ptr ) { <nl> planar = av_sample_fmt_is_planar ( frame -> format ); <nl> - channels = av_get_channel_layout_nb_channels ( frame -> channel_layout ); <nl> + channels = frame -> channels ; <nl> if (!( planar && channels > AV_NUM_DATA_POINTERS )) <nl> frame -> extended_data = frame -> data ; <nl> } else {
static int cdxl_read_packet ( AVFormatContext * s , AVPacket * pkt ) <nl> av_free_packet ( pkt ); <nl> return ret ; <nl> } <nl> + av_shrink_packet ( pkt , CDXL_HEADER_SIZE + ret ); <nl> pkt -> stream_index = cdxl -> video_stream_index ; <nl> pkt -> flags |= AV_PKT_FLAG_KEY ; <nl> pkt -> pos = pos ;
static int mpc8_read_header ( AVFormatContext * s ) <nl> while (! avio_feof ( pb )){ <nl> pos = avio_tell ( pb ); <nl> mpc8_get_chunk_header ( pb , & tag , & size ); <nl> + if ( size < 0 ) { <nl> + av_log ( s , AV_LOG_ERROR , " Invalid chunk length \ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> if ( tag == TAG_STREAMHDR ) <nl> break ; <nl> mpc8_handle_chunk ( s , tag , pos , size );
static void stream_pause ( VideoState * is ) <nl>  <nl> static double compute_target_time ( double frame_current_pts , VideoState * is ) <nl> { <nl> - double delay , sync_threshold , diff ; <nl> + double delay , sync_threshold , diff = 0 ; <nl>  <nl> /* compute nominal delay */ <nl> delay = frame_current_pts - is -> frame_last_pts ;
static int mov_read_dref ( MOVContext * c , AVIOContext * pb , MOVAtom atom ) <nl> entries = avio_rb32 ( pb ); <nl> if ( entries >= UINT_MAX / sizeof (* sc -> drefs )) <nl> return AVERROR_INVALIDDATA ; <nl> + av_free ( sc -> drefs ); <nl> sc -> drefs = av_mallocz ( entries * sizeof (* sc -> drefs )); <nl> if (! sc -> drefs ) <nl> return AVERROR ( ENOMEM );
static int get_packet ( URLContext * s , int for_header ) <nl> } <nl> } <nl> rt -> bytes_read += ret ; <nl> - if ( rt -> bytes_read > rt -> last_bytes_read + rt -> client_report_size ) { <nl> + if ( rt -> bytes_read - rt -> last_bytes_read > rt -> client_report_size ) { <nl> av_log ( s , AV_LOG_DEBUG , " Sending bytes read report \ n "); <nl> gen_bytes_read ( s , rt , rpkt . timestamp + 1 ); <nl> rt -> last_bytes_read = rt -> bytes_read ;
AVCodec ff_ffv1_decoder = { <nl> . update_thread_context = ONLY_IF_THREADS_ENABLED ( update_thread_context ), <nl> . capabilities = AV_CODEC_CAP_DR1 /*| AV_CODEC_CAP_DRAW_HORIZ_BAND */ | <nl> AV_CODEC_CAP_FRAME_THREADS | AV_CODEC_CAP_SLICE_THREADS , <nl> + . caps_internal = FF_CODEC_CAP_INIT_CLEANUP <nl> };
static const struct URLProtocol * url_find_protocol ( const char * filename ) <nl> * ptr = '\ 0 '; <nl>  <nl> protocols = ffurl_get_protocols ( NULL , NULL ); <nl> + if (! protocols ) <nl> + return NULL ; <nl> for ( i = 0 ; protocols [ i ]; i ++) { <nl> const URLProtocol * up = protocols [ i ]; <nl> if (! strcmp ( proto_str , up -> name )) {
static int decode_block ( MJpegDecodeContext * s , int16_t * block , int component , <nl> return AVERROR_INVALIDDATA ; <nl> } <nl> val = val * quant_matrix [ 0 ] + s -> last_dc [ component ]; <nl> - val = FFMIN ( val , 32767 ); <nl> + val = av_clip_int16 ( val ); <nl> s -> last_dc [ component ] = val ; <nl> block [ 0 ] = val ; <nl> /* AC coefs */
static int adx_decode_frame ( AVCodecContext * avctx , void * data , <nl> buf += header_size ; <nl> buf_size -= header_size ; <nl> } <nl> + if ( c -> channels <= 0 ) <nl> + return AVERROR_INVALIDDATA ; <nl>  <nl> /* calculate number of blocks in the packet */ <nl> num_blocks = buf_size / ( BLOCK_SIZE * c -> channels );
again : <nl> " SPS decoding failure , trying again with the complete NAL \ n "); <nl> if ( h -> is_avc ) <nl> av_assert0 ( next_avc - buf_index + consumed == nalsize ); <nl> + if (( next_avc - buf_index + consumed - 1 ) >= INT_MAX / 8 ) <nl> + break ; <nl> init_get_bits (& s -> gb , & buf [ buf_index + 1 - consumed ], <nl> 8 *( next_avc - buf_index + consumed - 1 )); <nl> ff_h264_decode_seq_parameter_set ( h );
static void swap_guid ( ff_asf_guid guid ) <nl>  <nl> static void align_position ( AVIOContext * pb , int64_t offset , uint64_t size ) <nl> { <nl> - if ( avio_tell ( pb ) != offset + size ) <nl> + if ( size < INT64_MAX - offset && avio_tell ( pb ) != offset + size ) <nl> avio_seek ( pb , offset + size , SEEK_SET ); <nl> } <nl> 
static void estimate_timings_from_bit_rate ( AVFormatContext * ic ) <nl> for ( i = 0 ; i < ic -> nb_streams ; i ++) { <nl> st = ic -> streams [ i ]; <nl> if ( st -> codec -> bit_rate > 0 ) { <nl> - if ( INT_MAX - st -> codec -> bit_rate > bit_rate ) { <nl> + if ( INT_MAX - st -> codec -> bit_rate < bit_rate ) { <nl> bit_rate = 0 ; <nl> break ; <nl> }
int av_reallocp ( void * ptr , size_t size ) <nl> void ** ptrptr = ptr ; <nl> void * ret ; <nl>  <nl> + if (! size ) { <nl> + av_freep ( ptr ); <nl> + return 0 ; <nl> + } <nl> ret = av_realloc (* ptrptr , size ); <nl>  <nl> if (! ret ) {
static int on2avc_decode_band_scales ( On2AVCContext * c , GetBitContext * gb ) <nl> } else { <nl> scale += get_vlc2 ( gb , c -> scale_diff . table , 9 , 3 ) - 60 ; <nl> } <nl> - if ( scale < 0 || scale > 128 ) { <nl> + if ( scale < 0 || scale > 127 ) { <nl> av_log ( c -> avctx , AV_LOG_ERROR , " Invalid scale value % d \ n ", <nl> scale ); <nl> return AVERROR_INVALIDDATA ;
static int svq3_decode_frame ( AVCodecContext * avctx , <nl> s -> next_p_frame_damaged = 0 ; <nl> } <nl>  <nl> - frame_start ( h ); <nl> + if ( frame_start ( h ) < 0 ) <nl> + return - 1 ; <nl>  <nl> if ( s -> pict_type == B_TYPE ) { <nl> h -> frame_num_offset = ( h -> slice_num - h -> prev_frame_num );
static int asfrtp_parse_packet ( AVFormatContext * s , PayloadContext * asf , <nl> int prev_len = out_len ; <nl> out_len += cur_len ; <nl> asf -> buf = av_realloc ( asf -> buf , out_len ); <nl> + if (! asf -> buf || FFMIN ( cur_len , len - off )< 0 ) <nl> + return - 1 ; <nl> memcpy ( asf -> buf + prev_len , buf + off , <nl> FFMIN ( cur_len , len - off )); <nl> avio_skip ( pb , cur_len );
static int roq_dpcm_encode_frame ( AVCodecContext * avctx , AVPacket * avpkt , <nl> context -> input_frames ++; <nl> return 0 ; <nl> } <nl> + } <nl> + if ( context -> input_frames < 8 ) { <nl> in = context -> frame_buffer ; <nl> } <nl> 
int ff_qsv_enc_init ( AVCodecContext * avctx , QSVEncContext * q ) <nl> } <nl>  <nl> ret = MFXVideoENCODE_Init ( q -> session , & q -> param ); <nl> - if ( ret < 0 ) { <nl> + if ( MFX_WRN_PARTIAL_ACCELERATION == ret ) { <nl> + av_log ( avctx , AV_LOG_WARNING , " Encoder will work with partial HW acceleration \ n "); <nl> + } else if ( ret < 0 ) { <nl> av_log ( avctx , AV_LOG_ERROR , " Error initializing the encoder \ n "); <nl> return ff_qsv_error ( ret ); <nl> }
static void dvbsub_parse_region_segment ( AVCodecContext * avctx , <nl> } <nl>  <nl> region -> depth = 1 << (((* buf ++) >> 2 ) & 7 ); <nl> + if ( region -> depth < 2 || region -> depth > 8 ){ <nl> + av_log ( avctx , AV_LOG_ERROR , " region depth % d is invalid \ n ", region -> depth ); <nl> + region -> depth = 4 ; <nl> + } <nl> region -> clut = * buf ++; <nl>  <nl> if ( region -> depth == 8 )
int av_bsf_list_parse_str ( const char * str , AVBSFContext ** bsf_lst ) <nl> if (! lst ) <nl> return AVERROR ( ENOMEM ); <nl>  <nl> - if (!( dup = buf = av_strdup ( str ))) <nl> - return AVERROR ( ENOMEM ); <nl> + if (!( dup = buf = av_strdup ( str ))) { <nl> + ret = AVERROR ( ENOMEM ); <nl> + goto end ; <nl> + } <nl>  <nl> while ( 1 ) { <nl> bsf_str = av_strtok ( buf , ",", & saveptr );
static int encode_apng ( AVCodecContext * avctx , AVPacket * pkt , <nl> int ret ; <nl> int enc_row_size ; <nl> size_t max_packet_size ; <nl> - APNGFctlChunk fctl_chunk ; <nl> + APNGFctlChunk fctl_chunk = { 0 }; <nl>  <nl> if ( pict && avctx -> codec_id == AV_CODEC_ID_APNG && s -> color_type == PNG_COLOR_TYPE_PALETTE ) { <nl> uint32_t checksum = ~ av_crc ( av_crc_get_table ( AV_CRC_32_IEEE_LE ), ~ 0U , pict -> data [ 1 ], 256 * sizeof ( uint32_t ));
static int aiff_read_packet ( AVFormatContext * s , <nl> size = st -> codecpar -> block_align ; <nl> break ; <nl> default : <nl> - size = ( MAX_SIZE / st -> codecpar -> block_align ) * st -> codecpar -> block_align ; <nl> + size = st -> codecpar -> block_align ? ( MAX_SIZE / st -> codecpar -> block_align ) * st -> codecpar -> block_align : MAX_SIZE ; <nl> } <nl> size = FFMIN ( max_size , size ); <nl> res = av_get_packet ( s -> pb , pkt , size );
static int read_sbr_grid ( AACContext * ac , SpectralBandReplication * sbr , <nl> if ( ch_data -> bs_frame_class == FIXFIX ) { <nl> idx = ch_data -> bs_num_env >> 1 ; <nl> } else if ( ch_data -> bs_frame_class & 1 ) { // FIXVAR or VARVAR <nl> - idx = ch_data -> bs_num_env - FFMAX ( bs_pointer - 1 , 1 ); <nl> + idx = ch_data -> bs_num_env - FFMAX (( int ) bs_pointer - 1 , 1 ); <nl> } else { // VARFIX <nl> if (! bs_pointer ) <nl> idx = 1 ;
static int svq1_encode_frame ( AVCodecContext * avctx , unsigned char * buf , <nl> init_put_bits (& s -> pb , buf , buf_size ); <nl>  <nl> * p = * pict ; <nl> - p -> pict_type = avctx -> frame_number % avctx -> gop_size ? P_TYPE : I_TYPE ; <nl> + p -> pict_type = avctx -> gop_size && avctx -> frame_number % avctx -> gop_size ? P_TYPE : I_TYPE ; <nl> p -> key_frame = p -> pict_type == I_TYPE ; <nl>  <nl> svq1_write_header ( s , p -> pict_type );
static int allocate_buffers ( ShortenContext * s ) <nl>  <nl> static inline unsigned int get_uint ( ShortenContext * s , int k ) <nl> { <nl> - if ( s -> version != 0 ) <nl> + if ( s -> version != 0 ) { <nl> k = get_ur_golomb_shorten (& s -> gb , ULONGSIZE ); <nl> + if ( k > 31U ) <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> return get_ur_golomb_shorten (& s -> gb , k ); <nl> } <nl> 
int ff_rtsp_make_setup_request ( AVFormatContext * s , const char * host , int port , <nl> int lower_transport , const char * real_challenge ) <nl> { <nl> RTSPState * rt = s -> priv_data ; <nl> - int rtx , j , i , err , interleave = 0 ; <nl> + int rtx = 0 , j , i , err , interleave = 0 ; <nl> RTSPStream * rtsp_st ; <nl> RTSPMessageHeader reply1 , * reply = & reply1 ; <nl> char cmd [ 2048 ];
static int mov_write_vmhd_tag ( ByteIOContext * pb ) <nl>  <nl> static int mov_write_hdlr_tag ( ByteIOContext * pb , MOVTrack * track ) <nl> { <nl> - const char * descr , * hdlr , * hdlr_type ; <nl> + const char * hdlr , * descr = NULL , * hdlr_type = NULL ; <nl> int64_t pos = url_ftell ( pb ); <nl>  <nl> if (! track ) { /* no media --> data handler */
static inline void render_line_unrolled ( intptr_t x , unsigned char y , int x1 , <nl> } <nl> } <nl>  <nl> - static void render_line ( int x0 , int y0 , int x1 , int y1 , float * buf ) <nl> + static void render_line ( int x0 , unsigned char y0 , int x1 , int y1 , float * buf ) <nl> { <nl> int dy = y1 - y0 ; <nl> int adx = x1 - x0 ;
static int vid_probe ( AVProbeData * p ) <nl> if ( AV_RL32 ( p -> buf ) != MKTAG (' V ', ' I ', ' D ', 0 )) <nl> return 0 ; <nl>  <nl> + if ( p -> buf [ 4 ] != 2 ) <nl> + return AVPROBE_SCORE_MAX / 4 ; <nl> + <nl> return AVPROBE_SCORE_MAX ; <nl> } <nl> 
sigterm_handler ( int sig ) <nl> received_nb_signals ++; <nl> term_exit_sigsafe (); <nl> if ( received_nb_signals > 3 ) <nl> - exit_program ( 123 ); <nl> + exit ( 123 ); <nl> } <nl>  <nl> void term_init ( void )
int avpriv_mpeg4audio_get_config ( MPEG4AudioConfig * c , const uint8_t * buf , <nl> GetBitContext gb ; <nl> int specific_config_bitindex ; <nl>  <nl> - if ( bit_size <= 0 ) <nl> + if ( bit_size <= 0 || init_get_bits (& gb , buf , bit_size ) < 0 ) <nl> return AVERROR_INVALIDDATA ; <nl> - <nl> - init_get_bits (& gb , buf , bit_size ); <nl> c -> object_type = get_object_type (& gb ); <nl> c -> sample_rate = get_sample_rate (& gb , & c -> sampling_index ); <nl> c -> chan_config = get_bits (& gb , 4 );
static int vorbis_decode_frame ( AVCodecContext * avctx , void * data , <nl> if (! vc -> first_frame ) { <nl> vc -> first_frame = 1 ; <nl> * got_frame_ptr = 0 ; <nl> + av_frame_unref ( frame ); <nl> return buf_size ; <nl> } <nl> 
static inline int mpeg1_fast_decode_block_inter ( MpegEncContext * s , int16_t * bloc <nl> } <nl>  <nl> block [ j ] = level ; <nl> - if ((( int32_t ) GET_CACHE ( re , & s -> gb )) <= ( int32_t ) 0xBFFFFFFF ) <nl> + if ((( int32_t ) GET_CACHE ( re , & s -> gb )) <= ( int32_t ) 0xBFFFFFFF || i >= 64 ) <nl> break ; <nl> UPDATE_CACHE ( re , & s -> gb ); <nl> }
static int msmpeg4v34_decode_mb ( MpegEncContext * s , int16_t block [ 6 ][ 64 ]) <nl> uint8_t * coded_val ; <nl> uint32_t * const mb_type_ptr = & s -> current_picture . mb_type [ s -> mb_x + s -> mb_y * s -> mb_stride ]; <nl>  <nl> + if ( get_bits_left (& s -> gb ) <= 0 ) <nl> + return AVERROR_INVALIDDATA ; <nl> + <nl> if ( s -> pict_type == AV_PICTURE_TYPE_P ) { <nl> if ( s -> use_skip_mb_code ) { <nl> if ( get_bits1 (& s -> gb )) {
static int parse_timestamp ( struct sbg_parser * p , <nl>  <nl> static int parse_fade ( struct sbg_parser * p , struct sbg_fade * fr ) <nl> { <nl> - struct sbg_fade f ; <nl> + struct sbg_fade f = { 0 }; <nl>  <nl> if ( lex_char ( p , '<')) <nl> f . in = SBG_FADE_SILENCE ;
static int svq1_decode_frame ( AVCodecContext * avctx , void * data , <nl> } <nl>  <nl> * pict = s -> current_picture . f ; <nl> + pict -> qscale_table = NULL ; <nl>  <nl> ff_MPV_frame_end ( s ); <nl> 
int swri_realloc_audio ( AudioData * a , int count ){ <nl> av_assert0 ( a -> bps ); <nl> av_assert0 ( a -> ch_count ); <nl>  <nl> - a -> data = av_mallocz ( countb * a -> ch_count ); <nl> + a -> data = av_mallocz_array ( countb , a -> ch_count ); <nl> if (! a -> data ) <nl> return AVERROR ( ENOMEM ); <nl> for ( i = 0 ; i < a -> ch_count ; i ++){
static int dxva2_map_frame ( AVHWFramesContext * ctx , AVFrame * dst , const AVFrame * <nl> } <nl>  <nl> map = av_mallocz ( sizeof (* map )); <nl> - if (! map ) <nl> + if (! map ) { <nl> + err = AVERROR ( ENOMEM ); <nl> goto fail ; <nl> + } <nl>  <nl> err = ff_hwframe_map_create ( src -> hw_frames_ctx , dst , src , <nl> dxva2_unmap_frame , map );
static int decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , <nl> for (; yq < slice_h && yq < h ; yq ++){ <nl> IDWTELEM * line = slice_buffer_get_line (& s -> sb , yq ); <nl> for ( x = 0 ; x < w ; x ++){ <nl> - line [ x ] <<= FRAC_BITS ; <nl> + line [ x ] *= 1 << FRAC_BITS ; <nl> } <nl> } <nl> }
const uint8_t * avpriv_mpv_find_start_code ( const uint8_t * restrict p , <nl> av_cold int ff_dct_common_init ( MpegEncContext * s ) <nl> { <nl> ff_dsputil_init (& s -> dsp , s -> avctx ); <nl> - ff_videodsp_init (& s -> vdsp , 8 ); <nl> + ff_videodsp_init (& s -> vdsp , s -> avctx -> bits_per_raw_sample ); <nl>  <nl> s -> dct_unquantize_h263_intra = dct_unquantize_h263_intra_c ; <nl> s -> dct_unquantize_h263_inter = dct_unquantize_h263_inter_c ;
static int mxg_update_cache ( AVFormatContext * s , unsigned int cache_size ) <nl> /* reallocate internal buffer */ <nl> if ( current_pos > current_pos + cache_size ) <nl> return AVERROR ( ENOMEM ); <nl> - if ( mxg -> soi_ptr ) soi_pos = mxg -> soi_ptr - mxg -> buffer ; <nl> + soi_pos = mxg -> soi_ptr - mxg -> buffer ; <nl> mxg -> buffer = av_fast_realloc ( mxg -> buffer , & mxg -> buffer_size , <nl> current_pos + cache_size + <nl> FF_INPUT_BUFFER_PADDING_SIZE );
static int find_and_decode_index ( NUTContext * nut ) <nl> has_keyframe [ n ++] = flag ; <nl> has_keyframe [ n ++] = ! flag ; <nl> } else { <nl> + if ( x <= 1 ) { <nl> + av_log ( s , AV_LOG_ERROR , " index : x %" PRIu64 " is invalid \ n ", x ); <nl> + goto fail ; <nl> + } <nl> while ( x != 1 ) { <nl> if ( n >= syncpoint_count + 1 ) { <nl> av_log ( s , AV_LOG_ERROR , " index overflow B \ n ");
AVCodec mjpeg_decoder = { <nl> ff_mjpeg_decode_frame , <nl> CODEC_CAP_DR1 , <nl> NULL , <nl> - . max_lowres = 8 , <nl> + . max_lowres = 4 , <nl> . long_name = NULL_IF_CONFIG_SMALL (" MJPEG ( Motion JPEG )"), <nl> }; <nl> 
static int parse_bintree ( Indeo3DecodeContext * ctx , AVCodecContext * avctx , <nl> av_log ( avctx , AV_LOG_ERROR , " SkipCell procedure not implemented yet !\ n "); <nl>  <nl> CHECK_CELL <nl> + if (! curr_cell . mv_ptr ) <nl> + return AVERROR_INVALIDDATA ; <nl> copy_cell ( ctx , plane , & curr_cell ); <nl> return 0 ; <nl> }
static void stream_component_close ( VideoState * is , int stream_index ) <nl> if ( is -> rdft ) { <nl> av_rdft_end ( is -> rdft ); <nl> av_freep (& is -> rdft_data ); <nl> + is -> rdft = NULL ; <nl> + is -> rdft_bits = 0 ; <nl> } <nl> break ; <nl> case AVMEDIA_TYPE_VIDEO :
static void fix_coding_method_array ( int sb , int channels , sb_int8_array coding_ <nl> run = 1 ; <nl> case_val = 8 ; <nl> } else { <nl> - switch ( switchtable [ coding_method [ ch ][ sb ][ j ]]) { <nl> + switch ( switchtable [ coding_method [ ch ][ sb ][ j ]- 8 ]) { <nl> case 0 : run = 10 ; case_val = 10 ; break ; <nl> case 1 : run = 1 ; case_val = 16 ; break ; <nl> case 2 : run = 5 ; case_val = 24 ; break ;
static void jpeg2000_dec_cleanup ( Jpeg2000DecoderContext * s ) <nl> } <nl> } <nl> av_freep (& s -> tile ); <nl> + memset ( s -> codsty , 0 , sizeof ( s -> codsty )); <nl> + memset ( s -> qntsty , 0 , sizeof ( s -> qntsty )); <nl> s -> numXtiles = s -> numYtiles = 0 ; <nl> } <nl> 
static int parse_playlist ( URLContext * h , const char * url ) <nl> return ret ; <nl>  <nl> read_chomp_line ( in , line , sizeof ( line )); <nl> - if ( strcmp ( line , "# EXTM3U ")) <nl> - return AVERROR_INVALIDDATA ; <nl> + if ( strcmp ( line , "# EXTM3U ")) { <nl> + ret = AVERROR_INVALIDDATA ; <nl> + goto fail ; <nl> + } <nl>  <nl> free_segment_list ( s ); <nl> s -> finished = 0 ;
static int find_slice_quant ( AVCodecContext * avctx , const AVFrame * pic , <nl> if ( ctx -> alpha_bits ) <nl> bits += estimate_alpha_plane ( ctx , & error , src , linesize [ 3 ], <nl> mbs_per_slice , q , td -> blocks [ 3 ]); <nl> - if ( bits > 65000 * 8 ) { <nl> + if ( bits > 65000 * 8 ) <nl> error = SCORE_LIMIT ; <nl> - break ; <nl> - } <nl> + <nl> slice_bits [ q ] = bits ; <nl> slice_score [ q ] = error ; <nl> }
yuv2mono_X_c_template ( SwsContext * c , const int16_t * lumFilter , <nl> const uint8_t * const d128 = dither_8x8_220 [ y & 7 ]; <nl> uint8_t * g = c -> table_gU [ 128 ] + c -> table_gV [ 128 ]; <nl> int i ; <nl> - int acc = 0 ; <nl> + unsigned acc = 0 ; <nl>  <nl> for ( i = 0 ; i < dstW - 1 ; i += 2 ) { <nl> int j ;
static int parse_picture_segment ( AVCodecContext * avctx , <nl> ctx -> pictures [ picture_id ]. w = width ; <nl> ctx -> pictures [ picture_id ]. h = height ; <nl>  <nl> - av_fast_malloc (& ctx -> pictures [ picture_id ]. rle , & ctx -> pictures [ picture_id ]. rle_buffer_size , rle_bitmap_len ); <nl> + av_fast_padded_malloc (& ctx -> pictures [ picture_id ]. rle , & ctx -> pictures [ picture_id ]. rle_buffer_size , rle_bitmap_len ); <nl>  <nl> if (! ctx -> pictures [ picture_id ]. rle ) <nl> return - 1 ;
static int decode_frame ( AVCodecContext * avctx , <nl> decoded = loco_decode_plane ( l , p -> data [ 0 ] + p -> linesize [ 0 ]*( avctx -> height - 1 ) + 3 , avctx -> width , avctx -> height , <nl> - p -> linesize [ 0 ], buf , buf_size , 4 ); <nl> break ; <nl> + default : <nl> + av_assert0 ( 0 ); <nl> } <nl>  <nl> if ( decoded < 0 || decoded > buf_size )
static int rv20_decode_picture_header ( MpegEncContext * s ) <nl> if ( s -> avctx -> debug & FF_DEBUG_PICT_INFO ){ <nl> av_log ( s -> avctx , AV_LOG_DEBUG , " F % d /% d \ n ", f , rpr_bits ); <nl> } <nl> - } <nl> + } else if ( av_image_check_size ( s -> width , s -> height , 0 , s -> avctx ) < 0 ) <nl> + return AVERROR_INVALIDDATA ; <nl>  <nl> mb_pos = ff_h263_decode_mba ( s ); <nl> 
static inline int wv_get_value_integer ( WavpackFrameContext * s , uint32_t * crc , in <nl> if ( s -> extra_bits ){ <nl> S <<= s -> extra_bits ; <nl>  <nl> - if ( s -> got_extra_bits ){ <nl> + if ( s -> got_extra_bits && get_bits_left (& s -> gb_extra_bits ) >= s -> extra_bits ){ <nl> S |= get_bits (& s -> gb_extra_bits , s -> extra_bits ); <nl> * crc = * crc * 9 + ( S & 0xffff ) * 3 + (( unsigned ) S >> 16 ); <nl> }
static int mxf_read_primer_pack ( MXFContext * mxf ) <nl>  <nl> static int mxf_add_metadata_set ( MXFContext * mxf , void * metadata_set ) <nl> { <nl> + if ( mxf -> metadata_sets_count + 1 >= UINT_MAX / sizeof (* mxf -> metadata_sets )) <nl> + return AVERROR ( ENOMEM ); <nl> mxf -> metadata_sets = av_realloc ( mxf -> metadata_sets , ( mxf -> metadata_sets_count + 1 ) * sizeof (* mxf -> metadata_sets )); <nl> if (! mxf -> metadata_sets ) <nl> return - 1 ;
typedef struct MpegDemuxContext { <nl> static int mpegps_read_header ( AVFormatContext * s ) <nl> { <nl> MpegDemuxContext * m = s -> priv_data ; <nl> - char buffer [ 7 ]; <nl> + char buffer [ 7 ] = { 0 }; <nl> int64_t last_pos = avio_tell ( s -> pb ); <nl>  <nl> m -> header_state = 0xff ;
int ff_srtp_decrypt ( struct SRTPContext * s , uint8_t * buf , int * lenptr ) <nl> { <nl> uint8_t iv [ 16 ] = { 0 }, hmac [ 20 ]; <nl> int len = * lenptr ; <nl> - int ext , seq_largest ; <nl> - uint32_t ssrc , roc ; <nl> + int ext , av_uninit ( seq_largest ); <nl> + uint32_t ssrc , av_uninit ( roc ); <nl> uint64_t index ; <nl> int rtcp ; <nl> 
static int send_invoke_response ( URLContext * s , RTMPPacket * pkt ) <nl> { <nl> RTMPContext * rt = s -> priv_data ; <nl> double seqnum ; <nl> - char filename [ 64 ]; <nl> + char filename [ 128 ]; <nl> char command [ 64 ]; <nl> int stringlen ; <nl> char * pchar ;
retry : <nl> uint8_t * side_data = av_packet_new_side_data ( pkt , <nl> AV_PKT_DATA_METADATA_UPDATE , <nl> os -> new_metadata_size ); <nl> + if ( side_data == NULL ) { <nl> + av_free_packet ( pkt ); <nl> + av_free ( pkt ); <nl> + return AVERROR ( ENOMEM ); <nl> + } <nl> memcpy ( side_data , os -> new_metadata , os -> new_metadata_size ); <nl> av_freep (& os -> new_metadata ); <nl> os -> new_metadata_size = 0 ;
int ff_get_qtpalette ( int codec_id , AVIOContext * pb , uint32_t * palette ) <nl>  <nl> /* If the depth is 1 , 2 , 4 , or 8 bpp , file is palettized . */ <nl> if (( bit_depth == 1 || bit_depth == 2 || bit_depth == 4 || bit_depth == 8 )) { <nl> - int color_count , color_start , color_end ; <nl> + uint32_t color_count , color_start , color_end ; <nl> uint32_t a , r , g , b ; <nl>  <nl> /* Ignore the greyscale bit for 1 - bit video and sample
static int decode_frame ( AVCodecContext * avctx , void * data , int * got_frame_ptr , <nl> header = AV_RB32 ( buf ); <nl> if ( header >> 8 == AV_RB32 (" TAG ")>> 8 ) { <nl> av_log ( avctx , AV_LOG_DEBUG , " discarding ID3 tag \ n "); <nl> - return buf_size ; <nl> + return buf_size + skipped ; <nl> } <nl> ret = avpriv_mpegaudio_decode_header (( MPADecodeHeader *) s , header ); <nl> if ( ret < 0 ) {
 <nl> static int null_filter_samples ( AVFilterLink * link , AVFilterBufferRef * samplesref ) <nl> { <nl> + avfilter_unref_bufferp (& samplesref ); <nl> return 0 ; <nl> } <nl> 
static int hls_write_header ( AVFormatContext * s ) <nl> int ret , i ; <nl> char * p ; <nl> const char * pattern = "% d . ts "; <nl> - int basename_size = strlen ( s -> filename ) + strlen ( pattern ); <nl> + int basename_size = strlen ( s -> filename ) + strlen ( pattern ) + 1 ; <nl>  <nl> hls -> number = 0 ; <nl> 
int ff_ivi_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , <nl> } <nl> } <nl> } <nl> + } else { <nl> + if ( ctx -> is_scalable ) <nl> + return AVERROR_INVALIDDATA ; <nl> + <nl> + for ( p = 0 ; p < 3 ; p ++) { <nl> + if (! ctx -> planes [ p ]. bands [ 0 ]. buf ) <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> } <nl>  <nl> // STOP_TIMER (" decode_planes "); }
 <nl> typedef struct Hnm4VideoContext { <nl> uint8_t version ; <nl> - uint16_t width ; <nl> - uint16_t height ; <nl> + int width ; <nl> + int height ; <nl> uint8_t * current ; <nl> uint8_t * previous ; <nl> uint8_t * buffer1 ;
static int rtmp_open ( URLContext * s , const char * uri , int flags ) <nl>  <nl> rt -> state = STATE_START ; <nl> if ( rtmp_handshake ( s , rt )) <nl> - return - 1 ; <nl> + goto fail ; <nl>  <nl> rt -> chunk_size = 128 ; <nl> rt -> state = STATE_HANDSHAKED ;
static int decode_block ( MJpegDecodeContext * s , int16_t * block , int component , <nl> return AVERROR_INVALIDDATA ; <nl> } <nl> val = val * quant_matrix [ 0 ] + s -> last_dc [ component ]; <nl> + val = FFMIN ( val , 32767 ); <nl> s -> last_dc [ component ] = val ; <nl> block [ 0 ] = val ; <nl> /* AC coefs */
static void probe_codec ( AVFormatContext * s , AVStream * st , const AVPacket * pkt ) <nl> memset ( pd -> buf + pd -> buf_size , 0 , AVPROBE_PADDING_SIZE ); <nl> } else { <nl> st -> probe_packets = 0 ; <nl> + if (! pd -> buf_size ) { <nl> + av_log ( s , AV_LOG_ERROR , " nothing to probe for stream % d \ n ", <nl> + st -> index ); <nl> + return ; <nl> + } <nl> } <nl>  <nl> if (! st -> probe_packets ||
static uint64_t calc_rice_params ( RiceContext * rc , <nl> bits [ pmin ] = UINT32_MAX ; <nl> for ( i = pmax ; ; ) { <nl> bits [ i ] = calc_optimal_rice_params (& tmp_rc , i , sums , n , pred_order , kmax , exact ); <nl> - if ( bits [ i ] < bits [ opt_porder ]) { <nl> + if ( bits [ i ] < bits [ opt_porder ] || pmax == pmin ) { <nl> opt_porder = i ; <nl> * rc = tmp_rc ; <nl> }
int main ( int argc , char ** argv ) <nl> goto end ; <nl>  <nl> /* read all packets */ <nl> + packet0 . data = NULL ; <nl> packet . data = NULL ; <nl> while ( 1 ) { <nl> if (! packet0 . data ) {
static int rm_read_audio_stream_info ( AVFormatContext * s , AVIOContext * pb , <nl> sub_packet_h <= 1 || <nl> ast -> coded_framesize * sub_packet_h > ( 2 + ( sub_packet_h & 1 )) * ast -> audio_framesize ) <nl> return AVERROR_INVALIDDATA ; <nl> + if ( ast -> coded_framesize * sub_packet_h != 2 * ast -> audio_framesize ) { <nl> + avpriv_request_sample ( s , " mismatching interleaver parameters "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> break ; <nl> case DEINT_ID_GENR : <nl> if ( ast -> sub_packet_size <= 0 ||
static void scale_coefs ( <nl> int dynrng , <nl> int len ) <nl> { <nl> - int i , shift , round ; <nl> - unsigned mul ; <nl> + int i , shift ; <nl> + unsigned mul , round ; <nl> int temp , temp1 , temp2 , temp3 , temp4 , temp5 , temp6 , temp7 ; <nl>  <nl> mul = ( dynrng & 0x1f ) + 0x20 ;
# include " libavutil / pixdesc . h " <nl> # include " avcodec . h " <nl> # include " internal . h " <nl> + <nl> +# if defined ( _MSC_VER ) <nl> +# define X264_API_IMPORTS 1 <nl> +# endif <nl> + <nl> # include < x264 . h > <nl> # include < float . h > <nl> # include < math . h >
static int shorten_decode_frame ( AVCodecContext * avctx , void * data , <nl> void * tmp_ptr ; <nl> s -> max_framesize = 8192 ; // should hopefully be enough for the first header <nl> tmp_ptr = av_fast_realloc ( s -> bitstream , & s -> allocated_bitstream_size , <nl> - s -> max_framesize ); <nl> + s -> max_framesize + FF_INPUT_BUFFER_PADDING_SIZE ); <nl> if (! tmp_ptr ) { <nl> av_log ( avctx , AV_LOG_ERROR , " error allocating bitstream buffer \ n "); <nl> return AVERROR ( ENOMEM );
static int hds_write_header ( AVFormatContext * s ) <nl>  <nl> snprintf ( os -> temp_filename , sizeof ( os -> temp_filename ), <nl> "% s / stream % d_temp ", s -> filename , i ); <nl> - init_file ( s , os , 0 ); <nl> + ret = init_file ( s , os , 0 ); <nl> + if ( ret < 0 ) <nl> + goto fail ; <nl>  <nl> if (! os -> has_video && c -> min_frag_duration <= 0 ) { <nl> av_log ( s , AV_LOG_WARNING ,
static int filter_samples ( AVFilterLink * inlink , AVFilterBufferRef * buf ) <nl>  <nl> if ( labs ( delta ) > s -> min_delta ) { <nl> av_log ( ctx , AV_LOG_VERBOSE , " Discontinuity - %" PRId64 " samples .\ n ", delta ); <nl> - out_size += delta ; <nl> + out_size = av_clipl_int32 (( int64_t ) out_size + delta ); <nl> } else { <nl> if ( s -> resample ) { <nl> int comp = av_clip ( delta , - s -> max_comp , s -> max_comp );
static int compute_bit_allocation ( AC3EncodeContext * s ) <nl> */ <nl> static inline int sym_quant ( int c , int e , int levels ) <nl> { <nl> - int v = (((( levels * c ) >> ( 24 - e )) + 1 ) >> 1 ) + ( levels >> 1 ); <nl> + int v = ((( levels * c ) >> ( 24 - e )) + levels ) >> 1 ; <nl> av_assert2 ( v >= 0 && v < levels ); <nl> return v ; <nl> }
static const AVCodecDescriptor codec_descriptors [] = { <nl> . type = AVMEDIA_TYPE_VIDEO , <nl> . name = " fraps ", <nl> . long_name = NULL_IF_CONFIG_SMALL (" Fraps "), <nl> - . props = AV_CODEC_PROP_LOSSLESS , <nl> + . props = AV_CODEC_PROP_INTRA_ONLY | AV_CODEC_PROP_LOSSLESS , <nl> }, <nl> { <nl> . id = AV_CODEC_ID_TRUEMOTION2 ,
int av_set_string3 ( void * obj , const char * name , const char * val , int alloc , cons <nl>  <nl> int av_opt_set ( void * obj , const char * name , const char * val , int search_flags ) <nl> { <nl> - int ret ; <nl> + int ret = 0 ; <nl> void * dst , * target_obj ; <nl> const AVOption * o = av_opt_find2 ( obj , name , NULL , 0 , search_flags , & target_obj ); <nl> if (! o || ! target_obj )
static int decode_residual_block ( AVSContext * h , GetBitContext * gb , <nl> const dec_2dvlc_t * r , int esc_golomb_order , <nl> int qp , uint8_t * dst , int stride ) { <nl> int i , level_code , esc_code , level , run , mask ; <nl> - DCTELEM level_buf [ 64 ]; <nl> - uint8_t run_buf [ 64 ]; <nl> + DCTELEM level_buf [ 65 ]; <nl> + uint8_t run_buf [ 65 ]; <nl> DCTELEM * block = h -> block ; <nl>  <nl> for ( i = 0 ; i < 65 ; i ++) {
static int vobsub_read_packet ( AVFormatContext * s , AVPacket * pkt ) <nl> FFDemuxSubtitlesQueue * q ; <nl> AVIOContext * pb = vobsub -> sub_ctx -> pb ; <nl> int ret , psize , total_read = 0 , i ; <nl> - AVPacket idx_pkt ; <nl> + AVPacket idx_pkt = { 0 }; <nl>  <nl> int64_t min_ts = INT64_MAX ; <nl> int sid = 0 ;
static const AVProfile mpeg2_video_profiles [] = { <nl> { FF_PROFILE_MPEG2_SIMPLE , " Simple " }, <nl> { FF_PROFILE_RESERVED , " Reserved " }, <nl> { FF_PROFILE_RESERVED , " Reserved " }, <nl> + { FF_PROFILE_UNKNOWN }, <nl> }; <nl>  <nl> 
static av_cold void uninit ( AVFilterContext * ctx ) <nl>  <nl> av_freep (& s -> frame_data . input ); <nl> av_freep (& s -> frame_data . temp ); <nl> + av_freep (& s -> fdsp ); <nl> av_frame_free (& s -> second ); <nl> } <nl> 
static int set_string_binary ( void * obj , const AVOption * o , const char * val , uint <nl> len /= 2 ; <nl>  <nl> ptr = bin = av_malloc ( len ); <nl> + if (! ptr ) <nl> + return AVERROR ( ENOMEM ); <nl> while (* val ) { <nl> int a = hexchar2int (* val ++); <nl> int b = hexchar2int (* val ++);
static int create_filter ( AVFilterContext ** filt_ctx , AVFilterGraph * ctx , int ind <nl> return ret ; <nl> } <nl>  <nl> - if (! strcmp ( filt_name , " scale ") && ! strstr ( args , " flags ")) { <nl> + if (! strcmp ( filt_name , " scale ") && args && ! strstr ( args , " flags ")) { <nl> snprintf ( tmp_args , sizeof ( tmp_args ), "% s :% s ", <nl> args , ctx -> scale_sws_opts ); <nl> args = tmp_args ;
static av_cold int vqa_decode_init ( AVCodecContext * avctx ) <nl> /* allocate decode buffer */ <nl> s -> decode_buffer_size = ( s -> width / s -> vector_width ) * <nl> ( s -> height / s -> vector_height ) * 2 ; <nl> - s -> decode_buffer = av_malloc ( s -> decode_buffer_size ); <nl> + s -> decode_buffer = av_mallocz ( s -> decode_buffer_size ); <nl> if (! s -> decode_buffer ) <nl> goto fail ; <nl> 
static int tak_read_header ( AVFormatContext * s ) <nl> buffer = av_malloc ( size - 3 + FF_INPUT_BUFFER_PADDING_SIZE ); <nl> if (! buffer ) <nl> return AVERROR ( ENOMEM ); <nl> + memset ( buffer + size - 3 , 0 , FF_INPUT_BUFFER_PADDING_SIZE ); <nl>  <nl> ffio_init_checksum ( pb , tak_check_crc , 0xCE04B7U ); <nl> if ( avio_read ( pb , buffer , size - 3 ) != size - 3 ) {
static int decode_frame ( AVCodecContext * avctx , <nl> int prev_y = 0 , prev_u = 0 , prev_v = 0 ; <nl> uint8_t * rbuf ; <nl>  <nl> - if ( buf_size <= 8 ) { <nl> + if ( buf_size < 8 + avctx -> height * ( avctx -> width / 2 )/ 8 ) { <nl> av_log ( avctx , AV_LOG_ERROR , " Packet size % d is too small \ n ", buf_size ); <nl> return AVERROR_INVALIDDATA ; <nl> }
static int check_opcodes ( MMCO * mmco1 , MMCO * mmco2 , int n_mmcos ) <nl> int ff_generate_sliding_window_mmcos ( H264Context * h , int first_slice ) <nl> { <nl> MMCO mmco_temp [ MAX_MMCO_COUNT ], * mmco = first_slice ? h -> mmco : mmco_temp ; <nl> - int mmco_index = 0 , i ; <nl> + int mmco_index = 0 , i = 0 ; <nl>  <nl> assert ( h -> long_ref_count + h -> short_ref_count <= h -> sps . ref_frame_count ); <nl> 
static int filter_frame ( AVFilterLink * inlink , AVFilterBufferRef * in ) <nl> GradFunContext * gf = inlink -> dst -> priv ; <nl> AVFilterLink * outlink = inlink -> dst -> outputs [ 0 ]; <nl> AVFilterBufferRef * out ; <nl> - int p , direct ; <nl> + int p , direct = 0 ; <nl>  <nl> if (( in -> perms & AV_PERM_WRITE ) && !( in -> perms & AV_PERM_PRESERVE )) { <nl> direct = 1 ;
static void rac_normalise ( RangeCoder * c ) <nl> c -> low |= * c -> src ++; <nl> } else if (! c -> low ) { <nl> c -> got_error = 1 ; <nl> - return ; <nl> + c -> low = 1 ; <nl> } <nl> if ( c -> range >= RAC_BOTTOM ) <nl> return ;
static int mov_preroll_write_stbl_atoms ( AVIOContext * pb , MOVTrack * track ) <nl> } <nl> entries ++; <nl>  <nl> - if (! group ) <nl> + if (! group ) { <nl> + av_free ( sgpd_entries ); <nl> return 0 ; <nl> + } <nl>  <nl> /* Write sgpd tag */ <nl> avio_wb32 ( pb , 24 + ( group * 2 )); /* size */
void ff_lzw_decode_tail ( LZWState * p ) <nl> struct LZWState * s = ( struct LZWState *) p ; <nl>  <nl> if ( s -> mode == FF_LZW_GIF ) { <nl> - while ( s -> pbuf < s -> ebuf && s -> bs > 0 ){ <nl> + while ( s -> pbuf + s -> bs < s -> ebuf && s -> bs > 0 ){ <nl> s -> pbuf += s -> bs ; <nl> s -> bs = * s -> pbuf ++; <nl> }
static int mjpeg_decode_app ( MJpegDecodeContext * s ) <nl>  <nl> if ( id == AV_RB32 (" JFIF ")) { <nl> int t_w , t_h , v1 , v2 ; <nl> + if ( len < 8 ) <nl> + goto out ; <nl> skip_bits (& s -> gb , 8 ); /* the trailing zero - byte */ <nl> v1 = get_bits (& s -> gb , 8 ); <nl> v2 = get_bits (& s -> gb , 8 );
static int h264_slice_header_init ( H264Context * h , int reinit ) <nl> return ret ; <nl> } <nl> } else { <nl> - if (( ret = ff_MPV_common_init ( s ) < 0 )) { <nl> + if (( ret = ff_MPV_common_init ( s )) < 0 ) { <nl> av_log ( h -> s . avctx , AV_LOG_ERROR , " ff_MPV_common_init () failed .\ n "); <nl> return ret ; <nl> }
static void search_for_quantizers_twoloop ( AVCodecContext * avctx , <nl> sce -> sf_idx [ i ] -= qstep ; <nl> } <nl> qstep >>= 1 ; <nl> - if (! qstep && tbits > destbits * 1 . 02 ) <nl> + if (! qstep && tbits > destbits * 1 . 02 && sce -> sf_idx [ 0 ] < 217 ) <nl> qstep = 1 ; <nl> - if ( sce -> sf_idx [ 0 ] >= 217 ) <nl> - break ; <nl> } while ( qstep ); <nl>  <nl> fflag = 0 ;
static int decode_residual_block ( AVSContext * h , GetBitContext * gb , <nl> return AVERROR_INVALIDDATA ; <nl> } <nl> esc_code = get_ue_code ( gb , esc_golomb_order ); <nl> + if ( esc_code < 0 || esc_code > 32767 ) { <nl> + av_log ( h -> avctx , AV_LOG_ERROR , " esc_code invalid \ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> + <nl> level = esc_code + ( run > r -> max_run ? 1 : r -> level_add [ run ]); <nl> while ( level > r -> inc_limit ) <nl> r ++;
static int decode_wdlt ( GetByteContext * gb , uint8_t * frame , int width , int height <nl> y += skip_lines ; <nl> segments = bytestream2_get_le16 ( gb ); <nl> } <nl> + <nl> + if ( frame_end <= frame ) <nl> + return AVERROR_INVALIDDATA ; <nl> if ( segments & 0x8000 ) { <nl> frame [ width - 1 ] = segments & 0xFF ; <nl> segments = bytestream2_get_le16 ( gb );
typedef struct AVStream { <nl> int codec_info_nb_frames ; <nl> # endif <nl> /** encoding : PTS generation when outputing stream */ <nl> - AVFrac pts ; <nl> + struct AVFrac pts ; <nl>  <nl> /** <nl> * this is the fundamental unit of time ( in seconds ) in terms
static void guess_mv ( MpegEncContext * s ){ <nl> fixed [ mb_xy ]= f ; <nl> if ( f == MV_FROZEN ) <nl> num_avail ++; <nl> - else if ( s -> last_picture . data [ 0 ]){ <nl> + else if ( s -> last_picture . data [ 0 ] && s -> last_picture . motion_val [ 0 ]){ <nl> const int mb_y = mb_xy / s -> mb_stride ; <nl> const int mb_x = mb_xy % s -> mb_stride ; <nl> const int mot_index = ( mb_x + mb_y * mot_stride ) * mot_step ;
int ff_mpv_reallocate_putbitbuffer ( MpegEncContext * s , size_t threshold , size_t s <nl> uint8_t * new_buffer = NULL ; <nl> int new_buffer_size = 0 ; <nl>  <nl> + if (( s -> avctx -> internal -> byte_buffer_size + size_increase ) >= INT_MAX / 8 ) { <nl> + av_log ( s -> avctx , AV_LOG_ERROR , " Cannot reallocate putbit buffer \ n "); <nl> + return AVERROR ( ENOMEM ); <nl> + } <nl> + <nl> av_fast_padded_malloc (& new_buffer , & new_buffer_size , <nl> s -> avctx -> internal -> byte_buffer_size + size_increase ); <nl> if (! new_buffer )
static int jp2_find_codestream ( Jpeg2000DecoderContext * s ) <nl> atom2_end = bytestream2_tell (& s -> g ) + atom2_size - 8 ; <nl> if ( atom2_size < 8 || atom2_end > atom_end || atom2_end < atom2_size ) <nl> break ; <nl> + atom2_size -= 8 ; <nl> if ( atom2 == JP2_CODESTREAM ) { <nl> return 1 ; <nl> } else if ( atom2 == MKBETAG (' c ',' o ',' l ',' r ') && atom2_size >= 7 ) {
static int tls_client_handshake_loop ( URLContext * h , int initial ) <nl> TLSContext * c = h -> priv_data ; <nl> TLSShared * s = & c -> tls_shared ; <nl> SECURITY_STATUS sspi_ret ; <nl> - SecBuffer outbuf [ 3 ]; <nl> + SecBuffer outbuf [ 3 ] = { 0 }; <nl> SecBufferDesc outbuf_desc ; <nl> SecBuffer inbuf [ 2 ]; <nl> SecBufferDesc inbuf_desc ;
static void do_video_out ( AVFormatContext * s , <nl> } else <nl> in_picture = next_picture ; <nl>  <nl> + if (! in_picture ) <nl> + return ; <nl> + <nl> in_picture -> pts = ost -> sync_opts ; <nl>  <nl> # if 1
static int dv_write_header ( AVFormatContext * s ) <nl> break ; <nl> } <nl> } <nl> - if ( tcr ) <nl> - return av_timecode_init_from_string (& dvc -> tc , rate , tcr -> value , s ); <nl> + if ( tcr && av_timecode_init_from_string (& dvc -> tc , rate , tcr -> value , s ) >= 0 ) <nl> + return 0 ; <nl> return av_timecode_init (& dvc -> tc , rate , 0 , 0 , s ); <nl> } <nl> 
static inline av_const SoftFloat av_sub_sf ( SoftFloat a , SoftFloat b ){ <nl> */ <nl> static inline av_const SoftFloat av_int2sf ( int v , int frac_bits ){ <nl> int exp_offset = 0 ; <nl> - if ( v == INT_MIN ){ <nl> + if ( v <= INT_MIN + 1 ){ <nl> exp_offset = 1 ; <nl> v >>= 1 ; <nl> }
int ff_thread_get_buffer ( AVCodecContext * avctx , AVFrame * f ) <nl> avctx -> get_buffer == avcodec_default_get_buffer ) { <nl> err = avctx -> get_buffer ( avctx , f ); <nl> } else { <nl> + pthread_mutex_lock (& p -> progress_mutex ); <nl> p -> requested_frame = f ; <nl> p -> state = STATE_GET_BUFFER ; <nl> - pthread_mutex_lock (& p -> progress_mutex ); <nl> pthread_cond_broadcast (& p -> progress_cond ); <nl>  <nl> while ( p -> state != STATE_SETTING_UP )
intra : <nl> } <nl> end : <nl>  <nl> + if ( get_bits_left (& s -> gb ) < 0 ) <nl> + return AVERROR_INVALIDDATA ; <nl> + <nl> /* per - MB end of slice check */ <nl> { <nl> int v = show_bits (& s -> gb , 16 );
static int decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , <nl> for ( j = 0 ; j < c -> slices ; j ++) { <nl> slice_end = bytestream2_get_le32u (& gb ); <nl> if ( slice_end < 0 || slice_end < slice_start || <nl> - bytestream2_get_bytes_left (& gb ) < slice_end ) { <nl> + bytestream2_get_bytes_left (& gb ) < slice_end + 1024LL ) { <nl> av_log ( avctx , AV_LOG_ERROR , " Incorrect slice size \ n "); <nl> return AVERROR_INVALIDDATA ; <nl> }
av_cold void ff_psy_preprocess_end ( struct FFPsyPreprocessContext * ctx ) <nl> for ( i = 0 ; i < ctx -> avctx -> channels ; i ++) <nl> ff_iir_filter_free_state ( ctx -> fstate [ i ]); <nl> av_freep (& ctx -> fstate ); <nl> + av_free ( ctx ); <nl> } <nl> 
int ff_ass_split_override_codes ( const ASSCodesCallbacks * callbacks , void * priv , <nl> char new_line [ 2 ]; <nl> int text_len = 0 ; <nl>  <nl> - while (* buf ) { <nl> + while ( buf && * buf ) { <nl> if ( text && callbacks -> text && <nl> ( sscanf ( buf , "\\% 1 [ nN ]", new_line ) == 1 || <nl> ! strncmp ( buf , "{\\", 2 ))) {
int av_cold ff_wma_get_frame_len_bits ( int sample_rate , int version , <nl> } else if ( sample_rate <= 22050 || <nl> ( sample_rate <= 32000 && version == 1 )) { <nl> frame_len_bits = 10 ; <nl> - } else if ( sample_rate <= 48000 ) { <nl> + } else if ( sample_rate <= 48000 || version < 3 ) { <nl> frame_len_bits = 11 ; <nl> } else if ( sample_rate <= 96000 ) { <nl> frame_len_bits = 12 ;
int ff_h264_build_ref_list ( H264Context * h , H264SliceContext * sl ) <nl> break ; <nl> } <nl> default : <nl> - av_assert1 ( 0 ); <nl> + av_assert0 ( 0 ); <nl> } <nl>  <nl> if ( i < 0 ) {
static int mv_read_header ( AVFormatContext * avctx ) <nl> uint32_t pos = avio_rb32 ( pb ); <nl> uint32_t asize = avio_rb32 ( pb ); <nl> uint32_t vsize = avio_rb32 ( pb ); <nl> + if ( avio_feof ( pb )) <nl> + return AVERROR_INVALIDDATA ; <nl> avio_skip ( pb , 8 ); <nl> av_add_index_entry ( ast , pos , timestamp , asize , 0 , AVINDEX_KEYFRAME ); <nl> av_add_index_entry ( vst , pos + asize , i , vsize , 0 , AVINDEX_KEYFRAME );
static void gif_copy_img_rect ( const uint32_t * src , uint32_t * dst , <nl> const uint32_t * src_px , * src_pr , <nl> * src_py = src + y_start , <nl> * dst_py = dst + y_start ; <nl> - const uint32_t * src_pb = src_py + ( t + h ) * linesize ; <nl> + const uint32_t * src_pb = src_py + t * linesize ; <nl> uint32_t * dst_px ; <nl>  <nl> for (; src_py < src_pb ; src_py += linesize , dst_py += linesize ) {
static int shorten_decode_frame ( AVCodecContext * avctx , void * data , <nl> tmp_ptr = av_fast_realloc ( s -> bitstream , & s -> allocated_bitstream_size , <nl> s -> max_framesize + AV_INPUT_BUFFER_PADDING_SIZE ); <nl> if (! tmp_ptr ) { <nl> + s -> max_framesize = 0 ; <nl> av_log ( avctx , AV_LOG_ERROR , " error allocating bitstream buffer \ n "); <nl> return AVERROR ( ENOMEM ); <nl> }
static int vc1_decode_sprites ( VC1Context * v , GetBitContext * gb ) <nl> if ( ret < 0 ) <nl> return ret ; <nl>  <nl> - if (! s -> current_picture . f -> data [ 0 ]) { <nl> + if (! s -> current_picture . f || ! s -> current_picture . f -> data [ 0 ]) { <nl> av_log ( avctx , AV_LOG_ERROR , " Got no sprites \ n "); <nl> return - 1 ; <nl> }
static int start_frame ( AVFilterLink * inlink , AVFilterBufferRef * picref ) <nl> avfilter_unref_buffer ( tinterlace -> cur ); <nl> tinterlace -> cur = tinterlace -> next ; <nl> tinterlace -> next = picref ; <nl> + inlink -> cur_buf = NULL ; <nl> return 0 ; <nl> } <nl> 
static av_cold void uninit ( AVFilterContext * ctx ) <nl> { <nl> MovieContext * movie = ctx -> priv ; <nl>  <nl> - av_free ( movie -> file_name ); <nl> - av_free ( movie -> format_name ); <nl> if ( movie -> codec_ctx ) <nl> avcodec_close ( movie -> codec_ctx ); <nl> if ( movie -> format_ctx )
static int matroska_read_header ( AVFormatContext * s ) <nl> break ; <nl> if ( i >= FF_ARRAY_ELEMS ( matroska_doctypes )) { <nl> av_log ( s , AV_LOG_WARNING , " Unknown EBML doctype '% s '\ n ", ebml . doctype ); <nl> + if ( matroska -> ctx -> error_recognition & AV_EF_EXPLODE ) { <nl> + ebml_free ( ebml_syntax , & ebml ); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> } <nl> ebml_free ( ebml_syntax , & ebml ); <nl> 
static int encode_frame ( AVCodecContext * avctx , AVPacket * pkt , <nl> ff_init_range_encoder ( c , pkt -> data , pkt -> size ); <nl> ff_build_rac_states ( c , 0 . 05 * ( 1LL << 32 ), 256 - 8 ); <nl>  <nl> + av_frame_unref ( p ); <nl> av_frame_ref ( p , pict ); <nl> p -> pict_type = AV_PICTURE_TYPE_I ; <nl> 
int LLVMFuzzerTestOneInput ( const uint8_t * data , size_t size ) { <nl> while ( avpkt . size > 0 && it ++ < maxiteration ) { <nl> av_frame_unref ( frame ); <nl> int ret = decode_handler ( ctx , frame , & got_frame , & avpkt ); <nl> + <nl> + if ( it > 20 ) <nl> + ctx -> error_concealment = 0 ; <nl> + <nl> if ( ret <= 0 || ret > avpkt . size ) <nl> break ; <nl> avpkt . data += ret ;
static int a64multi_encode_frame ( AVCodecContext * avctx , AVPacket * pkt , <nl> int b_width ; <nl>  <nl> int req_size , ret ; <nl> - uint8_t * buf ; <nl> + uint8_t * buf = NULL ; <nl>  <nl> int * charmap = c -> mc_charmap ; <nl> uint8_t * colram = c -> mc_colram ;
static av_cold int init_subtitles ( AVFilterContext * ctx , const char * args ) <nl> } <nl>  <nl> end : <nl> - if ( fmt ) <nl> - avformat_close_input (& fmt ); <nl> if ( dec_ctx ) <nl> avcodec_close ( dec_ctx ); <nl> + if ( fmt ) <nl> + avformat_close_input (& fmt ); <nl> return ret ; <nl> } <nl> 
static int tak_decode_frame ( AVCodecContext * avctx , void * data , <nl> for ( chan = 0 ; chan < avctx -> channels ; chan ++) { <nl> int32_t * samples = ( int32_t *) frame -> extended_data [ chan ]; <nl> for ( i = 0 ; i < s -> nb_samples ; i ++) <nl> - samples [ i ] <<= 8 ; <nl> + samples [ i ] *= 1 << 8 ; <nl> } <nl> break ; <nl> }
static int shorten_decode_frame ( AVCodecContext * avctx , void * data , <nl> av_log ( avctx , AV_LOG_ERROR , " error allocating bitstream buffer \ n "); <nl> return AVERROR ( ENOMEM ); <nl> } <nl> + memset ( tmp_ptr , 0 , s -> allocated_bitstream_size ); <nl> s -> bitstream = tmp_ptr ; <nl> } <nl> 
static int lag_decode_zero_run_line ( LagarithContext * l , uint8_t * dst , <nl> output_zeros : <nl> if ( l -> zeros_rem ) { <nl> count = FFMIN ( l -> zeros_rem , width - i ); <nl> + if ( end - dst < count ) { <nl> + av_log ( l -> avctx , AV_LOG_ERROR , " too many zeros remaining \ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> memset ( dst , 0 , count ); <nl> l -> zeros_rem -= count ; <nl> dst += count ;
static int h264_slice_init ( H264Context * h , H264SliceContext * sl , <nl>  <nl> if ( sl -> slice_type_nos == AV_PICTURE_TYPE_B && ! sl -> direct_spatial_mv_pred ) <nl> ff_h264_direct_dist_scale_factor ( h , sl ); <nl> - ff_h264_direct_ref_list_init ( h , sl ); <nl> + if (! h -> setup_finished ) <nl> + ff_h264_direct_ref_list_init ( h , sl ); <nl>  <nl> if ( h -> avctx -> skip_loop_filter >= AVDISCARD_ALL || <nl> ( h -> avctx -> skip_loop_filter >= AVDISCARD_NONKEY &&
static int wavpack_encode_block ( WavPackEncodeContext * s , <nl> uint8_t * out , int out_size ) <nl> { <nl> int block_size , start , end , data_size , tcount , temp , m = 0 ; <nl> - int i , j , ret , got_extra = 0 , nb_samples = s -> block_samples ; <nl> + int i , j , ret = 0 , got_extra = 0 , nb_samples = s -> block_samples ; <nl> uint32_t crc = 0xffffffffu ; <nl> struct Decorr * dpp ; <nl> PutByteContext pb ;
static int tiff_decode_tag ( TiffContext * s , AVFrame * frame ) <nl> s -> subsampling [ i ] = ff_tget (& s -> gb , type , s -> le ); <nl> if ( s -> subsampling [ i ] <= 0 ) { <nl> av_log ( s -> avctx , AV_LOG_ERROR , " subsampling % d is invalid \ n ", s -> subsampling [ i ]); <nl> + s -> subsampling [ i ] = 1 ; <nl> return AVERROR_INVALIDDATA ; <nl> } <nl> }
static int flush_packet ( AVFormatContext * ctx , int stream_index , <nl>  <nl> if ( stuffing_size < 0 ) <nl> stuffing_size = 0 ; <nl> + <nl> + if ( startcode == PRIVATE_STREAM_1 && id >= 0xa0 ) { <nl> + if ( payload_size < av_fifo_size ( stream -> fifo )) <nl> + stuffing_size += payload_size % stream -> lpcm_align ; <nl> + } <nl> + <nl> if ( stuffing_size > 16 ) { /*<= 16 for MPEG - 1 , <= 32 for MPEG - 2 */ <nl> pad_packet_bytes += stuffing_size ; <nl> packet_size -= stuffing_size ;
static int codec_get_buffer ( AVCodecContext * s , AVFrame * frame ) <nl> FrameBuffer * buf ; <nl> int ret , i ; <nl>  <nl> + if ( av_image_check_size ( s -> width , s -> height , 0 , s )) <nl> + return - 1 ; <nl> + <nl> if (! ist -> buffer_pool && ( ret = alloc_buffer ( s , ist , & ist -> buffer_pool )) < 0 ) <nl> return ret ; <nl> 
static int parse_palette ( AVCodecContext * avctx , GetByteContext * gbc , <nl> bytestream2_skip ( gbc , 1 ); <nl> b = bytestream2_get_byte ( gbc ); <nl> bytestream2_skip ( gbc , 1 ); <nl> - pal [ idx ] = ( r << 16 ) | ( g << 8 ) | b ; <nl> + pal [ idx ] = ( 0xFFU << 24 ) | ( r << 16 ) | ( g << 8 ) | b ; <nl> } <nl> return 0 ; <nl> }
static int decode_frame ( AVCodecContext * avctx , <nl> if ( i ) { <nl> AVRational q = av_d2q ( av_int2float ( i ), 4096 ); <nl> if ( q . num > 0 && q . den > 0 ) <nl> - avctx -> time_base = av_inv_q ( q ); <nl> + avctx -> framerate = q ; <nl> } <nl> } <nl> 
static int mp_get_vlc ( MotionPixelsContext * mp , GetBitContext * gb ) <nl> int i ; <nl>  <nl> i = ( mp -> codes_count == 1 ) ? 0 : get_vlc2 ( gb , mp -> vlc . table , mp -> max_codes_bits , 1 ); <nl> + i = FFMIN ( i , FF_ARRAY_ELEMS ( mp -> codes ) - 1 ); <nl> return mp -> codes [ i ]. delta ; <nl> } <nl> 
static int process_line ( URLContext * h , char * line , int line_count , <nl> # ifdef DEBUG <nl> printf (" http_code =% d \ n ", s -> http_code ); <nl> # endif <nl> + /* error codes are 4xx and 5xx */ <nl> + if ( s -> http_code >= 400 && s -> http_code < 600 ) <nl> + return - 1 ; <nl> } else { <nl> while (* p != '\ 0 ' && * p != ':') <nl> p ++;
static int mov_read_close ( AVFormatContext * s ) <nl> MOVContext * mov = ( MOVContext *) s -> priv_data ; <nl> for ( i = 0 ; i < mov -> total_streams ; i ++) <nl> mov_free_stream_context ( mov -> streams [ i ]); <nl> - for ( i = 0 ; i < s -> nb_streams ; i ++) <nl> - av_freep (& s -> streams [ i ]); <nl> /* free color tabs */ <nl> for ( i = 0 ; i < mov -> ctab_size ; i ++) <nl> av_freep (& mov -> ctab [ i ]);
static int open_output_file ( const char * filename ) <nl> || dec_ctx -> codec_type == AVMEDIA_TYPE_AUDIO ) { <nl> /* in this example , we choose transcoding to same codec */ <nl> encoder = avcodec_find_encoder ( dec_ctx -> codec_id ); <nl> + if (! encoder ) { <nl> + av_log ( NULL , AV_LOG_FATAL , " Neccessary encoder not found \ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl>  <nl> /* In this example , we transcode to same properties ( picture size , <nl> * sample rate etc .). These properties can be changed for output
static void compute_rematrixing_strategy ( AC3EncodeContext * s ) <nl> { <nl> int nb_coefs ; <nl> int blk , bnd ; <nl> - AC3Block * block , * block0 ; <nl> + AC3Block * block , * block0 = NULL ; <nl>  <nl> if ( s -> channel_mode != AC3_CHMODE_STEREO ) <nl> return ;
static int get_metadata_size ( const uint8_t * buf , int buf_size ) <nl>  <nl> buf += 4 ; <nl> do { <nl> + if ( buf_end - buf < 4 ) <nl> + return 0 ; <nl> ff_flac_parse_block_header ( buf , & metadata_last , NULL , & metadata_size ); <nl> buf += 4 ; <nl> - if ( buf + metadata_size > buf_end ) { <nl> + if ( buf_end - buf < metadata_size ) { <nl> /* need more data in order to read the complete header */ <nl> return 0 ; <nl> }
av_cold void ff_init_range_decoder ( RangeCoder * c , const uint8_t * buf , <nl>  <nl> c -> low = AV_RB16 ( c -> bytestream ); <nl> c -> bytestream += 2 ; <nl> + if ( c -> low >= 0xFF00 ) { <nl> + c -> low = 0xFF00 ; <nl> + c -> bytestream_end = c -> bytestream + 2 ; <nl> + } <nl> } <nl>  <nl> void ff_build_rac_states ( RangeCoder * c , int factor , int max_p )
wav_new_out ( struct fileops * ops , struct dev * dev , <nl> } <nl> f -> mode = mode ; <nl> f -> pstate = WAV_CFG ; <nl> - f -> endpos = f -> startpos = 0 ; <nl> + f -> mmcpos = f -> endpos = f -> startpos = 0 ; <nl> f -> next = wav_list ; <nl> wav_list = f ; <nl> if ( hdr == HDR_WAV ) {
struct cpu_disklabel { <nl> int cd_dummy ; /* must have one element . */ <nl> }; <nl>  <nl> -# ifdef _KERNEL <nl> - struct disklabel ; <nl> - int bounds_check_with_label __P (( struct buf *, struct disklabel *, int )); <nl> -# endif <nl> - <nl> # endif /* _MACHINE_DISKLABEL_H_ */
elf32_arm_size_dynamic_sections ( bfd * output_bfd ATTRIBUTE_UNUSED , <nl> if ( elf_hash_table ( info )-> dynamic_sections_created ) <nl> { <nl> /* Set the contents of the . interp section to the interpreter . */ <nl> - if ( info -> executable ) <nl> + if ( info -> executable && ! info -> static_link ) <nl> { <nl> s = bfd_get_section_by_name ( dynobj , ". interp "); <nl> BFD_ASSERT ( s != NULL );
_dl_lookup_symbol ( const char * undef_name , const Elf32_Sym ** ref , <nl> { <nl> Elf32_Addr a ; <nl> const Elf32_Sym * s ; <nl> - } weak_value = { 0 , NULL }; <nl> + } weak_value ; /* = { 0 , NULL }; breaks GCC 2 . 8 due to implicit memset */ <nl> + <nl> + _dl_memset (& weak_value , 0 , sizeof ( weak_value )); <nl>  <nl> /* Search the relevant loaded objects for a definition . */ <nl> for ( map = symbol_scope ; map ; map = map -> next )
void feedlist_formaction :: process_operation ( operation op , bool automatic , std :: v <nl> case OP_OPENINBROWSER : { <nl> std :: tr1 :: shared_ptr < rss_feed > feed = v -> get_ctrl ()-> get_feed ( pos ); <nl> if ( feed ) { <nl> + LOG ( LOG_INFO , " feedlist_formaction : opening feed at position `% s ': % s ", feedpos . c_str (), feed -> link (). c_str ()); <nl> v -> open_in_browser ( feed -> link ()); <nl> } <nl> }
static target_ulong disas_insn ( DisasContext * s , target_ulong pc_start ) <nl> tval += s -> pc - s -> cs_base ; <nl> if ( s -> dflag == 0 ) <nl> tval &= 0xffff ; <nl> + else if (! CODE64 ( s )) <nl> + tval &= 0xffffffff ; <nl> gen_jmp ( s , tval ); <nl> break ; <nl> case 0xea : /* ljmp im */
static const TypeInfo qemu_s390_skeys_info = { <nl> . instance_init = qemu_s390_skeys_init , <nl> . instance_size = sizeof ( QEMUS390SKeysState ), <nl> . class_init = qemu_s390_skeys_class_init , <nl> - . instance_size = sizeof ( S390SKeysClass ), <nl> + . class_size = sizeof ( S390SKeysClass ), <nl> }; <nl>  <nl> static void s390_storage_keys_save ( QEMUFile * f , void * opaque )
void qemu_chr_be_write ( CharDriverState * s , uint8_t * buf , int len ) <nl> int qemu_chr_fe_get_msgfd ( CharDriverState * s ) <nl> { <nl> int fd ; <nl> - return ( qemu_chr_fe_get_msgfds ( s , & fd , 1 ) >= 0 ) ? fd : - 1 ; <nl> + return ( qemu_chr_fe_get_msgfds ( s , & fd , 1 ) == 1 ) ? fd : - 1 ; <nl> } <nl>  <nl> int qemu_chr_fe_get_msgfds ( CharDriverState * s , int * fds , int len )
static int elf_core_dump ( int signr , const CPUArchState * env ) <nl> phdr . p_align = ELF_EXEC_PAGESIZE ; <nl>  <nl> bswap_phdr (& phdr , 1 ); <nl> - dump_write ( fd , & phdr , sizeof ( phdr )); <nl> + if ( dump_write ( fd , & phdr , sizeof ( phdr )) != 0 ) { <nl> + goto out ; <nl> + } <nl> } <nl>  <nl> /*
CPUArchState * cpu_copy ( CPUArchState * env ) <nl> { <nl> CPUState * cpu = ENV_GET_CPU ( env ); <nl> CPUState * new_cpu = cpu_init ( cpu_model ); <nl> - CPUArchState * new_env = cpu -> env_ptr ; <nl> + CPUArchState * new_env = new_cpu -> env_ptr ; <nl> CPUBreakpoint * bp ; <nl> CPUWatchpoint * wp ; <nl> 
int rom_add_file ( const char * file , const char * fw_dir , <nl> err : <nl> if ( fd != - 1 ) <nl> close ( fd ); <nl> + <nl> g_free ( rom -> data ); <nl> g_free ( rom -> path ); <nl> g_free ( rom -> name ); <nl> + if ( fw_dir ) { <nl> + g_free ( rom -> fw_dir ); <nl> + g_free ( rom -> fw_file ); <nl> + } <nl> g_free ( rom ); <nl> + <nl> return - 1 ; <nl> } <nl> 
do_check_protect_pse36 : <nl>  <nl> /* the page can be put in the TLB */ <nl> prot = PAGE_READ ; <nl> - if (!( ptep & PG_NX_MASK )) <nl> + if (!( ptep & PG_NX_MASK ) && <nl> + !(( env -> cr [ 4 ] & CR4_SMEP_MASK ) && ( ptep & PG_USER_MASK ))) { <nl> prot |= PAGE_EXEC ; <nl> + } <nl> if ( pte & PG_DIRTY_MASK ) { <nl> /* only set write access if already dirty ... otherwise wait <nl> for dirty access */
e1000e_set_pbaclr ( E1000ECore * core , int index , uint32_t val ) <nl>  <nl> core -> mac [ PBACLR ] = val & E1000_PBACLR_VALID_MASK ; <nl>  <nl> - if ( msix_enabled ( core -> owner )) { <nl> + if (! msix_enabled ( core -> owner )) { <nl> return ; <nl> } <nl> 
static int img_check ( int argc , char ** argv ) <nl> static const struct option long_options [] = { <nl> {" help ", no_argument , 0 , ' h '}, <nl> {" format ", required_argument , 0 , ' f '}, <nl> - {" repair ", no_argument , 0 , ' r '}, <nl> + {" repair ", required_argument , 0 , ' r '}, <nl> {" output ", required_argument , 0 , OPTION_OUTPUT }, <nl> { 0 , 0 , 0 , 0 } <nl> };
void * address_space_map ( AddressSpace * as , <nl> if ( bounce . buffer ) { <nl> return NULL ; <nl> } <nl> - bounce . buffer = qemu_memalign ( TARGET_PAGE_SIZE , TARGET_PAGE_SIZE ); <nl> + /* Avoid unbounded allocations */ <nl> + l = MIN ( l , TARGET_PAGE_SIZE ); <nl> + bounce . buffer = qemu_memalign ( TARGET_PAGE_SIZE , l ); <nl> bounce . addr = addr ; <nl> bounce . len = l ; <nl> 
static Qcow2BitmapList * bitmap_list_load ( BlockDriverState * bs , uint64_t offset , <nl> goto fail ; <nl> } <nl>  <nl> - bm = g_new ( Qcow2Bitmap , 1 ); <nl> + bm = g_new0 ( Qcow2Bitmap , 1 ); <nl> bm -> table . offset = e -> bitmap_table_offset ; <nl> bm -> table . size = e -> bitmap_table_size ; <nl> bm -> flags = e -> flags ;
int pci_piix3_xen_ide_unplug ( DeviceState * dev ) <nl> { <nl> PCIIDEState * pci_ide ; <nl> DriveInfo * di ; <nl> - int i = 0 ; <nl> + int i ; <nl>  <nl> pci_ide = PCI_IDE ( dev ); <nl>  <nl> - for (; i < 3 ; i ++) { <nl> + for ( i = 0 ; i < 4 ; i ++) { <nl> di = drive_get_by_index ( IF_IDE , i ); <nl> if ( di != NULL && ! di -> media_cd ) { <nl> BlockBackend * blk = blk_by_legacy_dinfo ( di );
static int usb_msd_initfn ( USBDevice * dev ) <nl> usb_msd_handle_reset ( dev ); <nl>  <nl> if ( bdrv_key_required ( s -> conf . dinfo -> bdrv )) { <nl> - if ( s -> dev . qdev . hotplugged ) { <nl> + if ( cur_mon ) { <nl> monitor_read_bdrv_key_start ( cur_mon , s -> conf . dinfo -> bdrv , <nl> usb_msd_password_cb , s ); <nl> s -> dev . auto_attach = 0 ;
struct TranslationBlock ; <nl> typedef struct TranslationBlock TranslationBlock ; <nl>  <nl> /* XXX : make safe guess about sizes */ <nl> -# if ( HOST_LONG_BITS == 32 ) && ( TARGET_LONG_BITS == 64 ) <nl> -# define MAX_OP_PER_INSTR 128 <nl> -# else <nl> -# define MAX_OP_PER_INSTR 96 <nl> -# endif <nl> +# define MAX_OP_PER_INSTR 208 <nl>  <nl> # if HOST_LONG_BITS == 32 <nl> # define MAX_OPC_PARAM_PER_ARG 2
static uint64_t coroutine_fn mirror_iteration ( MirrorBlockJob * s ) <nl> nb_chunks * sectors_per_chunk ); <nl> bitmap_set ( s -> in_flight_bitmap , sector_num / sectors_per_chunk , nb_chunks ); <nl> while ( nb_chunks > 0 && sector_num < end ) { <nl> - int ret ; <nl> + int64_t ret ; <nl> int io_sectors , io_sectors_acct ; <nl> BlockDriverState * file ; <nl> enum MirrorMethod {
static uint64_t msix_pba_mmio_read ( void * opaque , hwaddr addr , <nl> return pci_get_long ( dev -> msix_pba + addr ); <nl> } <nl>  <nl> + static void msix_pba_mmio_write ( void * opaque , hwaddr addr , <nl> + uint64_t val , unsigned size ) <nl> +{ <nl> +} <nl> + <nl> static const MemoryRegionOps msix_pba_mmio_ops = { <nl> . read = msix_pba_mmio_read , <nl> + . write = msix_pba_mmio_write , <nl> . endianness = DEVICE_LITTLE_ENDIAN , <nl> . valid = { <nl> . min_access_size = 4 ,
static int scsi_disk_emulate_inquiry ( SCSIRequest * req , uint8_t * outbuf ) <nl> } <nl>  <nl> l = strlen ( s -> serial ); <nl> - if ( l > 20 ) { <nl> - l = 20 ; <nl> + if ( l > 36 ) { <nl> + l = 36 ; <nl> } <nl>  <nl> DPRINTF (" Inquiry EVPD [ Serial number ] "
static void tcp_chr_tls_handshake ( QIOTask * task , <nl> if ( qio_task_propagate_error ( task , NULL )) { <nl> tcp_chr_disconnect ( chr ); <nl> } else { <nl> - /* tn3270 does not support TLS yet */ <nl> - if ( s -> do_telnetopt && ! s -> is_tn3270 ) { <nl> + if ( s -> do_telnetopt ) { <nl> tcp_chr_telnet_init ( chr ); <nl> } else { <nl> tcp_chr_connect ( chr );
static void qemu_rdma_cleanup ( RDMAContext * rdma ) <nl> rdma_destroy_event_channel ( rdma -> channel ); <nl> rdma -> channel = NULL ; <nl> } <nl> + g_free ( rdma -> host ); <nl> + rdma -> host = NULL ; <nl> } <nl>  <nl> 
static inline void setcc ( S390CPU * cpu , uint64_t cc ) <nl>  <nl> env -> psw . mask &= ~( 3ull << 44 ); <nl> env -> psw . mask |= ( cc & 3 ) << 44 ; <nl> + env -> cc_op = cc ; <nl> } <nl>  <nl> typedef struct LowCore
void target_set_brk ( abi_ulong new_brk ) <nl> abi_long do_brk ( abi_ulong new_brk ) <nl> { <nl> abi_long mapped_addr ; <nl> - int new_alloc_size ; <nl> + abi_ulong new_alloc_size ; <nl>  <nl> DEBUGF_BRK (" do_brk (" TARGET_ABI_FMT_lx ") -> ", new_brk ); <nl> 
static void vhost_user_cleanup ( NetClientState * nc ) <nl> s -> vhost_net = NULL ; <nl> } <nl> if ( nc -> queue_index == 0 ) { <nl> + if ( s -> watch ) { <nl> + g_source_remove ( s -> watch ); <nl> + s -> watch = 0 ; <nl> + } <nl> qemu_chr_fe_deinit (& s -> chr , true ); <nl> } <nl> 
static void gen_sync ( DisasContext * ctx ) <nl> /* wait */ <nl> static void gen_wait ( DisasContext * ctx ) <nl> { <nl> - TCGv_i32 t0 = tcg_temp_new_i32 (); <nl> + TCGv_i32 t0 = tcg_const_i32 ( 1 ); <nl> tcg_gen_st_i32 ( t0 , cpu_env , <nl> - offsetof ( PowerPCCPU , env ) + offsetof ( CPUState , halted )); <nl> tcg_temp_free_i32 ( t0 );
static bool blit_is_unsafe ( struct CirrusVGAState * s ) <nl> assert ( s -> cirrus_blt_width > 0 ); <nl> assert ( s -> cirrus_blt_height > 0 ); <nl>  <nl> + if ( s -> cirrus_blt_width > CIRRUS_BLTBUFSIZE ) { <nl> + return true ; <nl> + } <nl> + <nl> if ( blit_region_is_unsafe ( s , s -> cirrus_blt_dstpitch , <nl> s -> cirrus_blt_dstaddr & s -> cirrus_addr_mask )) { <nl> return true ;
static void esp_pci_dma_memory_rw ( PCIESPState * pci , uint8_t * buf , int len , <nl> /* update status registers */ <nl> pci -> dma_regs [ DMA_WBC ] -= len ; <nl> pci -> dma_regs [ DMA_WAC ] += len ; <nl> - if ( pci -> dma_regs [ DMA_WBC ] == 0 ) <nl> + if ( pci -> dma_regs [ DMA_WBC ] == 0 ) { <nl> pci -> dma_regs [ DMA_STAT ] |= DMA_STAT_DONE ; <nl> + } <nl> } <nl>  <nl> static void esp_pci_dma_memory_read ( void * opaque , uint8_t * buf , int len )
# include " exec / cpu - defs . h " <nl> # define TARGET_PAGE_BITS 12 <nl>  <nl> -# define TARGET_PHYS_ADDR_SPACE_BITS 64 <nl> +/* Actually 64 - bits , limited by the memory API to 62 bits . We <nl> + * never use that much . <nl> + */ <nl> +# define TARGET_PHYS_ADDR_SPACE_BITS 62 <nl> # define TARGET_VIRT_ADDR_SPACE_BITS 64 <nl>  <nl> # include " exec / cpu - all . h "
static int qemu_rdma_broken_ipv6_kernel ( Error ** errp , struct ibv_context * verbs ) <nl>  <nl> for ( x = 0 ; x < num_devices ; x ++) { <nl> verbs = ibv_open_device ( dev_list [ x ]); <nl> + if (! verbs ) { <nl> + if ( errno == EPERM ) { <nl> + continue ; <nl> + } else { <nl> + return - EINVAL ; <nl> + } <nl> + } <nl>  <nl> if ( ibv_query_port ( verbs , 1 , & port_attr )) { <nl> ibv_close_device ( verbs );
size_t ram_control_save_page ( QEMUFile * f , ram_addr_t block_offset , <nl> offset , size , bytes_sent ); <nl>  <nl> if ( ret != RAM_SAVE_CONTROL_DELAYED ) { <nl> - if (* bytes_sent > 0 ) { <nl> + if ( bytes_sent && * bytes_sent > 0 ) { <nl> qemu_update_position ( f , * bytes_sent ); <nl> } else if ( ret < 0 ) { <nl> qemu_file_set_error ( f , ret );
static void dump_map_entry ( OutputFormat output_format , MapEntry * e , <nl> ( e -> flags & BDRV_BLOCK_ZERO ) ? " true " : " false ", <nl> ( e -> flags & BDRV_BLOCK_DATA ) ? " true " : " false "); <nl> if ( e -> flags & BDRV_BLOCK_OFFSET_VALID ) { <nl> - printf (", ' offset ': %" PRId64 "", e -> offset ); <nl> + printf (", \" offset \": %" PRId64 "", e -> offset ); <nl> } <nl> putchar ('}'); <nl> 
void qemu_spice_create_host_primary ( SimpleSpiceDisplay * ssd ) <nl> { <nl> QXLDevSurfaceCreate surface ; <nl>  <nl> + memset (& surface , 0 , sizeof ( surface )); <nl> + <nl> dprint ( 1 , "% s : % dx % d \ n ", __FUNCTION__ , <nl> ds_get_width ( ssd -> ds ), ds_get_height ( ssd -> ds )); <nl> 
static int parse_drive ( DeviceState * dev , Property * prop , const char * str ) <nl> static int print_drive ( DeviceState * dev , Property * prop , char * dest , size_t len ) <nl> { <nl> DriveInfo ** ptr = qdev_get_prop_ptr ( dev , prop ); <nl> - return snprintf ( dest , len , "% s ", (* ptr )-> id ); <nl> + return snprintf ( dest , len , "% s ", (* ptr ) ? (* ptr )-> id : "< null >"); <nl> } <nl>  <nl> PropertyInfo qdev_prop_drive = {
static sd_rsp_type_t sd_app_command ( SDState * sd , <nl> } <nl>  <nl> fprintf ( stderr , " SD : ACMD % i in a wrong state \ n ", req . cmd ); <nl> - return sd_r0 ; <nl> + return sd_illegal ; <nl> } <nl>  <nl> static int cmd_valid_while_locked ( SDState * sd , SDRequest * req )
static int64_t seek_to_sector ( BlockDriverState * bs , int64_t sector_num ) <nl> offset = sector_num % s -> tracks ; <nl>  <nl> /* not allocated */ <nl> - if (( index > s -> catalog_size ) || ( s -> catalog_bitmap [ index ] == 0 )) <nl> + if (( index >= s -> catalog_size ) || ( s -> catalog_bitmap [ index ] == 0 )) <nl> return - 1 ; <nl> return <nl> (( uint64_t ) s -> catalog_bitmap [ index ] * s -> off_multiplier + offset ) * 512 ;
glue ( glue ( cirrus_bitblt_rop_bkwd_transp_ , ROP_NAME ), _16 )( CirrusVGAState * s , <nl> srcpitch += bltwidth ; <nl> for ( y = 0 ; y < bltheight ; y ++) { <nl> for ( x = 0 ; x < bltwidth ; x += 2 ) { <nl> - ROP_OP_TR_16 ( s , dstaddr , cirrus_src16 ( s , srcaddr ), transp ); <nl> + ROP_OP_TR_16 ( s , dstaddr - 1 , cirrus_src16 ( s , srcaddr - 1 ), transp ); <nl> dstaddr -= 2 ; <nl> srcaddr -= 2 ; <nl> }
static int slirp_smb ( SlirpState * s , const char * exported_dir , <nl> fprintf ( f , <nl> "[ global ]\ n " <nl> " private dir =% s \ n " <nl> - " smb ports = 0 \ n " <nl> " socket address = 127 . 0 . 0 . 1 \ n " <nl> " pid directory =% s \ n " <nl> " lock directory =% s \ n "
static void omap2_gpio_module_write ( void * opaque , target_phys_addr_t addr , <nl>  <nl> static uint32_t omap2_gpio_module_readp ( void * opaque , target_phys_addr_t addr ) <nl> { <nl> - return omap2_gpio_module_readp ( opaque , addr ) >> (( addr & 3 ) << 3 ); <nl> + return omap2_gpio_module_read ( opaque , addr & ~ 3 ) >> (( addr & 3 ) << 3 ); <nl> } <nl>  <nl> static void omap2_gpio_module_writep ( void * opaque , target_phys_addr_t addr ,
static gboolean ga_channel_listen_accept ( GIOChannel * channel , <nl> ret = ga_channel_client_add ( c , client_fd ); <nl> if ( ret ) { <nl> g_warning (" error setting up connection "); <nl> + close ( client_fd ); <nl> goto out ; <nl> } <nl> accepted = true ;
static int ide_drive_pio_post_load ( void * opaque , int version_id ) <nl> { <nl> IDEState * s = opaque ; <nl>  <nl> - if ( s -> end_transfer_fn_idx > ARRAY_SIZE ( transfer_end_table )) { <nl> + if ( s -> end_transfer_fn_idx >= ARRAY_SIZE ( transfer_end_table )) { <nl> return - EINVAL ; <nl> } <nl> s -> end_transfer_func = transfer_end_table [ s -> end_transfer_fn_idx ];
PCIDevice * pci_nic_init_nofail ( NICInfo * nd , PCIBus * rootbus , <nl>  <nl> res = pci_nic_init ( nd , rootbus , default_model , default_devaddr , & err ); <nl> if (! res ) { <nl> - error_report_err ( err ); <nl> + if ( err ) { <nl> + error_report_err ( err ); <nl> + } <nl> exit ( 1 ); <nl> } <nl> return res ;
static void pprint_data ( V9fsPDU * pdu , int rx , size_t * offsetp , const char * name ) <nl>  <nl> if ( rx ) { <nl> count = pdu -> elem . in_num ; <nl> - } else <nl> + } else { <nl> count = pdu -> elem . out_num ; <nl> } <nl> 
static void lan9118_eeprom_cmd ( lan9118_state * s , int cmd , int addr ) <nl> } else { <nl> DPRINTF (" EEPROM Write All ( ignored )\ n "); <nl> } <nl> + break ; <nl> case 5 : /* ERASE */ <nl> if ( s -> eeprom_writable ) { <nl> s -> eeprom [ addr ] = 0xff ;
static int grow_refcount_table ( BlockDriverState * bs , int min_size ) <nl> qemu_free ( s -> refcount_table ); <nl> s -> refcount_table = new_table ; <nl> s -> refcount_table_size = new_table_size ; <nl> + s -> refcount_table_offset = table_offset ; <nl>  <nl> update_refcount ( bs , table_offset , new_table_size2 , 1 ); <nl> return 0 ;
int do_snapshot_blkdev ( Monitor * mon , const QDict * qdict , QObject ** ret_data ) <nl> int ret = 0 ; <nl> int flags ; <nl>  <nl> + if (! filename ) { <nl> + qerror_report ( QERR_MISSING_PARAMETER , " snapshot_file "); <nl> + ret = - 1 ; <nl> + goto out ; <nl> + } <nl> + <nl> bs = bdrv_find ( device ); <nl> if (! bs ) { <nl> qerror_report ( QERR_DEVICE_NOT_FOUND , device );
static always_inline int translate_one ( DisasContext * ctx , uint32_t insn ) <nl> break ; <nl> case 0x2C : <nl> /* XXX : incorrect */ <nl> - if ( fn11 == 0x2AC ) { <nl> + if ( fn11 == 0x2AC || fn11 == 0x6AC ) { <nl> /* CVTST */ <nl> gen_farith2 (& helper_cvtst , rb , rc ); <nl> } else {
abi_long target_mmap ( abi_ulong start , abi_ulong len , int prot , <nl> goto fail ; <nl> if (!( prot & PROT_WRITE )) { <nl> ret = target_mprotect ( start , len , prot ); <nl> - if ( ret != 0 ) { <nl> - start = ret ; <nl> - goto the_end ; <nl> - } <nl> + assert ( ret == 0 ); <nl> } <nl> goto the_end ; <nl> }
static void pc_fw_add_pflash_drv ( void ) <nl> return ; <nl> } <nl>  <nl> - drive_init ( opts , machine -> use_scsi ); <nl> + if (! drive_init ( opts , machine -> use_scsi )) { <nl> + qemu_opts_del ( opts ); <nl> + } <nl> } <nl>  <nl> static void pc_system_flash_init ( MemoryRegion * rom_memory ,
static ImageInfoSpecific * qcow2_get_specific_info ( BlockDriverState * bs ) <nl> . lazy_refcounts = s -> compatible_features & <nl> QCOW2_COMPAT_LAZY_REFCOUNTS , <nl> . has_lazy_refcounts = true , <nl> + . corrupt = s -> incompatible_features & <nl> + QCOW2_INCOMPAT_CORRUPT , <nl> + . has_corrupt = true , <nl> }; <nl> } <nl> 
static uint64_t serial_ioport_read ( void * opaque , hwaddr addr , unsigned size ) <nl> ret = s -> divider & 0xff ; <nl> } else { <nl> if ( s -> fcr & UART_FCR_FE ) { <nl> - ret = fifo8_is_full (& s -> recv_fifo ) ? <nl> + ret = fifo8_is_empty (& s -> recv_fifo ) ? <nl> 0 : fifo8_pop (& s -> recv_fifo ); <nl> if ( s -> recv_fifo . num == 0 ) { <nl> s -> lsr &= ~( UART_LSR_DR | UART_LSR_BI );
static int cryptodev_builtin_create_cipher_session ( <nl> return - 1 ; <nl> } <nl> break ; <nl> + case VIRTIO_CRYPTO_CIPHER_AES_XTS : <nl> + mode = QCRYPTO_CIPHER_MODE_XTS ; <nl> + algo = cryptodev_builtin_get_aes_algo ( sess_info -> key_len , <nl> + mode , errp ); <nl> + if ( algo < 0 ) { <nl> + return - 1 ; <nl> + } <nl> + break ; <nl> case VIRTIO_CRYPTO_CIPHER_DES_ECB : <nl> mode = QCRYPTO_CIPHER_MODE_ECB ; <nl> algo = QCRYPTO_CIPHER_ALG_DES_RFB ;
static int vmdk_parent_open ( BlockDriverState * bs , const char * filename ) <nl> p_name += sizeof (" parentFileNameHint ") + 1 ; <nl> if (( end_name = strchr ( p_name ,'\"')) == 0 ) <nl> return - 1 ; <nl> + if (( end_name - p_name ) > sizeof ( s -> hd -> backing_file ) - 1 ) <nl> + return - 1 ; <nl>  <nl> strncpy ( s -> hd -> backing_file , p_name , end_name - p_name ); <nl> if ( stat ( s -> hd -> backing_file , & file_buf ) != 0 ) {
static bool scsi_block_is_passthrough ( SCSIDiskState * s , uint8_t * buf ) <nl> * for the number of logical blocks specified in the length <nl> * field ). For other modes , do not use scatter / gather operation . <nl> */ <nl> - if (( buf [ 1 ] & 6 ) != 2 ) { <nl> + if (( buf [ 1 ] & 6 ) == 2 ) { <nl> return false ; <nl> } <nl> break ;
fail : <nl>  <nl> if ( use_local_qiov ) { <nl> qemu_iovec_destroy (& local_qiov ); <nl> - qemu_vfree ( head_buf ); <nl> - qemu_vfree ( tail_buf ); <nl> } <nl> + qemu_vfree ( head_buf ); <nl> + qemu_vfree ( tail_buf ); <nl>  <nl> return ret ; <nl> }
static int usb_xhci_initfn ( struct PCIDevice * dev ) <nl> if ( xhci -> numintrs > MAXINTRS ) { <nl> xhci -> numintrs = MAXINTRS ; <nl> } <nl> + while ( xhci -> numintrs & ( xhci -> numintrs - 1 )) { /* ! power of 2 */ <nl> + xhci -> numintrs ++; <nl> + } <nl> if ( xhci -> numintrs < 1 ) { <nl> xhci -> numintrs = 1 ; <nl> }
static QTAILQ_HEAD ( CharDriverStateHead , CharDriverState ) chardevs = <nl> CharDriverState * qemu_chr_alloc ( void ) <nl> { <nl> CharDriverState * chr = g_malloc0 ( sizeof ( CharDriverState )); <nl> + qemu_mutex_init (& chr -> chr_write_lock ); <nl> return chr ; <nl> } <nl> 
static void usb_msd_realize_storage ( USBDevice * dev , Error ** errp ) <nl> error_propagate ( errp , err ); <nl> return ; <nl> } <nl> - s -> bus . qbus . allow_hotplug = 0 ; <nl> usb_msd_handle_reset ( dev ); <nl>  <nl> if ( bdrv_key_required ( bs )) {
static void assign_failed_examine ( AssignedDevice * dev ) <nl> goto fail ; <nl> } <nl>  <nl> + driver [ r ] = 0 ; <nl> ns = strrchr ( driver , '/'); <nl> if (! ns ) { <nl> goto fail ;
static void i6300esb_restart_timer ( I6300State * d , int stage ) <nl> * multiply here can exceed 64 - bits , before we divide by 33MHz , so <nl> * we use a higher - precision intermediate result . <nl> */ <nl> - timeout = muldiv64 ( get_ticks_per_sec (), timeout , 33000000 ); <nl> + timeout = muldiv64 ( timeout , get_ticks_per_sec (), 33000000 ); <nl>  <nl> i6300esb_debug (" stage % d , timeout %" PRIi64 "\ n ", d -> stage , timeout ); <nl> 
static int disas_neon_data_insn ( CPUState * env , DisasContext * s , uint32_t insn ) <nl> } <nl> tmp3 = neon_load_reg ( rm , 1 ); <nl> gen_helper_neon_tbl ( tmp3 , tmp3 , tmp , tmp4 , tmp5 ); <nl> - dead_tmp ( tmp5 ); <nl> - dead_tmp ( tmp4 ); <nl> + tcg_temp_free_i32 ( tmp5 ); <nl> + tcg_temp_free_i32 ( tmp4 ); <nl> neon_store_reg ( rd , 0 , tmp2 ); <nl> neon_store_reg ( rd , 1 , tmp3 ); <nl> dead_tmp ( tmp );
static ssize_t nc_sendv_compat ( NetClientState * nc , const struct iovec * iov , <nl> offset = iov [ 0 ]. iov_len ; <nl> } else { <nl> buffer = buf ; <nl> - offset = iov_to_buf ( iov , iovcnt , 0 , buffer , sizeof ( buffer )); <nl> + offset = iov_to_buf ( iov , iovcnt , 0 , buf , sizeof ( buf )); <nl> } <nl>  <nl> if ( flags & QEMU_NET_PACKET_FLAG_RAW && nc -> info -> receive_raw ) {
void memory_mapping_filter ( MemoryMappingList * list , int64_t begin , <nl> if ( cur -> phys_addr >= begin + length || <nl> cur -> phys_addr + cur -> length <= begin ) { <nl> QTAILQ_REMOVE (& list -> head , cur , next ); <nl> + g_free ( cur ); <nl> list -> num --; <nl> continue ; <nl> }
static uint64_t uart_read ( void * opaque , hwaddr addr , <nl> r = s -> regs [ R_RXTX ]; <nl> s -> regs [ R_LSR ] &= ~ LSR_DR ; <nl> uart_update_irq ( s ); <nl> + qemu_chr_accept_input ( s -> chr ); <nl> break ; <nl> case R_IIR : <nl> case R_LSR :
# define XLNX_ZYNQ_DEVCFG ( obj ) \ <nl> OBJECT_CHECK ( XlnxZynqDevcfg , ( obj ), TYPE_XLNX_ZYNQ_DEVCFG ) <nl>  <nl> -# define XLNX_ZYNQ_DEVCFG_R_MAX 0x118 <nl> +# define XLNX_ZYNQ_DEVCFG_R_MAX ( 0x100 / 4 ) <nl>  <nl> # define XLNX_ZYNQ_DEVCFG_DMA_CMD_FIFO_LEN 10 <nl> 
static ssize_t qcow2_crypto_hdr_init_func ( QCryptoBlock * block , size_t headerlen , <nl> /* Zero fill remaining space in cluster so it has predictable <nl> * content in case of future spec changes */ <nl> clusterlen = size_to_clusters ( s , headerlen ) * s -> cluster_size ; <nl> + assert ( qcow2_pre_write_overlap_check ( bs , 0 , ret , clusterlen ) == 0 ); <nl> ret = bdrv_pwrite_zeroes ( bs -> file , <nl> ret + headerlen , <nl> clusterlen - headerlen , 0 );
static Property vhost_scsi_properties [] = { <nl> DEFINE_PROP_STRING (" wwpn ", VirtIOSCSICommon , conf . wwpn ), <nl> DEFINE_PROP_UINT32 (" boot_tpgt ", VirtIOSCSICommon , conf . boot_tpgt , 0 ), <nl> DEFINE_PROP_UINT32 (" num_queues ", VirtIOSCSICommon , conf . num_queues , 1 ), <nl> + DEFINE_PROP_UINT32 (" virtqueue_size ", VirtIOSCSICommon , conf . virtqueue_size , <nl> + 128 ), <nl> DEFINE_PROP_UINT32 (" max_sectors ", VirtIOSCSICommon , conf . max_sectors , <nl> 0xFFFF ), <nl> DEFINE_PROP_UINT32 (" cmd_per_lun ", VirtIOSCSICommon , conf . cmd_per_lun , 128 ),
static int qdev_add_one_global ( QemuOpts * opts , void * opaque ) <nl> g -> driver = qemu_opt_get ( opts , " driver "); <nl> g -> property = qemu_opt_get ( opts , " property "); <nl> g -> value = qemu_opt_get ( opts , " value "); <nl> - oc = object_class_by_name ( g -> driver ); <nl> + oc = object_class_dynamic_cast ( object_class_by_name ( g -> driver ), <nl> + TYPE_DEVICE ); <nl> if ( oc ) { <nl> DeviceClass * dc = DEVICE_CLASS ( oc ); <nl> 
static ssize_t gem_receive ( VLANClientState * nc , const uint8_t * buf , size_t size ) <nl> */ <nl>  <nl> memcpy ( rxbuf , buf , size ); <nl> - memset ( rxbuf + size , 0 , sizeof ( rxbuf - size )); <nl> + memset ( rxbuf + size , 0 , sizeof ( rxbuf ) - size ); <nl> rxbuf_ptr = rxbuf ; <nl> crc_val = cpu_to_le32 ( crc32 ( 0 , rxbuf , MAX ( size , 60 ))); <nl> if ( size < 60 ) {
static GSList * gd_vc_gfx_init ( GtkDisplayState * s , VirtualConsole * vc , <nl> QemuConsole * con , int idx , <nl> GSList * group , GtkWidget * view_menu ) <nl> { <nl> - Error * local_err = NULL ; <nl> Object * obj ; <nl>  <nl> - obj = object_property_get_link ( OBJECT ( con ), " device ", & local_err ); <nl> + obj = object_property_get_link ( OBJECT ( con ), " device ", NULL ); <nl> if ( obj ) { <nl> vc -> label = g_strdup_printf ("% s ", object_get_typename ( obj )); <nl> } else {
void qemu_ram_remap ( ram_addr_t addr , ram_addr_t length ) <nl> abort (); <nl> } else { <nl> flags = MAP_FIXED ; <nl> - munmap ( vaddr , length ); <nl> if ( block -> fd >= 0 ) { <nl> flags |= ( block -> flags & RAM_SHARED ? <nl> MAP_SHARED : MAP_PRIVATE );
int qemu_chr_fe_write ( CharDriverState * s , const uint8_t * buf , int len ) <nl> int qemu_chr_fe_write_all ( CharDriverState * s , const uint8_t * buf , int len ) <nl> { <nl> int offset = 0 ; <nl> - int res ; <nl> + int res = 0 ; <nl>  <nl> qemu_mutex_lock (& s -> chr_write_lock ); <nl> while ( offset < len ) {
static abi_ulong mmap_find_vma_reserved ( abi_ulong start , abi_ulong size ) <nl> if ( prot ) { <nl> end_addr = addr ; <nl> } <nl> - if ( addr + size == end_addr ) { <nl> + if ( addr && addr + size == end_addr ) { <nl> break ; <nl> } <nl> addr -= qemu_host_page_size ;
static inline abi_long do_semctl ( int semid , int semnum , int cmd , <nl> { <nl> union semun arg ; <nl> struct semid_ds dsarg ; <nl> - unsigned short * array ; <nl> + unsigned short * array = NULL ; <nl> struct seminfo seminfo ; <nl> abi_long ret = - TARGET_EINVAL ; <nl> abi_long err ;
Coroutine * qemu_coroutine_new ( void ) <nl> stack_t oss ; <nl> sigset_t sigs ; <nl> sigset_t osigs ; <nl> - jmp_buf old_env ; <nl> + sigjmp_buf old_env ; <nl>  <nl> /* The way to manipulate stack is with the sigaltstack function . We <nl> * prepare a stack , with it delivering a signal to ourselves and then
qcrypto_tls_session_check_certificate ( QCryptoTLSSession * session , <nl>  <nl> allow = qemu_acl_party_is_allowed ( acl , session -> peername ); <nl>  <nl> - error_setg ( errp , " TLS x509 ACL check for % s is % s ", <nl> - session -> peername , allow ? " allowed " : " denied "); <nl> if (! allow ) { <nl> + error_setg ( errp , " TLS x509 ACL check for % s is denied ", <nl> + session -> peername ); <nl> goto error ; <nl> } <nl> }
static void kvm_apic_realize ( DeviceState * dev , Error ** errp ) <nl> { <nl> APICCommonState * s = APIC_COMMON ( dev ); <nl>  <nl> - memory_region_init_io (& s -> io_memory , NULL , & kvm_apic_io_ops , s , " kvm - apic - msi ", <nl> - APIC_SPACE_SIZE ); <nl> + memory_region_init_io (& s -> io_memory , OBJECT ( s ), & kvm_apic_io_ops , s , <nl> + " kvm - apic - msi ", APIC_SPACE_SIZE ); <nl>  <nl> if ( kvm_has_gsi_routing ()) { <nl> msi_nonbroken = true ;
static int alloc_refcount_block ( BlockDriverState * bs , <nl> uint64_t last_table_size ; <nl> uint64_t blocks_clusters ; <nl> do { <nl> - uint64_t table_clusters = size_to_clusters ( s , table_size ); <nl> + uint64_t table_clusters = <nl> + size_to_clusters ( s , table_size * sizeof ( uint64_t )); <nl> blocks_clusters = 1 + <nl> (( table_clusters + refcount_block_clusters - 1 ) <nl> / refcount_block_clusters );
static void ivshmem_read ( void * opaque , const uint8_t * buf , int size ) <nl> if ( incoming_posn == - 1 ) { <nl> void * map_ptr ; <nl>  <nl> + if ( s -> shm_fd >= 0 ) { <nl> + error_report (" shm already initialized "); <nl> + close ( incoming_fd ); <nl> + return ; <nl> + } <nl> + <nl> if ( check_shm_size ( s , incoming_fd , & err ) == - 1 ) { <nl> error_report_err ( err ); <nl> close ( incoming_fd );
void tcg_gen_ld8u_i64 ( TCGv_i64 ret , TCGv_ptr arg2 , tcg_target_long offset ) <nl> void tcg_gen_ld8s_i64 ( TCGv_i64 ret , TCGv_ptr arg2 , tcg_target_long offset ) <nl> { <nl> tcg_gen_ld8s_i32 ( TCGV_LOW ( ret ), arg2 , offset ); <nl> - tcg_gen_sari_i32 ( TCGV_HIGH ( ret ), TCGV_HIGH ( ret ), 31 ); <nl> + tcg_gen_sari_i32 ( TCGV_HIGH ( ret ), TCGV_LOW ( ret ), 31 ); <nl> } <nl>  <nl> void tcg_gen_ld16u_i64 ( TCGv_i64 ret , TCGv_ptr arg2 , tcg_target_long offset )
 <nl> static inline bool virtio_access_is_big_endian ( VirtIODevice * vdev ) <nl> { <nl> +# if defined ( TARGET_IS_BIENDIAN ) <nl> + return virtio_is_big_endian ( vdev ); <nl> +# elif defined ( TARGET_WORDS_BIGENDIAN ) <nl> if ( virtio_vdev_has_feature ( vdev , VIRTIO_F_VERSION_1 )) { <nl> /* Devices conforming to VIRTIO 1 . 0 or later are always LE . */ <nl> return false ; <nl> } <nl> -# if defined ( TARGET_IS_BIENDIAN ) <nl> - return virtio_is_big_endian ( vdev ); <nl> -# elif defined ( TARGET_WORDS_BIGENDIAN ) <nl> return true ; <nl> # else <nl> return false ;
uint64_t pc_dimm_get_free_addr ( uint64_t address_space_start , <nl> uint64_t address_space_end = address_space_start + address_space_size ; <nl>  <nl> g_assert ( QEMU_ALIGN_UP ( address_space_start , align ) == address_space_start ); <nl> - g_assert ( QEMU_ALIGN_UP ( address_space_size , align ) == address_space_size ); <nl>  <nl> if (! address_space_size ) { <nl> error_setg ( errp , " memory hotplug is not enabled , "
DisplaySurface * qemu_create_displaysurface_guestmem ( int width , int height , <nl> linesize = width * PIXMAN_FORMAT_BPP ( format ) / 8 ; <nl> } <nl>  <nl> - size = linesize * height ; <nl> + size = ( hwaddr ) linesize * height ; <nl> data = cpu_physical_memory_map ( addr , & size , 0 ); <nl> - if ( size != linesize * height ) { <nl> + if ( size != ( hwaddr ) linesize * height ) { <nl> cpu_physical_memory_unmap ( data , size , 0 , 0 ); <nl> return NULL ; <nl> }
void console_select ( unsigned int index ) <nl> if ( s ) { <nl> DisplayState * ds = s -> ds ; <nl>  <nl> - if ( active_console -> cursor_timer ) { <nl> + if ( active_console && active_console -> cursor_timer ) { <nl> qemu_del_timer ( active_console -> cursor_timer ); <nl> } <nl> active_console = s ;
int cpu_exec ( CPUArchState * env ) <nl> * local variables as longjmp is marked ' noreturn '. */ <nl> cpu = current_cpu ; <nl> env = cpu -> env_ptr ; <nl> +# if !( defined ( CONFIG_USER_ONLY ) && \ <nl> + ( defined ( TARGET_M68K ) || defined ( TARGET_PPC ) || defined ( TARGET_S390X ))) <nl> + cc = CPU_GET_CLASS ( cpu ); <nl> +# endif <nl> } <nl> } /* for (;;) */ <nl> 
static int sd_create ( const char * filename , QemuOpts * opts , <nl> bdrv_unref ( bs ); <nl> } <nl>  <nl> + s -> aio_context = qemu_get_aio_context (); <nl> ret = do_sd_create ( s , & vid , 0 , errp ); <nl> if ( ret ) { <nl> goto out ;
static gboolean qio_channel_websock_handshake_io ( QIOChannel * ioc , <nl> return TRUE ; <nl> } <nl>  <nl> - object_ref ( OBJECT ( task )); <nl> trace_qio_channel_websock_handshake_reply ( ioc ); <nl> qio_channel_add_watch ( <nl> wioc -> master , <nl> G_IO_OUT , <nl> qio_channel_websock_handshake_send , <nl> task , <nl> - ( GDestroyNotify ) object_unref ); <nl> + NULL ); <nl> return FALSE ; <nl> } <nl> 
VHostNetState * get_vhost_net ( NetClientState * nc ) <nl> int vhost_set_vring_enable ( NetClientState * nc , int enable ) <nl> { <nl> VHostNetState * net = get_vhost_net ( nc ); <nl> - const VhostOps * vhost_ops = net -> dev . vhost_ops ; <nl> + const VhostOps * vhost_ops ; <nl> + <nl> + if (! net ) { <nl> + return 0 ; <nl> + } <nl>  <nl> + vhost_ops = net -> dev . vhost_ops ; <nl> if ( vhost_ops -> vhost_set_vring_enable ) { <nl> return vhost_ops -> vhost_set_vring_enable (& net -> dev , enable ); <nl> }
ram_addr_t qemu_ram_alloc_from_ptr ( ram_addr_t size , void * host , <nl>  <nl> qemu_ram_setup_dump ( new_block -> host , size ); <nl> qemu_madvise ( new_block -> host , size , QEMU_MADV_HUGEPAGE ); <nl> + qemu_madvise ( new_block -> host , size , QEMU_MADV_DONTFORK ); <nl>  <nl> if ( kvm_enabled ()) <nl> kvm_setup_guest_memory ( new_block -> host , size );
void cmos_set_s3_resume ( void ) <nl> } <nl>  <nl> static QEMUMachine pc_machine = { <nl> - . name = " pc ", <nl> + . name = " pc - 0 . 11 ", <nl> + . alias = " pc ", <nl> . desc = " Standard PC ", <nl> . init = pc_init_pci , <nl> . max_cpus = 255 ,
static int vhost_kernel_memslots_limit ( struct vhost_dev * dev ) <nl> & s , NULL , NULL )) { <nl> uint64_t val = g_ascii_strtoull ( s , NULL , 10 ); <nl> if (!(( val == G_MAXUINT64 || ! val ) && errno )) { <nl> + g_free ( s ); <nl> return val ; <nl> } <nl> error_report (" ignoring invalid max_mem_regions value in vhost module :" <nl> " % s ", s ); <nl> } <nl> + g_free ( s ); <nl> return limit ; <nl> } <nl> 
static void run_block_job ( BlockJob * job , Error ** errp ) <nl>  <nl> do { <nl> aio_poll ( aio_context , true ); <nl> - qemu_progress_print (( float ) job -> offset / job -> len * 100 . f , 0 ); <nl> + qemu_progress_print ( job -> len ? <nl> + (( float ) job -> offset / job -> len * 100 . f ) : 0 . 0f , 0 ); <nl> } while (! job -> ready ); <nl>  <nl> block_job_complete_sync ( job , errp );
int spapr_h_cas_compose_response ( sPAPRMachineState * spapr , <nl> return 1 ; <nl> } <nl>  <nl> + if ( size < sizeof ( hdr ) || size > FW_MAX_SIZE ) { <nl> + error_report (" SLOF provided an unexpected CAS buffer size " <nl> + TARGET_FMT_lu " ( min : % zu , max : % u )", <nl> + size , sizeof ( hdr ), FW_MAX_SIZE ); <nl> + exit ( EXIT_FAILURE ); <nl> + } <nl> + <nl> size -= sizeof ( hdr ); <nl>  <nl> /* Create skeleton */
QEMUOptionParameter * append_option_parameters ( QEMUOptionParameter * dest , <nl> num_options += count_option_parameters ( list ); <nl>  <nl> dest = qemu_realloc ( dest , ( num_options + 1 ) * sizeof ( QEMUOptionParameter )); <nl> + dest [ num_dest_options ]. name = NULL ; <nl>  <nl> while ( list && list -> name ) { <nl> if ( get_option_parameter ( dest , list -> name ) == NULL ) {
int qcow2_alloc_clusters_at ( BlockDriverState * bs , uint64_t offset , <nl> BDRVQcowState * s = bs -> opaque ; <nl> uint64_t cluster_index ; <nl> uint64_t old_free_cluster_index ; <nl> - int i , refcount , ret ; <nl> + uint64_t i ; <nl> + int refcount , ret ; <nl> + <nl> + assert ( nb_clusters >= 0 ); <nl> + if ( nb_clusters == 0 ) { <nl> + return 0 ; <nl> + } <nl>  <nl> /* Check how many clusters there are free */ <nl> cluster_index = offset >> s -> cluster_bits ;
int main ( int argc , char ** argv , char ** envp ) <nl> HD_OPTS ); <nl> break ; <nl> case QEMU_OPTION_drive : <nl> - drive_def ( optarg ); <nl> + if ( drive_def ( optarg ) == NULL ) { <nl> + exit ( 1 ); <nl> + } <nl> break ; <nl> case QEMU_OPTION_set : <nl> if ( qemu_set_option ( optarg ) != 0 )
static void core_prop_set_core_id ( Object * obj , Visitor * v , const char * name , <nl> return ; <nl> } <nl>  <nl> + if ( value < 0 ) { <nl> + error_setg ( errp , " Invalid core id %" PRId64 , value ); <nl> + return ; <nl> + } <nl> + <nl> core -> core_id = value ; <nl> } <nl> 
static void wav_capture_destroy ( void * opaque ) <nl> WAVState * wav = opaque ; <nl>  <nl> AUD_del_capture ( wav -> cap , wav ); <nl> + g_free ( wav ); <nl> } <nl>  <nl> static void wav_capture_info ( void * opaque )
 <nl> # define DRC_CONTAINER_PATH "/ dr - connector " <nl> # define DRC_INDEX_TYPE_SHIFT 28 <nl> -# define DRC_INDEX_ID_MASK (~(~ 0 << DRC_INDEX_TYPE_SHIFT )) <nl> +# define DRC_INDEX_ID_MASK (( 1ULL << DRC_INDEX_TYPE_SHIFT ) - 1 ) <nl>  <nl> static sPAPRDRConnectorTypeShift get_type_shift ( sPAPRDRConnectorType type ) <nl> {
int pci_add_capability ( PCIDevice * pdev , uint8_t cap_id , <nl> Error * local_err = NULL ; <nl>  <nl> ret = pci_add_capability2 ( pdev , cap_id , offset , size , & local_err ); <nl> - if ( local_err ) { <nl> - assert ( ret < 0 ); <nl> + if ( ret < 0 ) { <nl> error_report_err ( local_err ); <nl> - } else { <nl> - /* success implies a positive offset in config space */ <nl> - assert ( ret > 0 ); <nl> } <nl> return ret ; <nl> }
ram_addr_t qemu_ram_alloc_from_ptr ( ram_addr_t size , void * host , <nl>  <nl> ram_list . phys_dirty = g_realloc ( ram_list . phys_dirty , <nl> last_ram_offset () >> TARGET_PAGE_BITS ); <nl> + memset ( ram_list . phys_dirty + ( new_block -> offset >> TARGET_PAGE_BITS ), <nl> + 0 , size >> TARGET_PAGE_BITS ); <nl> cpu_physical_memory_set_dirty_range ( new_block -> offset , size , 0xff ); <nl>  <nl> if ( kvm_enabled ())
static void ehci_advance_state ( EHCIState * ehci , <nl> fprintf ( stderr , " processing error - resetting ehci HC \ n "); <nl> ehci_reset ( ehci ); <nl> again = 0 ; <nl> - assert ( 0 ); <nl> } <nl> } <nl> while ( again );
static uint64_t ich_elrsr_read ( CPUARMState * env , const ARMCPRegInfo * ri ) <nl> uint64_t lr = cs -> ich_lr_el2 [ i ]; <nl>  <nl> if (( lr & ICH_LR_EL2_STATE_MASK ) == 0 && <nl> - (( lr & ICH_LR_EL2_HW ) == 1 || ( lr & ICH_LR_EL2_EOI ) == 0 )) { <nl> + (( lr & ICH_LR_EL2_HW ) != 0 || ( lr & ICH_LR_EL2_EOI ) == 0 )) { <nl> value |= ( 1 << i ); <nl> } <nl> }
static void vga_draw_text ( VGACommonState * s , int full_update ) <nl> cx_min = width ; <nl> cx_max = - 1 ; <nl> for ( cx = 0 ; cx < width ; cx ++) { <nl> + if ( src + sizeof ( uint16_t ) > s -> vram_ptr + s -> vram_size ) { <nl> + break ; <nl> + } <nl> ch_attr = *( uint16_t *) src ; <nl> if ( full_update || ch_attr != * ch_attr_ptr || src == cursor_ptr ) { <nl> if ( cx < cx_min )
static VncState * vnc_state ; /* needed for info vnc */ <nl>  <nl> void do_info_vnc ( void ) <nl> { <nl> - if ( vnc_state == NULL ) <nl> + if ( vnc_state == NULL || vnc_state -> display == NULL ) <nl> term_printf (" VNC server disabled \ n "); <nl> else { <nl> term_printf (" VNC server active on : ");
static void x86_cpu_register_feature_bit_props ( X86CPU * cpu , <nl>  <nl> for ( i = 1 ; names [ i ]; i ++) { <nl> feat2prop ( names [ i ]); <nl> - object_property_add_alias ( obj , names [ i ], obj , g_strdup ( names [ 0 ]), <nl> + object_property_add_alias ( obj , names [ i ], obj , names [ 0 ], <nl> & error_abort ); <nl> } <nl> 
int qcow2_grow_l1_table ( BlockDriverState * bs , uint64_t min_size , <nl> if ( min_size <= s -> l1_size ) <nl> return 0 ; <nl>  <nl> + /* Do a sanity check on min_size before trying to calculate new_l1_size <nl> + * ( this prevents overflows during the while loop for the calculation of <nl> + * new_l1_size ) */ <nl> + if ( min_size > INT_MAX / sizeof ( uint64_t )) { <nl> + return - EFBIG ; <nl> + } <nl> + <nl> if ( exact_size ) { <nl> new_l1_size = min_size ; <nl> } else {
static void bit_prop_set ( DeviceState * dev , Property * props , bool val ) <nl> uint32_t * p = qdev_get_prop_ptr ( dev , props ); <nl> uint32_t mask = qdev_get_prop_mask ( props ); <nl> if ( val ) <nl> - * p |= ~ mask ; <nl> + * p |= mask ; <nl> else <nl> * p &= ~ mask ; <nl> }
static void gen_rot_rm_T1 ( DisasContext * s , int ot , int op1 , int is_right ) <nl> if ( is_right ) { <nl> tcg_gen_shri_tl ( cpu_cc_src2 , cpu_T [ 0 ], mask - 1 ); <nl> tcg_gen_shri_tl ( cpu_cc_dst , cpu_T [ 0 ], mask ); <nl> + tcg_gen_andi_tl ( cpu_cc_dst , cpu_cc_dst , 1 ); <nl> } else { <nl> tcg_gen_shri_tl ( cpu_cc_src2 , cpu_T [ 0 ], mask ); <nl> tcg_gen_andi_tl ( cpu_cc_dst , cpu_T [ 0 ], 1 );
static void puv3_load_kernel ( const char * kernel_filename ) <nl> if ( kernel_filename == NULL && qtest_enabled ()) { <nl> return ; <nl> } <nl> - assert ( kernel_filename != NULL ); <nl> + if ( kernel_filename == NULL ) { <nl> + error_report (" kernel parameter cannot be empty "); <nl> + exit ( 1 ); <nl> + } <nl>  <nl> /* only zImage format supported */ <nl> size = load_image_targphys ( kernel_filename , KERNEL_LOAD_ADDR ,
static PCIDevice * qemu_pci_hot_add_storage ( Monitor * mon , <nl> const char * opts ) <nl> { <nl> PCIDevice * dev ; <nl> - DriveInfo * dinfo ; <nl> + DriveInfo * dinfo = NULL ; <nl> int type = - 1 ; <nl> char buf [ 128 ]; <nl> 
void bdrv_image_info_specific_dump ( fprintf_function func_fprintf , void * f , <nl> assert ( qobject_type ( obj ) == QTYPE_QDICT ); <nl> data = qdict_get ( qobject_to_qdict ( obj ), " data "); <nl> dump_qobject ( func_fprintf , f , 1 , data ); <nl> + qobject_decref ( obj ); <nl> visit_free ( v ); <nl> } <nl> 
static void pcie_cap_slot_hotplug_common ( PCIDevice * hotplug_dev , <nl> /* the slot is electromechanically locked . <nl> * This error is propagated up to qdev and then to HMP / QMP . <nl> */ <nl> - error_setg_errno ( errp , - EBUSY , " slot is electromechanically locked "); <nl> + error_setg_errno ( errp , EBUSY , " slot is electromechanically locked "); <nl> } <nl> } <nl> 
static int alloc_cluster_link_l2 ( BlockDriverState * bs , uint64_t cluster_offset , <nl> goto err ; <nl>  <nl> for ( i = 0 ; i < j ; i ++) <nl> - free_any_clusters ( bs , old_cluster [ i ], 1 ); <nl> + free_any_clusters ( bs , be64_to_cpu ( old_cluster [ i ]), 1 ); <nl>  <nl> ret = 0 ; <nl> err :
int inet_dgram_opts ( QemuOpts * opts ) <nl> if ( 0 != ( rc = getaddrinfo ( addr , port , & ai , & local ))) { <nl> fprintf ( stderr ," getaddrinfo (% s ,% s ): % s \ n ", addr , port , <nl> gai_strerror ( rc )); <nl> - return - 1 ; <nl> + goto err ; <nl> } <nl>  <nl> /* create socket */
static int rtl8139_cplus_transmit_one ( RTL8139State * s ) <nl>  <nl> int tcp_hlen = TCP_HEADER_DATA_OFFSET ( p_tcp_hdr ); <nl>  <nl> + /* Invalid TCP data offset ? */ <nl> + if ( tcp_hlen < sizeof ( tcp_header ) || tcp_hlen > ip_data_len ) { <nl> + goto skip_offload ; <nl> + } <nl> + <nl> /* ETH_MTU = ip header len + tcp header len + payload */ <nl> int tcp_data_len = ip_data_len - tcp_hlen ; <nl> int tcp_chunk_size = ETH_MTU - hlen - tcp_hlen ;
static int xen_pt_initfn ( PCIDevice * d ) <nl>  <nl> /* Initialize virtualized PCI configuration ( Extended 256 Bytes ) */ <nl> if ( xen_host_pci_get_block (& s -> real_device , 0 , d -> config , <nl> - PCI_CONFIG_SPACE_SIZE ) == - 1 ) { <nl> + PCI_CONFIG_SPACE_SIZE ) < 0 ) { <nl> xen_host_pci_device_put (& s -> real_device ); <nl> return - 1 ; <nl> }
void virtio_queue_set_notification ( VirtQueue * vq , int enable ) <nl> } else { <nl> vring_used_flags_set_bit ( vq , VRING_USED_F_NO_NOTIFY ); <nl> } <nl> + if ( enable ) { <nl> + /* Expose avail event / used flags before caller checks the avail idx . */ <nl> + smp_mb (); <nl> + } <nl> } <nl>  <nl> int virtio_queue_ready ( VirtQueue * vq )
static int usb_host_open ( USBHostDevice * dev , int bus_num , <nl>  <nl> dev -> bus_num = bus_num ; <nl> dev -> addr = addr ; <nl> - strcpy ( dev -> port , port ); <nl> + pstrcpy ( dev -> port , sizeof ( dev -> port ), port ); <nl> dev -> fd = fd ; <nl>  <nl> /* read the device description */
void cpu_x86_cpuid ( CPUX86State * env , uint32_t index , uint32_t count , <nl> index = env -> cpuid_xlevel ; <nl> } <nl> } else { <nl> - index = env -> cpuid_xlevel ; <nl> + /* Intel documentation states that invalid EAX input will <nl> + * return the same information as EAX = cpuid_level <nl> + * ( Intel SDM Vol . 2A - Instruction Set Reference - CPUID ) <nl> + */ <nl> + index = env -> cpuid_level ; <nl> } <nl> } <nl> } else {
static int sd_snapshot_create ( BlockDriverState * bs , QEMUSnapshotInfo * sn_info ) <nl>  <nl> ret = do_sd_create ( s , & new_vid , 1 , & local_err ); <nl> if ( ret < 0 ) { <nl> - error_report_err ( local_err ); <nl> - error_report (" failed to create inode for snapshot . % s ", <nl> - strerror ( errno )); <nl> + error_report (" failed to create inode for snapshot : % s ", <nl> + error_get_pretty ( local_err )); <nl> goto cleanup ; <nl> } <nl> 
void vnc_display_open ( const char * id , Error ** errp ) <nl> if ( vs -> ws_enabled ) { <nl> vs -> lwebsock = inet_listen_opts ( wsopts , 0 , errp ); <nl> if ( vs -> lwebsock < 0 ) { <nl> - if ( vs -> lsock ) { <nl> + if ( vs -> lsock != - 1 ) { <nl> close ( vs -> lsock ); <nl> vs -> lsock = - 1 ; <nl> }
int spapr_populate_pci_devices ( sPAPRPHBState * phb , <nl> reg [ 0 ]. size = 0 ; <nl>  <nl> n = 0 ; <nl> - for ( i = 0 ; i < PCI_NUM_REGIONS ; ++ i ) { <nl> + for ( i = 0 ; i < ARRAY_SIZE ( bars ); ++ i ) { <nl> if ( 0 == dev -> io_regions [ i ]. size ) { <nl> continue ; <nl> }
void block_job_set_speed ( BlockJob * job , int64_t speed , Error ** errp ) <nl> } <nl>  <nl> job -> speed = speed ; <nl> - if ( speed <= old_speed ) { <nl> + if ( speed && speed <= old_speed ) { <nl> return ; <nl> } <nl> 
static void spapr_cpu_core_realize ( DeviceState * dev , Error ** errp ) <nl> } <nl>  <nl> err : <nl> - while ( i >= 0 ) { <nl> + while (-- i >= 0 ) { <nl> obj = sc -> threads + i * size ; <nl> object_unparent ( obj ); <nl> - i --; <nl> } <nl> g_free ( sc -> threads ); <nl> error_propagate ( errp , local_err );
static int get_device_guid ( <nl> & len ); <nl>  <nl> if ( status != ERROR_SUCCESS || name_type != REG_SZ ) { <nl> - return - 1 ; <nl> + ++ i ; <nl> + continue ; <nl> } <nl> else { <nl> if ( is_tap_win32_dev ( enum_name )) {
static int qcow_create ( const char * filename , QemuOpts * opts , Error ** errp ) <nl> header_size += backing_filename_len ; <nl> } else { <nl> /* special backing file for vvfat */ <nl> + g_free ( backing_file ); <nl> backing_file = NULL ; <nl> } <nl> header . cluster_bits = 9 ; /* 512 byte cluster to avoid copying
static void disas_arm_insn ( CPUARMState * env , DisasContext * s ) <nl> } <nl> ARCH ( 6 ); <nl> gen_srs ( s , ( insn & 0x1f ), ( insn >> 23 ) & 3 , insn & ( 1 << 21 )); <nl> + return ; <nl> } else if (( insn & 0x0e50ffe0 ) == 0x08100a00 ) { <nl> /* rfe */ <nl> int32_t offset ;
void shpc_cleanup ( PCIDevice * d , MemoryRegion * bar ) <nl> SHPCDevice * shpc = d -> shpc ; <nl> d -> cap_present &= ~ QEMU_PCI_CAP_SHPC ; <nl> memory_region_del_subregion ( bar , & shpc -> mmio ); <nl> + object_unparent ( OBJECT (& shpc -> mmio )); <nl> /* TODO : cleanup config space changes ? */ <nl> g_free ( shpc -> config ); <nl> g_free ( shpc -> cmask );
static void cpu_common_reset ( CPUState * cpu ) <nl> log_cpu_state ( cpu , cc -> reset_dump_flags ); <nl> } <nl>  <nl> - cpu -> exit_request = 0 ; <nl> cpu -> interrupt_request = 0 ; <nl> cpu -> current_tb = NULL ; <nl> cpu -> halted = 0 ;
void qemu_system_guest_panicked ( void ) <nl> } <nl> qapi_event_send_guest_panicked ( GUEST_PANIC_ACTION_PAUSE , & error_abort ); <nl> vm_stop ( RUN_STATE_GUEST_PANICKED ); <nl> + if (! no_shutdown ) { <nl> + qapi_event_send_guest_panicked ( GUEST_PANIC_ACTION_POWEROFF , <nl> + & error_abort ); <nl> + qemu_system_shutdown_request (); <nl> + } <nl> } <nl>  <nl> void qemu_system_reset_request ( void )
static void sdhci_sdma_transfer_multi_blocks ( SDHCIState * s ) <nl> boundary_count -= block_size - begin ; <nl> } <nl> dma_memory_read (& address_space_memory , s -> sdmasysad , <nl> - & s -> fifo_buffer [ begin ], s -> data_count ); <nl> + & s -> fifo_buffer [ begin ], s -> data_count - begin ); <nl> s -> sdmasysad += s -> data_count - begin ; <nl> if ( s -> data_count == block_size ) { <nl> for ( n = 0 ; n < block_size ; n ++) {
sofree ( struct socket * so ) <nl> if ( so -> so_next && so -> so_prev ) <nl> remque ( so ); /* crashes if so is not in a queue */ <nl>  <nl> + if ( so -> so_tcpcb ) { <nl> + free ( so -> so_tcpcb ); <nl> + } <nl> free ( so ); <nl> } <nl> 
static int pci_add_option_rom ( PCIDevice * pdev , bool is_default_rom ) <nl> if ( size < 0 ) { <nl> error_report ("% s : failed to find romfile \"% s \"", <nl> __FUNCTION__ , pdev -> romfile ); <nl> + qemu_free ( path ); <nl> return - 1 ; <nl> } <nl> if ( size & ( size - 1 )) {
static void vga_update_memory_access ( VGACommonState * s ) <nl> size = 0x8000 ; <nl> break ; <nl> case 3 : <nl> + default : <nl> base = 0xb8000 ; <nl> size = 0x8000 ; <nl> break ;
static int vmdk_parse_extents ( const char * desc , BlockDriverState * bs , <nl> } else { <nl> ret = vmdk_open_sparse ( bs , extent_file , bs -> open_flags , buf , errp ); <nl> } <nl> + g_free ( buf ); <nl> if ( ret ) { <nl> - g_free ( buf ); <nl> bdrv_unref ( extent_file ); <nl> return ret ; <nl> }
static void fill_prefetch_fifo ( struct omap_gpmc_s * s ) <nl> if ( bytes > s -> prefetch . count ) { <nl> bytes = s -> prefetch . count ; <nl> } <nl> + if ( is16bit ) { <nl> + bytes &= ~ 1 ; <nl> + } <nl> + <nl> s -> prefetch . count -= bytes ; <nl> s -> prefetch . fifopointer += bytes ; <nl> fptr = 64 - s -> prefetch . fifopointer ;
static void sd_reset ( SDState * sd , BlockDriverState * bdrv ) <nl> } else { <nl> sect = 0 ; <nl> } <nl> - sect <<= 9 ; <nl> - <nl> - size = sect + 1 ; <nl> + size = sect << 9 ; <nl>  <nl> sect = ( size >> ( HWBLOCK_SHIFT + SECTOR_SHIFT + WPGROUP_SHIFT )) + 1 ; <nl> 
static int read_directory ( BDRVVVFATState * s , int mapping_index ) <nl> /* root directory */ <nl> int cur = s -> directory . next ; <nl> array_ensure_allocated (&( s -> directory ), ROOT_ENTRIES - 1 ); <nl> + s -> directory . next = ROOT_ENTRIES ; <nl> memset ( array_get (&( s -> directory ), cur ), 0 , <nl> ( ROOT_ENTRIES - cur ) * sizeof ( direntry_t )); <nl> }
static void create_dummy_nodes ( RAGraph * g ) { <nl> const RListIter * it ; <nl> const RGraphEdge * e ; <nl>  <nl> - g -> long_edges = r_list_new (); <nl> + g -> long_edges = r_list_newf (( RListFree ) free ); <nl> dummy_vis . data = g -> long_edges ; <nl> dummy_vis . tree_edge = ( RGraphEdgeCallback ) view_dummy ; <nl> dummy_vis . fcross_edge = ( RGraphEdgeCallback ) view_dummy ;
eprintf ("-- % s \ n ", buf ); <nl> } <nl> case ' C ': /* comment */ <nl> if ( input [ 1 ] == '+') { <nl> - const char * text , * newcomment = input + 2 ; <nl> + const char * newcomment = input + 2 ; <nl> + char * text ; <nl> while (* newcomment ==' ') newcomment ++; <nl> char * comment = r_meta_get_string ( <nl> core -> anal , R_META_TYPE_COMMENT , addr );
void logto ( char * logfile ) { <nl> uwsgi . logfile = logfile ; <nl>  <nl> if ( uwsgi . chmod_logfile_value ) { <nl> - if ( chmod ( uwsgi . logfile , uwsgi . chmod_logfile_value )) { <nl> - uwsgi_error (" chmod ()"); <nl> + if ( fchmod ( fd , uwsgi . chmod_logfile_value )) { <nl> + uwsgi_error (" fchmod ()"); <nl> } <nl> } <nl> }
void get_player_info ( const config & cfg , game_state & gamestate , std :: string save_ <nl> LOG_NG << " found gold : '" << gold << "'\ n "; <nl>  <nl> int ngold = lexical_cast_default < int >( gold ); <nl> - if ( player != NULL && player -> gold >= ngold ) { <nl> + if ( ( player != NULL && player -> gold >= ngold ) || snapshot ) { <nl> ngold = player -> gold ; <nl> } <nl> 
SOCKET_STATE receive_buf ( TCPsocket sock , std :: vector < char >& buf ) <nl> } <nl> } <nl>  <nl> - const ssize_t res = SDLNet_TCP_Recv ( sock , beg , end - beg ); <nl> + const int res = SDLNet_TCP_Recv ( sock , beg , end - beg ); <nl> if ( res <= 0 ) { <nl> if ( SDLNet_CheckSockets ( set , 15000 ) <= 0 ) { <nl> ERR_NW << " SDLNet_CheckSockets : " << strerror ( errno ) << "\ n ";
bool game :: describe_slots () { <nl> std :: string descr = buf . str (); <nl>  <nl> if ((* description_ )[" slots "] != descr ) { <nl> - description_ -> set_attr_dup (" slots ", descr ); <nl> + description_ -> set_attr_dup (" slots ", descr . c_str ()); <nl> return true ; <nl> } else { <nl> return false ;
process ( register int code , unsigned char ** fill ) <nl> } <nl>  <nl> if ( oldcode == - 1 ) { <nl> + if ( code >= clear ) { <nl> + fprintf ( stderr , " bad input : code =% d is larger than clear =% d \ n ", code , clear ); <nl> + return 0 ; <nl> + } <nl> *(* fill )++ = suffix [ code ]; <nl> firstchar = oldcode = code ; <nl> return 1 ;
static int readContigStripsIntoBuffer ( TIFF * in , uint8 * buf ) <nl> ( unsigned long ) strip , ( unsigned long ) rows ); <nl> return 0 ; <nl> } <nl> - bufp += bytes_read ; <nl> + bufp += stripsize ; <nl> } <nl>  <nl> return 1 ;
int dhcp_server_handle_message ( sd_dhcp_server * server , DHCPMessage * message , <nl> lease -> address = req -> requested_ip ; <nl> lease -> client_id . data = memdup ( req -> client_id . data , <nl> req -> client_id . length ); <nl> - if (! lease -> client_id . data ) <nl> + if (! lease -> client_id . data ) { <nl> + free ( lease ); <nl> return - ENOMEM ; <nl> + } <nl> lease -> client_id . length = req -> client_id . length ; <nl> } else <nl> lease = existing_lease ;
_public_ int sd_pid_get_machine_name ( pid_t pid , char ** name ) { <nl>  <nl> _public_ int sd_pid_get_owner_uid ( pid_t pid , uid_t * uid ) { <nl> int r ; <nl> - _cleanup_free_ char * root = NULL , * cgroup = NULL , * p = NULL , * cc = NULL ; <nl> + _cleanup_free_ char * root = NULL , * cgroup = NULL , * cc = NULL ; <nl> + char * p ; <nl> struct stat st ; <nl>  <nl> if ( pid < 0 )
const SyscallFilterSet syscall_filter_sets [ _SYSCALL_FILTER_SET_MAX ] = { <nl> " reboot \ 0 " <nl> }, <nl> [ SYSCALL_FILTER_SET_RESOURCES ] = { <nl> - /* Alter resource settings */ <nl> . name = "@ resources ", <nl> + . help = " Alter resource settings ", <nl> . value = <nl> " sched_setparam \ 0 " <nl> " sched_setscheduler \ 0 "
static int idev_evdev_io ( idev_evdev * evdev ) { <nl>  <nl> error : <nl> idev_evdev_hup ( evdev ); <nl> - return r ; <nl> + return 0 ; /* idev_evdev_hup () handles the error so discard it */ <nl> } <nl>  <nl> static int idev_evdev_event_fn ( sd_event_source * s , int fd , uint32_t revents , void * userdata ) {
int cunescape_length_with_prefix ( const char * s , size_t length , const char * prefi <nl> continue ; <nl> } <nl>  <nl> + free ( r ); <nl> return - EINVAL ; <nl> } <nl>  <nl> int cunescape_length_with_prefix ( const char * s , size_t length , const char * prefi <nl> continue ; <nl> } <nl>  <nl> + free ( r ); <nl> return k ; <nl> } <nl> 
static int unit_find_paths ( <nl> _cleanup_free_ char * template = NULL ; <nl>  <nl> r = unit_name_template ( unit_name , & template ); <nl> - if ( r != - EINVAL ) <nl> + if ( r < 0 && r != - EINVAL ) <nl> return log_error_errno ( r , " Failed to determine template name : % m "); <nl> if ( r >= 0 ) { <nl> r = unit_file_find_path ( lp , template , & path );
static DBusHandlerResult locale_message_handler ( <nl> " Locale \ 0 "); <nl> if (! changed ) <nl> goto oom ; <nl> - } <nl> + } else <nl> + strv_free ( l ); <nl> + <nl> } else if ( dbus_message_is_method_call ( message , " org . freedesktop . locale1 ", " SetVConsoleKeyboard ")) { <nl>  <nl> const char * keymap , * keymap_toggle ;
static int json_parse_tokens ( JsonVariant ** tokens , size_t ntokens , JsonVariant * <nl> size_t it = 0 ; <nl> int r ; <nl> JsonVariant * e ; <nl> - _cleanup_jsonunref_ JsonVariant * p ; <nl> + _cleanup_jsonunref_ JsonVariant * p = NULL ; <nl>  <nl> assert ( tokens ); <nl> assert ( ntokens );
int bus_socket_read_message ( sd_bus * bus ) { <nl> return - EIO ; <nl> } <nl>  <nl> - f = realloc ( bus -> fds , sizeof ( int ) + ( bus -> n_fds + n )); <nl> + f = realloc ( bus -> fds , sizeof ( int ) * ( bus -> n_fds + n )); <nl> if (! f ) { <nl> close_many (( int *) CMSG_DATA ( cmsg ), n ); <nl> return - ENOMEM ;
int udev_monitor_filter_update ( struct udev_monitor * udev_monitor ) <nl> bpf_stmt ( ins , & i , BPF_RET | BPF_K , 0xffffffff ); <nl>  <nl> /* install filter */ <nl> + memset (& filter , 0x00 , sizeof ( filter )); <nl> filter . len = i ; <nl> filter . filter = ins ; <nl> err = setsockopt ( udev_monitor -> sock , SOL_SOCKET , SO_ATTACH_FILTER , & filter , sizeof ( filter ));
saEvtEventAttributesSet ( <nl> struct event_data_instance * edi ; <nl> int i ; <nl>  <nl> + if ( priority < SA_EVT_HIGHEST_PRIORITY || <nl> + priority > SA_EVT_LOWEST_PRIORITY ) { <nl> + return SA_AIS_ERR_INVALID_PARAM ; <nl> + } <nl> + <nl> error = saHandleInstanceGet (& event_handle_db , eventHandle , <nl> ( void *)& edi ); <nl> if ( error != SA_AIS_OK ) {
int amfReadNetwork ( char ** error_string , <nl> int res = 0 ; <nl> int line_number = 0 ; <nl>  <nl> + memset ( mcast_addr , 0 , sizeof ( struct sockaddr_in )); <nl> + memset ( bindnet_addr , 0 , sizeof ( struct sockaddr_in )); <nl>  <nl> mcast_addr -> sin_family = AF_INET ; <nl> fp = fopen ("/ etc / ais / network . conf ", " r ");
my_bool <nl> my_net_write ( NET * net , const char * packet , ulong len ) <nl> { <nl> uchar buff [ NET_HEADER_SIZE ]; <nl> - if ( unlikely (! net -> vio )) // nowhere to write <nl> + if ( unlikely (! net -> vio )) /* nowhere to write */ <nl> return 0 ; <nl> /* <nl> Big packets are handled by splitting them in packets of MAX_PACKET_LENGTH
referenced_xids_note_snapshot_txn_end_iter ( OMTVALUE live_xidv , u_int32_t UU ( inde <nl> if (-- tuple -> references == 0 ) { <nl> r = toku_omt_delete_at ( referenced_xids , idx ); <nl> lazy_assert_zero ( r ); <nl> + toku_free ( tuple ); <nl> } <nl> done : <nl> return 0 ;
static int connect_assisted_discovery ( handlerton *, THD * thd , <nl> break ; <nl> # if defined ( MONGO_SUPPORT ) <nl> case TAB_MONGO : <nl> + if (! topt -> tabname ) <nl> + topt -> tabname = tab ; <nl> + <nl> ok = true ; <nl> break ; <nl> # endif // MONGO_SUPPORT
buf_page_init_low ( <nl> /*==============*/ <nl> buf_page_t * bpage ) /* in : block to init */ <nl> { <nl> + bpage -> flush_type = BUF_FLUSH_LRU ; <nl> bpage -> accessed = FALSE ; <nl> bpage -> io_fix = BUF_IO_NONE ; <nl> bpage -> buf_fix_count = 0 ;
btr_pcur_move_to_prev_page ( <nl>  <nl> page_cur_set_after_last ( prev_block , btr_pcur_get_page_cur ( cursor )); <nl>  <nl> - page_check_dir ( prev_page ); <nl> + ut_d ( page_check_dir ( prev_page )); <nl> } <nl>  <nl> /*********************************************************//**
row_merge_create_temporary_table ( <nl>  <nl> if ( error != DB_SUCCESS ) { <nl> trx -> error_state = error ; <nl> + dict_mem_table_free ( new_table ); <nl> new_table = NULL ; <nl> } <nl> 
ulong my_scan_8bit ( CHARSET_INFO * cs , const char * str , const char * end , int sq ) <nl> return 0 ; <nl>  <nl> case MY_SEQ_SPACES : <nl> - for ( str ++ ; str != end ; str ++) <nl> + for (; str != end ; str ++) <nl> { <nl> if (! my_isspace ( cs ,* str )) <nl> break ;
 <nl> # include < File . hpp > <nl>  <nl> +// alt use PATH_MAX <nl> +# ifndef MAXPATHLEN <nl> +# define MAXPATHLEN 1024 <nl> +# endif <nl> + <nl> // <nl> // PUBLIC <nl> //
innobase_xa_prepare ( <nl> int error = 0 ; <nl> trx_t * trx = check_trx_exists ( thd ); <nl>  <nl> - if ( thd -> lex -> sql_command != SQLCOM_XA_PREPARE ) { <nl> + if ( thd -> lex -> sql_command != SQLCOM_XA_PREPARE && <nl> + ( all || !( thd -> options & ( OPTION_NOT_AUTOCOMMIT | OPTION_BEGIN )))) <nl> + { <nl>  <nl> /* For ibbackup to work the order of transactions in binlog <nl> and InnoDB must be the same . Consider the situation
rend_config_services ( const or_options_t * options , int validate_only ) <nl> log_warn ( LD_CONFIG , <nl> " HiddenServiceAllowUnknownPorts should be 0 or 1 , not % s ", <nl> line -> value ); <nl> - smartlist_free ( temp_service_list ); <nl> goto free_and_return ; <nl> } <nl> log_info ( LD_CONFIG ,
parse_server_transport_line ( const char * line , int validate_only ) <nl> done : <nl> SMARTLIST_FOREACH ( items , char *, s , tor_free ( s )); <nl> smartlist_free ( items ); <nl> - SMARTLIST_FOREACH ( transport_list , char *, s , tor_free ( s )); <nl> - smartlist_free ( transport_list ); <nl> + if ( transport_list ) { <nl> + SMARTLIST_FOREACH ( transport_list , char *, s , tor_free ( s )); <nl> + smartlist_free ( transport_list ); <nl> + } <nl>  <nl> return r ; <nl> }
MOCK_IMPL ( STATIC X509 *, <nl> goto error ; <nl> if (! X509_set_pubkey ( x509 , pkey )) <nl> goto error ; <nl> - if (! X509_sign ( x509 , sign_pkey , EVP_sha1 ())) <nl> + <nl> + if (! X509_sign ( x509 , sign_pkey , EVP_sha256 ())) <nl> goto error ; <nl>  <nl> goto done ;
# error " Sorry ; we don ' t support building with NDEBUG ." <nl> # else <nl> # ifdef __GNUC__ <nl> -# define PREDICT_FALSE ( x ) PREDICT (( x ) != (( typeof ( x )) 0 ), 0 ) <nl> +# define PREDICT_FALSE ( x ) PREDICT (( x ) == (( typeof ( x )) 0 ), 0 ) <nl> # else <nl> # define PREDICT_FALSE ( x ) !( x ) <nl> # endif
ECP :: ECP ( BufferedTransformation & bt ) <nl> GetField (). BERDecodeElement ( seq , m_b ); <nl> // skip optional seed <nl> if (! seq . EndReached ()) <nl> - BERDecodeOctetString ( seq , TheBitBucket ()); <nl> + { <nl> + SecByteBlock seed ; <nl> + unsigned int unused ; <nl> + BERDecodeBitString ( seq , seed , unused ); <nl> + } <nl> seq . MessageEnd (); <nl> } <nl> 
void jshFlashErasePage ( uint32_t addr ) { <nl> if (! f ) return ; <nl> uint32_t startAddr , pageSize ; <nl> if ( jshFlashGetPage ( addr , & startAddr , & pageSize )) { <nl> + startAddr -= FLASH_START ; <nl> fseek ( f , startAddr , SEEK_SET ); <nl> char * buf = malloc ( pageSize ); <nl> memset ( buf , 0xFF , pageSize );
main ( int argc , char * argv []) <nl>  <nl> _slurmd_fini (); <nl> _destroy_conf (); <nl> + slurm_crypto_fini (); /* must be after _destroy_conf () */ <nl> + <nl> info (" Slurmd shutdown completing "); <nl> log_fini (); <nl> return 0 ; <nl> _slurmd_fini () <nl> slurm_conf_destroy (); <nl> slurm_proctrack_fini (); <nl> slurm_auth_fini (); <nl> - slurm_crypto_fini (); <nl> slurmd_req ( NULL ); /* purge memory allocated by slurmd_req () */ <nl> return SLURM_SUCCESS ; <nl> }
static void _purge_missing_jobs ( int node_inx , time_t now ) <nl> node_boot_time = node_ptr -> boot_time - ( msg_timeout + 5 ); <nl> } <nl> batch_startup_time = now - batch_start_timeout ; <nl> - batch_startup_time -= msg_timeout ; <nl> + batch_startup_time -= MIN ( DEFAULT_MSG_TIMEOUT , msg_timeout ); <nl>  <nl> job_iterator = list_iterator_create ( job_list ); <nl> while (( job_ptr = ( struct job_record *) list_next ( job_iterator ))) {
char * slurm_sprint_partition_info ( partition_info_t * part_ptr , <nl> if ( part_ptr -> disable_root_jobs ) <nl> sprintf ( tmp_line , " DisableRootJobs = YES "); <nl> else <nl> - sprintf ( tmp_line , " DisableRootJobs = NO "); <nl> + sprintf ( tmp_line , " DisableRootJobs = NO "); <nl> xstrcat ( out , tmp_line ); <nl>  <nl> if ( part_ptr -> hidden )
styleObj * msRemoveStyle ( classObj * class , int nStyleIndex ) { <nl> return NULL ; <nl> } <nl> msCopyStyle ( style , &( class -> styles [ nStyleIndex ])); <nl> + style -> isachild = MS_FALSE ; <nl> for ( i = nStyleIndex ; i < class -> numstyles - 1 ; i ++) { <nl> msCopyStyle (& class -> styles [ i ], & class -> styles [ i + 1 ]); <nl> }
mono_gc_pthread_detach ( pthread_t thread ) <nl> void <nl> mono_gc_pthread_exit ( void * retval ) <nl> { <nl> + mono_thread_info_dettach (); <nl> pthread_exit ( retval ); <nl> } <nl> 
seq_point_info_add_seq_point ( MonoSeqPointInfo * info , SeqPoint * sp , SeqPoint * la <nl> guint8 buffer [ 4 ]; <nl> guint8 len ; <nl>  <nl> + if (! info -> has_debug_data && <nl> + ( sp -> il_offset == METHOD_ENTRY_IL_OFFSET || sp -> il_offset == METHOD_EXIT_IL_OFFSET )) <nl> + return FALSE ; <nl> + <nl> /* check that data can be added to the arrays */ <nl> g_assert ( info -> alloc_arrays ); <nl> 
mono_threads_attach_coop_internal ( MonoDomain * domain , gpointer * cookie , MonoSta <nl> { <nl> MonoDomain * orig ; <nl> MonoThreadInfo * info ; <nl> - gboolean external ; <nl> + gboolean external = FALSE ; <nl>  <nl> orig = mono_domain_get (); <nl> 
RemoteBackend :: RemoteBackend ( const std :: string & suffix ) <nl> { <nl> setArgPrefix (" remote "+ suffix ); <nl> build ( getArg (" connection - string ")); <nl> + this -> d_result = NULL ; <nl> this -> d_dnssec = mustDo (" dnssec "); <nl> this -> d_index = - 1 ; <nl> this -> d_trxid = 0 ;
M_API M_bool M_queue_remove ( M_queue_t * queue , void * member ); <nl> * \ param member User - supplied queue object ( pointer ) to find . <nl> * \ return M_TRUE if member exists , M_FALSE otherwise . <nl> */ <nl> - M_bool M_queue_exists ( M_queue_t * queue , void * member ); <nl> + M_API M_bool M_queue_exists ( M_queue_t * queue , void * member ); <nl>  <nl>  <nl> /*! Take control of a user - supplied queue object ( pointer ). This will remove the
nautilus_link_get_link_uri_from_desktop ( GKeyFile * key_file , const char * desktop <nl> g_object_unref ( parent ); <nl> } <nl> } <nl> + g_free ( scheme ); <nl> } <nl>  <nl> return retval ;
eel_canvas_button ( GtkWidget * widget , GdkEventButton * event ) <nl>  <nl> canvas = EEL_CANVAS ( widget ); <nl>  <nl> + /* Don ' t handle extra mouse button events */ <nl> + if ( event -> button > 5 ) <nl> + return FALSE ; <nl> + <nl> /* <nl> * dispatch normally regardless of the event ' s window if an item has <nl> * has a pointer grab in effect
static GF_Err gf_isom_parse_movie_boxes_internal ( GF_ISOFile * mov , u32 * boxType , <nl> if ( pos < 0 ) pos = 0 ; <nl> gf_list_insert ( mov -> TopBoxes , brand , pos ); <nl> } <nl> + gf_isom_box_del ( a ); <nl> } <nl> break ; <nl> 
GF_Err MergeFragment ( GF_MovieFragmentBox * moof , GF_ISOFile * mov ) <nl>  <nl> static void FixTrackID ( GF_ISOFile * mov ) <nl> { <nl> + if (! mov -> moov ) return ; <nl> + <nl> if ( gf_list_count ( mov -> moov -> trackList ) == 1 && gf_list_count ( mov -> moof -> TrackList ) == 1 ) { <nl> GF_TrackFragmentBox * traf = ( GF_TrackFragmentBox *) gf_list_get ( mov -> moof -> TrackList , 0 ); <nl> GF_TrackBox * trak = ( GF_TrackBox *) gf_list_get ( mov -> moov -> trackList , 0 );
GF_Err dump_isom_xml ( GF_ISOFile * file , char * inName , Bool is_final_name , Bool do <nl> if ( e ) { <nl> fprintf ( stderr , " Error dumping ISO structure \ n "); <nl> } <nl> - if ( gf_isom_get_track_count ( file ) == 0 ) <nl> - do_track_dump = GF_FALSE ; <nl>  <nl> if ( do_track_dump ) { <nl> u32 i , j ;
sc_pkcs15_free_pubkey_info ( sc_pkcs15_pubkey_info_t * info ) <nl> { <nl> if ( info -> subject . value ) <nl> free ( info -> subject . value ); <nl> + if ( info -> direct . spki . value ) <nl> + free ( info -> direct . spki . value ); <nl> + if ( info -> direct . raw . value ) <nl> + free ( info -> direct . raw . value ); <nl> sc_pkcs15_free_key_params (& info -> params ); <nl> free ( info ); <nl> }
pkcs15_pubkey_get_attribute ( struct sc_pkcs11_session * session , void * object , CK_ <nl> *( CK_OBJECT_CLASS *) attr -> pValue = CKO_PUBLIC_KEY ; <nl> break ; <nl> case CKA_TOKEN : <nl> + check_attribute_buffer ( attr , sizeof ( CK_BBOOL )); <nl> + *( CK_BBOOL *) attr -> pValue = TRUE ; <nl> + break ; <nl> case CKA_SENSITIVE : <nl> /* By PKCS # 11 v2 . 20 public key cannot have SENSITIVE attr TRUE */ <nl> check_attribute_buffer ( attr , sizeof ( CK_BBOOL ));
coolkey_add_object ( coolkey_private_data_t * priv , unsigned long object_id , const <nl> new_object . id = object_id ; <nl> new_object . length = object_length ; <nl>  <nl> + /* The object ID needs to be unique */ <nl> + if ( coolkey_find_object_by_id (& priv -> objects_list , object_id ) != NULL ) { <nl> + return SC_ERROR_INTERNAL ; <nl> + } <nl> + <nl> if ( object_data ) { <nl> new_object . data = malloc ( object_length + add_v1_record ); <nl> if ( new_object . data == NULL ) {
sc_parse_ef_atr_content ( struct sc_card * card , unsigned char * buf , size_t buflen ) <nl>  <nl> category = * buf ; <nl>  <nl> + memset (& ef_atr , 0 , sizeof ( struct sc_ef_atr )); <nl> /* IAS / ECC specific : skip second ' zero ' byte */ <nl> if (*(++ buf ) == 0x00 ) <nl> ++ buf ;
static bool php_mb_parse_encoding ( const Variant & encoding , <nl> } <nl> if (! ret ) { <nl> if ( return_list && * return_list ) { <nl> - free (* return_list ); <nl> + req :: free (* return_list ); <nl> * return_list = nullptr ; <nl> } <nl> return_size = 0 ;
do { while ( optind < Argc && Legacy ( optind )) {} <nl> switch ( opC ) <nl> { case OpCksum : defCks ( optarg ); <nl> break ; <nl> + case OpCoerce : OpSpec |= DoCoerce ; <nl> + break ; <nl> case OpDebug : OpSpec |= DoDebug ; <nl> if (! a2i ( optarg , & Dlvl , 0 , 3 )) Usage ( 22 ); <nl> break ;
msg_create ( mqueue_t * mq , const char * message ) <nl> } <nl>  <nl> mowgli_node_add ( msg , & msg -> node , & mq -> entries ); <nl> + mq -> last_used = CURRTIME ; <nl>  <nl> return msg ; <nl> }
void NativeWindow :: TitleWasSet ( content :: NavigationEntry * entry , <nl> FOR_EACH_OBSERVER ( NativeWindowObserver , <nl> observers_ , <nl> OnPageTitleUpdated (& prevent_default , text )); <nl> - if (! prevent_default ) <nl> + if (! prevent_default && ! is_closed_ ) <nl> SetTitle ( text ); <nl> } <nl> 
 <nl> # define STREAM_VERIFY_SANE ( S ) \ <nl> do { \ <nl> - if ( !( GETP_VALID ( S , ( S )-> getp )) && ENDP_VALID ( S , ( S )-> endp ) ) \ <nl> + if ( !( GETP_VALID ( S , ( S )-> getp ) && ENDP_VALID ( S , ( S )-> endp )) ) \ <nl> STREAM_WARN_OFFSETS ( S ); \ <nl> assert ( GETP_VALID ( S , ( S )-> getp ) ); \ <nl> assert ( ENDP_VALID ( S , ( S )-> endp ) ); \
void ospf6_spf_reason_string ( unsigned int reason , char * buf , int size ) <nl> if (! buf ) <nl> return ; <nl>  <nl> - for ( bit = 0 ; bit <= ( sizeof ( ospf6_spf_reason_str ) / sizeof ( char *)); bit ++) <nl> + for ( bit = 0 ; bit < array_size ( ospf6_spf_reason_str ); bit ++) <nl> { <nl> if (( reason & ( 1 << bit )) && ( len < size )) <nl> {
bgp_address_del ( struct prefix * p ) <nl> tmp . addr = p -> u . prefix4 ; <nl>  <nl> addr = hash_lookup ( bgp_address_hash , & tmp ); <nl> + /* may have been deleted earlier by bgp_interface_down () */ <nl> + if ( addr == NULL ) <nl> + return ; <nl> + <nl> addr -> refcnt --; <nl>  <nl> if ( addr -> refcnt == 0 )
int regexp_nsub ( struct regexp * r ) { <nl> } <nl>  <nl> void regexp_release ( struct regexp * regexp ) { <nl> - if ( regexp -> re != NULL ) { <nl> + if ( regexp != NULL && regexp -> re != NULL ) { <nl> regfree ( regexp -> re ); <nl> FREE ( regexp -> re ); <nl> }
namespace tnt <nl> explicit HttpReply ( std :: ostream & s , bool sendStatusLine = true ); <nl>  <nl> void setContentType ( const char * t ) { setHeader ( httpheader :: contentType , t ); } <nl> + void setContentType ( const std :: string & t ) { setHeader ( httpheader :: contentType , t ); } <nl> const char * getContentType () const { return getHeader ( httpheader :: contentType ); } <nl>  <nl> void setHeadRequest ( bool sw = true ) { headRequest = sw ; }
namespace tnt <nl> { <nl> log_debug (" worker - process "); <nl>  <nl> + stop = false ; <nl> + <nl> if ( listeners . empty ()) <nl> { <nl> unsigned short int port = ( getuid () == 0 ? 80 : 8000 );
new_msym ( codegen_scope * s , mrb_sym sym ) <nl> { <nl> size_t i , len ; <nl>  <nl> + if ( s -> irep == NULL ) return 0 ; <nl> len = s -> irep -> slen ; <nl> + <nl> if ( len > 256 ) len = 256 ; <nl> for ( i = 0 ; i < len ; i ++) { <nl> if ( s -> irep -> syms [ i ] == sym ) return i ;
convert_type ( mrb_state * mrb , mrb_value val , const char * tname , const char * metho <nl> return mrb_nil_value (); <nl> } <nl> } <nl> - return mrb_funcall ( mrb , val , method , 0 ); <nl> + return mrb_funcall_argv ( mrb , val , m , 0 , 0 ); <nl> } <nl>  <nl> mrb_value
void restart_connections_by_peer ( struct connection * const c ) <nl> host_addr = c -> spd . that . host_addr ; <nl> } <nl>  <nl> - if ( hp_next == NULL ) { <nl> + if ( c_kind == CK_INSTANCE && hp_next == NULL ) { <nl> + /* in simple cases this is a dangling hp */ <nl> DBG ( DBG_CONTROL , <nl> DBG_log (" no connection to restart after termination ")); <nl> } else {
whack_handle ( int whackctlfd ) <nl> close ( whackfd ); <nl> return ; <nl> } <nl> + memset (& msg , 0 , sizeof ( msg )); <nl> n = read ( whackfd , & msg , sizeof ( msg )); <nl> if ( n <= 0 ) <nl> {
static void retransmit_v1_msg ( struct state * st ) <nl> delay_ms = c -> r_interval ; <nl> } <nl>  <nl> - if ( delay_ms != 0 ) { <nl> + if ( delay_ms != 0 ) <nl> delay_ms = retrans_delay ( st , delay_ms ); <nl>  <nl> if ( delay_ms != 0 ) {
parse ( cherokee_handler_ssi_t * hdl , <nl>  <nl> ret = parse ( hdl , & file_content , out ); <nl> if ( unlikely ( ret != ret_ok )) { <nl> + cherokee_buffer_mrproper (& file_content ); <nl> return ret_error ; <nl> } <nl> 
cherokee_config_node_add ( cherokee_config_node_t * conf , const char * key , cheroke <nl> } <nl>  <nl> if ( final ) { <nl> + cherokee_buffer_clean (& child -> val ); <nl> cherokee_buffer_add_buffer (& child -> val , val ); <nl> } <nl> 
frexpf ( float x , int * eptr ) <nl> } <nl> * eptr += ( ix >> 23 )- 126 ; <nl> hx = ( hx & 0x807fffff )| 0x3f000000 ; <nl> - *( int *)& x = hx ; <nl> + SET_FLOAT_WORD ( x , hx ); <nl> return x ; <nl> }
File * FileRef :: create ( FileName fileName , bool readAudioProperties , <nl> File * file = new Ogg :: FLAC :: File ( fileName , readAudioProperties , audioPropertiesStyle ); <nl> if ( file -> isValid ()) <nl> return file ; <nl> + delete file ; <nl> return new Ogg :: Vorbis :: File ( fileName , readAudioProperties , audioPropertiesStyle ); <nl> } <nl> if ( ext == " FLAC ")
static MagickBooleanType WriteOnePNGImage ( MngInfo * mng_info , <nl> image_colors =( int ) image -> colors ; <nl> image_matte = image -> alpha_trait == BlendPixelTrait ? MagickTrue : MagickFalse ; <nl>  <nl> - if ( mng_info -> write_png_colortype > 4 ) <nl> + if ( mng_info -> write_png_colortype < 5 ) <nl> mng_info -> IsPalette = image -> storage_class == PseudoClass && <nl> image_colors <= 256 && image -> colormap != NULL ; <nl> else
static ssize_t DecodePSDPixels ( const size_t number_compact_pixels , <nl> length ++; <nl> for ( j = 0 ; j < ( ssize_t ) length ; j ++) <nl> { <nl> + CheckNumberCompactPixels ; <nl> switch ( depth ) <nl> { <nl> case 1 : <nl> static ssize_t DecodePSDPixels ( const size_t number_compact_pixels , <nl> break ; <nl> } <nl> } <nl> - CheckNumberCompactPixels ; <nl> compact_pixels ++; <nl> } <nl> }
static MagickBooleanType ReadPSDChannelPixels ( Image * image , <nl> SetPixelIndex ( image ,((( unsigned char ) pixel ) & <nl> ( 0x01 << ( 7 - bit ))) != 0 ? 0 : 255 , q ); <nl> SetPixelViaPixelInfo ( image , image -> colormap +( ssize_t ) <nl> - GetPixelIndex ( image , q ), q ); <nl> + ConstrainColormapIndex ( image , GetPixelIndex ( image , q ), <nl> + exception ), q ); <nl> q += GetPixelChannels ( image ); <nl> x ++; <nl> }
static inline MagickSizeType GetPSDSize ( const PSDInfo * psd_info , Image * image ) <nl> static inline size_t GetPSDRowSize ( Image * image ) <nl> { <nl> if ( image -> depth == 1 ) <nl> - return (( image -> columns + 7 )/ 8 ); <nl> + return ((( image -> columns + 7 )/ 8 )* GetPSDPacketSize ( image )); <nl> else <nl> return ( image -> columns * GetPSDPacketSize ( image )); <nl> }
private : <nl> } <nl> } <nl>  <nl> + UPDATE_TRACE_POINT (); <nl> APR_BRIGADE_INSERT_TAIL ( bb , b ); <nl>  <nl> b = apr_bucket_eos_create ( r -> connection -> bucket_alloc );
void CCountryFlags :: OnInit () <nl> CCountryFlag DummyEntry ; <nl> DummyEntry . m_CountryCode = - 1 ; <nl> DummyEntry . m_Texture = - 1 ; <nl> + mem_zero ( DummyEntry . m_aCountryCodeString , sizeof ( DummyEntry . m_aCountryCodeString )); <nl> m_aCountryFlags . add ( DummyEntry ); <nl> } <nl> }
server_request_free_answers ( struct server_request * req ) <nl> free ( victim -> name ); <nl> if ( victim -> data ) <nl> free ( victim -> data ); <nl> - /* XXXX free ( victim ?) - NM */ <nl> + free ( victim ); <nl> victim = next ; <nl> } <nl> * list = NULL ;
int FileCopy :: Do () <nl> } <nl> if ( get -> Error () && get -> Size ()== 0 ) <nl> { <nl> - put -> PutEOF (); <nl> - Roll ( put ); <nl> + if ( put -> GetPos ()> 0 ) <nl> + { <nl> + put -> PutEOF (); <nl> + Roll ( put ); <nl> + } <nl> get_error : <nl> SetError ( get -> ErrorText ()); <nl> return MOVED ;
_win32_read_file ( void * state , void * data , zip_uint64_t len , zip_source_cmd_t cmd <nl> zip_error_set (& ctx -> error , ZIP_ER_RENAME , _zip_set_win32_error ( GetLastError (), & ctx -> win32err )); <nl> return - 1 ; <nl> } <nl> + free ( ctx -> tmpname ); <nl> + ctx -> tmpname = NULL ; <nl> return 0 ; <nl> } <nl> 
static int uv__ifaddr_exclude ( struct ifaddrs * ent ) { <nl> return 1 ; <nl> if ( ent -> ifa_addr == NULL ) <nl> return 1 ; <nl> - if ( ent -> ifa_addr -> sa_family == PF_PACKET ) <nl> + if ( ent -> ifa_addr -> sa_family != AF_INET && <nl> + ent -> ifa_addr -> sa_family != AF_INET6 ) <nl> return 1 ; <nl> return 0 ; <nl> }
static const char * static_camera_list [] = { <nl> " FujiFilm X - E1 ", <nl> " FujiFilm X - E2 ", <nl> " FujiFilm X - E2S ", <nl> + " FujiFilm X - E3 ", <nl> " FujiFilm X - M1 ", <nl> " FujiFilm XF1 ", <nl> " FujiFilm X - T1 ",
int sql_dump ( sqlite3 * db , const char * query , sqlite3_stmt ** handle ) <nl> ret = sqlite3_prepare ( db , query , - 1 , handle , NULL ); <nl> if ( ret != SQLITE_OK || ! handle ) { <nl> printf (" Error : sql_dump ()=% d % s \ n ", ret , sqlite3_errmsg ( db )); <nl> + return - 1 ; <nl> } <nl>  <nl> return ret ;
struct mk_iov * mk_iov_create ( int n , int offset ) <nl> iov = mk_mem_malloc ( sizeof ( struct mk_iov )); <nl> iov -> iov_idx = offset ; <nl> iov -> io = mk_mem_malloc_z ( n * sizeof ( struct iovec )); <nl> - iov -> buf_to_free = mk_mem_malloc_z ( n * sizeof ( char *)); <nl> + iov -> buf_to_free = mk_mem_malloc ( n * sizeof ( char *)); <nl> iov -> buf_idx = 0 ; <nl> iov -> total_len = 0 ; <nl> iov -> size = n ;
shell_global_get_runtime_state ( ShellGlobal * global , <nl> else <nl> { <nl> GBytes * bytes = g_mapped_file_get_bytes ( mfile ); <nl> - res = g_variant_new_from_bytes (( GVariantType *) property_type , bytes , TRUE ); <nl> + res = g_variant_new_from_bytes ( G_VARIANT_TYPE ( property_type ), bytes , TRUE ); <nl> g_bytes_unref ( bytes ); <nl> g_mapped_file_unref ( mfile ); <nl> }
static int SSHParseBanner ( SshState * state , SshHeader * header , const uint8_t * inp <nl> uint32_t line_len = input_len ; <nl>  <nl> /* is it the version line ? */ <nl> - if ( SCMemcmp (" SSH -", line_ptr , 4 ) != 0 ) { <nl> + if ( line_len >= 4 && SCMemcmp (" SSH -", line_ptr , 4 ) != 0 ) { <nl> SCReturnInt (- 1 ); <nl> } <nl> 
int SCCudaHlGetCudaModule ( CUmodule * p_module , const char * ptx_image , int handle ) <nl> if ( unlikely ( image == NULL )) { <nl> exit ( EXIT_FAILURE ); <nl> } <nl> - memset ( image , 0x0 , sizeof ( image )); <nl> + memset ( image , 0x0 , strlen ( ptx_image )+ 15 ); <nl>  <nl> int major = INT_MAX ; <nl> int minor = INT_MAX ;
ivec_reserve ( rust_task * task , type_desc * ty , rust_ivec * v , size_t n_elems ) <nl> } else { <nl> // On heap ; resize . <nl> heap_part = ( rust_ivec_heap *) task -> realloc ( v -> payload . ptr , <nl> - new_alloc ); <nl> + new_alloc + sizeof ( size_t )); <nl> v -> payload . ptr = heap_part ; <nl> } <nl> 
SOFTWARE , EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE . <nl> */ <nl>  <nl> +// transition helper <nl> +# ifdef FMT_FORMAT_PROVIDE_PRINTF <nl> +# include " printf . h " <nl> +# endif <nl> + <nl> # ifndef FMT_FORMAT_H_ <nl> # define FMT_FORMAT_H_ <nl> 
void FormatDecimal ( char * buffer , uint64_t value , unsigned num_digits ) { <nl> # ifdef _MSC_VER <nl> int signbit ( double value ) { <nl> if ( value < 0 ) return 1 ; <nl> - if (! isnan ( value )) return 0 ; <nl> + if ( value == value ) return 0 ; <nl> int dec = 0 , sign = 0 ; <nl> ecvt ( value , 0 , & dec , & sign ); <nl> return sign ;
CURLcode Curl_readwrite ( struct connectdata * conn , <nl> time_t secs = time ( NULL ); <nl> k -> timeofdoc = curl_getdate ( k -> p + strlen (" Last - Modified :"), <nl> & secs ); <nl> - if ( data -> set . get_filetime >= 0 ) <nl> + if ( data -> set . get_filetime ) <nl> data -> info . filetime = k -> timeofdoc ; <nl> } <nl> else if (( k -> httpcode >= 300 && k -> httpcode < 400 ) &&
int Curl_resolv_timeout ( struct connectdata * conn , <nl>  <nl> * entry = NULL ; <nl>  <nl> + if ( timeoutms < 0 ) <nl> + /* got an already expired timeout */ <nl> + return CURLRESOLV_TIMEDOUT ; <nl> + <nl> # ifdef USE_ALARM_TIMEOUT <nl> if ( data -> set . no_signal ) <nl> /* Ignore the timeout when signals are disabled */
CURLcode Curl_http ( struct connectdata * conn , bool * done ) <nl> if ( http -> writebytecount >= postsize ) { <nl> /* already sent the entire request body , mark the " upload " as <nl> complete */ <nl> - infof ( data , " upload completely sent off : %" FORMAT_OFF_T " out of " <nl> + infof ( data , " upload completely sent off : %" FORMAT_OFF_T " out of " <nl> "%" FORMAT_OFF_T " bytes \ n ", <nl> http -> writebytecount , postsize ); <nl> data -> req . upload_done = TRUE ;
static ssize_t send_callback ( nghttp2_session * h2 , <nl> ( void ) h2 ; <nl> ( void ) flags ; <nl>  <nl> + if (! c -> send_underlying ) <nl> + /* called before setup properly ! */ <nl> + return NGHTTP2_ERR_CALLBACK_FAILURE ; <nl> + <nl> written = (( Curl_send *) c -> send_underlying )( conn , FIRSTSOCKET , <nl> data , length , & result ); <nl> 
void curl_easy_reset ( struct Curl_easy * data ) <nl>  <nl> data -> progress . flags |= PGRS_HIDE ; <nl> data -> state . current_speed = - 1 ; /* init to negative == impossible */ <nl> + <nl> + /* zero out authentication data : */ <nl> + memset (& data -> state . authhost , 0 , sizeof ( struct auth )); <nl> + memset (& data -> state . authproxy , 0 , sizeof ( struct auth )); <nl> } <nl>  <nl> /*
static int me_gcap ( struct Client *, struct Client *, int , const char **); <nl>  <nl> struct Message capab_msgtab = { <nl> " CAPAB ", 0 , 0 , 0 , MFLG_SLOW | MFLG_UNREG , <nl> - {{ mr_capab , 0 }, mg_ignore , mg_ignore , mg_ignore , mg_ignore , mg_ignore } <nl> + {{ mr_capab , 2 }, mg_ignore , mg_ignore , mg_ignore , mg_ignore , mg_ignore } <nl> }; <nl> struct Message gcap_msgtab = { <nl> " GCAP ", 0 , 0 , 0 , MFLG_SLOW ,
foptoas ( int op , Type * t , int flg ) <nl> { <nl> int et , a ; <nl>  <nl> + a = AGOK ; <nl> et = simtype [ t -> etype ]; <nl>  <nl> if ( use_sse )
pc2line ( uvlong pc ) <nl> if ( pc < currpc || pc > txtend ) <nl> return ~ 0 ; <nl>  <nl> - for ( c = pcline ; c < pclineend && pc <= currpc ; c ++) { <nl> + for ( c = pcline ; c < pclineend && currpc < pc ; c ++) { <nl> u = * c ; <nl> if ( u == 0 ) { <nl> currline += ( c [ 1 ]<< 24 )|( c [ 2 ]<< 16 )|( c [ 3 ]<< 8 )| c [ 4 ];
static struct DWAbbrev { <nl> DW_TAG_subrange_type , DW_CHILDREN_no , <nl> // No name ! <nl> DW_AT_type , DW_FORM_ref_addr , <nl> - DW_AT_upper_bound , DW_FORM_data1 , <nl> + DW_AT_upper_bound , DW_FORM_udata , <nl> 0 , 0 <nl> }, <nl> 
runtime · Goexit ( void ) <nl> rundefer (); <nl> runtime · goexit (); <nl> } <nl> + <nl> + void <nl> + runtime · panicdivide ( void ) <nl> +{ <nl> + runtime · panicstring (" integer divide by zero "); <nl> +}
dumpbv ( BitVector * bv , uintptr offset ) <nl> for ( i = 0 ; i < bv -> n ; i += BitsPerPointer ) { <nl> switch ( bv -> bytedata [ i / 8 ] >> i % 8 & 3 ) { <nl> case BitsDead : <nl> - return ; <nl> + // BitsDead has already been processed in makeheapobjbv . <nl> + // We should only see it in stack maps , in which case we should continue processing . <nl> + break ; <nl> case BitsScalar : <nl> break ; <nl> case BitsPointer :
int asn1parse_main ( int argc , char ** argv ) <nl> ASN1_TYPE * atmp ; <nl> int typ ; <nl> j = atoi ( sk_OPENSSL_STRING_value ( osk , i )); <nl> - if ( j == 0 ) { <nl> + if ( j <= 0 || j >= tmplen ) { <nl> BIO_printf ( bio_err , "'% s ' is an invalid number \ n ", <nl> sk_OPENSSL_STRING_value ( osk , i )); <nl> continue ;
int OBJ_create ( const char * oid , const char * sn , const char * ln ) <nl>  <nl> /* Convert numerical OID string to an ASN1_OBJECT structure */ <nl> tmpoid = OBJ_txt2obj ( oid , 1 ); <nl> + if ( tmpoid == NULL ) <nl> + return 0 ; <nl>  <nl> /* If NID is not NID_undef then object already exists */ <nl> if ( OBJ_obj2nid ( tmpoid ) != NID_undef ) {
static int pkey_gost_ctrl ( EVP_PKEY_CTX * ctx , int type , int p1 , void * p2 ) <nl> return 1 ; <nl> case EVP_PKEY_CTRL_SET_IV : <nl> pctx -> shared_ukm = OPENSSL_malloc (( int ) p1 ); <nl> + if ( pctx -> shared_ukm == NULL ) <nl> + { <nl> + GOSTerr ( GOST_F_PKEY_GOST_CTRL , ERR_R_MALLOC_FAILURE ); <nl> + return 0 ; <nl> + } <nl> memcpy ( pctx -> shared_ukm , p2 ,( int ) p1 ); <nl> return 1 ; <nl> case EVP_PKEY_CTRL_PEER_KEY :
static int tree_init ( X509_POLICY_TREE ** ptree , STACK_OF ( X509 ) * certs , <nl> X509_check_purpose ( x , - 1 , 0 ); <nl>  <nl> /* If cache is NULL , likely ENOMEM : return immediately */ <nl> - if (( cache = policy_cache_set ( x )) == NULL ) <nl> + if ( policy_cache_set ( x ) == NULL ) <nl> return X509_PCY_TREE_INTERNAL ; <nl> } <nl> 
static void cms_env_set_version ( CMS_EnvelopedData * env ) <nl> env -> version = 2 ; <nl> } <nl> } <nl> - if ( env -> version == 2 ) <nl> - return ; <nl> if ( env -> originatorInfo || env -> unprotectedAttrs ) <nl> env -> version = 2 ; <nl> + if ( env -> version == 2 ) <nl> + return ; <nl> env -> version = 0 ; <nl> } <nl> 
static CAPI_KEY * capi_get_key ( CAPI_CTX * ctx , const TCHAR * contname , TCHAR * provn <nl> CAPI_KEY * key ; <nl> DWORD dwFlags = 0 ; <nl> key = OPENSSL_malloc ( sizeof ( CAPI_KEY )); <nl> + if ( key == NULL ) <nl> + return NULL ; <nl> if ( sizeof ( TCHAR )== sizeof ( char )) <nl> CAPI_trace ( ctx , " capi_get_key , contname =% s , provname =% s , type =% d \ n ", <nl> contname , provname , ptype );
retry : <nl> struct stat statbuf ; <nl>  <nl> strcpy ( filename , str ); <nl> + free ( str ); <nl> if (! stat ( filename , & statbuf )) { <nl> wlogprint (" File exists , overwrite ?\ n "); <nl> input = getch (); <nl> retry : <nl> goto retry ; <nl> } <nl> } <nl> + else <nl> + free ( str ); <nl> fcfg = fopen ( filename , " w "); <nl> if (! fcfg ) { <nl> wlogprint (" Cannot open or create file \ n ");
static void * miner_thread ( void * userdata ) <nl> nonce_inc = next_inc ; <nl> } else if (! diff . tv_sec ) <nl> nonce_inc = hashes_done * 2 ; <nl> + if ( nonce_inc < 4 ) <nl> + nonce_inc = 0xffffff ; <nl> max64 = work -> blk . nonce + nonce_inc ; <nl> if ( max64 > 0xfffffffaULL ) <nl> max64 = 0xfffffffaULL ;
read_gif ( Gif_Reader * grr , int read_flags , <nl> Gif_DeleteArray ( gfc . suffix ); <nl> Gif_DeleteArray ( gfc . length ); <nl> gfc . gfi = 0 ; <nl> + last_name = 0 ; <nl>  <nl> if ( gfs ) <nl> gfs -> errors = gfc . errors [ 1 ];
particular purpose .\ n "); <nl> # ifdef DMALLOC <nl> dmalloc_report (); <nl> # endif <nl> + Clp_DeleteParser ( clp ); <nl> return ( error_count ? EXIT_ERR : EXIT_OK ); <nl> }
int main ( int argc , char ** argv ) <nl> printf ("% s \ n ", context ); <nl> freecon ( context ); <nl> } <nl> + free ( pc [ i ]); <nl> } <nl>  <nl> printf ("\ nFile contexts :\ n "); <nl> int main ( int argc , char ** argv ) <nl> freecon ( context ); <nl> } <nl> } <nl> + free ( fc [ i ]); <nl> } <nl>  <nl> return 0 ;
doRetry ( nsd_gtls_t * pNsd ) <nl> break ; <nl> default : <nl> assert ( 0 ); /* this shall not happen ! */ <nl> + dbgprintf (" ERROR : pNsd -> rtryCall invalid in nsdsel_gtls . c :% d \ n ", __LINE__ ); <nl> + gnuRet = 0 ; /* if it happens , we have at least a defined behaviour ... ;) */ <nl> break ; <nl> } <nl> 
archive_acl_from_text_l ( struct archive_acl * acl , const char * text , <nl> st = field [ n ]. start + 1 ; <nl> len = field [ n ]. end - field [ n ]. start ; <nl>  <nl> + if ( len == 0 ) { <nl> + ret = ARCHIVE_WARN ; <nl> + continue ; <nl> + } <nl> + <nl> switch (* s ) { <nl> case ' u ': <nl> if ( len == 1 || ( len == 4
int mutt_index_menu ( void ) <nl> char buf [ 128 ]; <nl>  <nl> buf [ 0 ] = '\ 0 '; <nl> - if (! mutt_get_field (" Enter macro stroke : ", buf , sizeof ( buf ), <nl> + if (! mutt_get_field ( _ (" Enter macro stroke : "), buf , sizeof ( buf ), <nl> MUTT_CLEAR ) && buf [ 0 ]) <nl> { <nl> snprintf ( str , sizeof ( str ), "% s % s ", MarkMacroPrefix , buf );
int mutt_pattern_func ( int op , char * prompt ) <nl> simple = safe_strdup ( buf ); <nl> mutt_check_simple ( buf , sizeof ( buf ), NONULL ( SimpleSearch )); <nl>  <nl> + memset (& err , 0 , sizeof ( err )); <nl> err . data = error ; <nl> err . dsize = sizeof ( error ); <nl> if (( pat = mutt_pattern_comp ( buf , M_FULL_MSG , & err )) == NULL )
int main ( int argc , char * argv []) <nl> if (! use_curses ) <nl> early_quit ( 0 , " No servers could be used ! Exiting ."); <nl> # ifdef HAVE_CURSES <nl> + wrefresh ( logwin ); <nl> halfdelay ( 10 ); <nl> if ( getch () != ERR ) <nl> early_quit ( 0 , " No servers could be used ! Exiting .");
static int open_user_core ( uid_t uid , uid_t fsuid , pid_t pid , char ** percent_valu <nl>  <nl> static bool dump_fd_info ( const char * dest_filename , char * source_filename , int source_base_ofs , uid_t uid , gid_t gid ) <nl> { <nl> - FILE * fp = fopen ( dest_filename , " w "); <nl> + FILE * fp = fopen ( dest_filename , " wx "); <nl> if (! fp ) <nl> return false ; <nl> 
static void server_recv_cb ( EV_P_ ev_io * w , int revents ) <nl>  <nl> if ( remote_ctx != NULL ) { <nl> if ( memcmp (& src_addr , & remote_ctx -> src_addr , sizeof ( src_addr )) <nl> - || strcmp ( addr_header , remote_ctx -> addr_header ) != 0 ) { <nl> + || remote_ctx -> addr_header_len != addr_header_len <nl> + || memcmp ( addr_header , remote_ctx -> addr_header , addr_header_len ) != 0 ) { <nl> remote_ctx = NULL ; <nl> } <nl> }
php_http_info_t * php_http_info_parse ( php_http_info_t * info , const char * pre_head <nl> } else { <nl> PHP_HTTP_INFO ( info ). request . url = php_http_url_parse_authority ( url , http - url , ~ 0 TSRMLS_CC ); <nl> } <nl> + if (! PHP_HTTP_INFO ( info ). request . url ) { <nl> + PTR_SET ( PHP_HTTP_INFO ( info ). request . method , NULL ); <nl> + return NULL ; <nl> + } <nl> } else { <nl> PTR_SET ( PHP_HTTP_INFO ( info ). request . method , NULL ); <nl> return NULL ;
void h2o_http2_scheduler_rebind ( h2o_http2_scheduler_node_t * parent , h2o_http2_sc <nl> decr_active_cnt ( ref -> super . _parent ); <nl> incr_active_cnt ( parent ); <nl> } <nl> + /* update the backlinks */ <nl> + ref -> super . _parent = parent ; <nl> + ref -> super . _slot = new_slot ; <nl>  <nl> if ( exclusive ) <nl> convert_to_exclusive ( parent , ref );
LibreportError save_dump_dir_from_problem_data ( problem_data_t * problem_data , cha <nl> VERB2 log (" Renaming from '% s ' to '% s '", dd -> dd_dirname , new_path ); <nl> if ( dd_rename ( dd , new_path ) != 0 ) <nl> { <nl> + free ( new_path ); <nl> + dd_close ( dd ); <nl> + <nl> free (* problem_id ); <nl> * problem_id = NULL ; <nl> return LR_ERROR ; <nl> } <nl> - free ( new_path ); <nl>  <nl> + free ( new_path ); <nl> dd_close ( dd ); <nl>  <nl> return LR_OK ;
static void view_bookmarks_check ( TEXT_BUFFER_VIEW_REC * view , LINE_REC * line ) <nl> if ( new_line != NULL ) { <nl> g_hash_table_insert ( view -> bookmarks , <nl> tmp -> data , new_line ); <nl> + } else { <nl> + g_free ( tmp -> data ); <nl> } <nl> } <nl> g_slist_free ( rec . remove_list );
dhcp6opt_print ( const u_char * cp , const u_char * ep ) <nl> if ( ep < cp + sizeof (* dh6o )) <nl> goto trunc ; <nl> dh6o = ( struct dhcp6opt *) cp ; <nl> + TCHECK (* dh6o ); <nl> optlen = EXTRACT_16BITS (& dh6o -> dh6opt_len ); <nl> if ( ep < cp + sizeof (* dh6o ) + optlen ) <nl> goto trunc ;
local size_t compressed_suffix ( char * nm ) <nl> if ( len > 4 ) { <nl> nm += len - 4 ; <nl> len = 4 ; <nl> - if ( strcmp ( nm , ". zip ") == 0 || strcmp ( nm , ". ZIP ") == 0 ) <nl> + if ( strcmp ( nm , ". zip ") == 0 || strcmp ( nm , ". ZIP ") == 0 || strcmp ( nm , ". spli ") == 0 ) <nl> return 4 ; <nl> } <nl> if ( len > 3 ) {
bool find_server ( PgSocket * client ) <nl> sbuf_pause (& client -> sbuf ); <nl> res = false ; /* don ' t process client data yet */ <nl> server -> setting_vars = 1 ; <nl> + server -> ready = 0 ; <nl> } else <nl> res = true ; <nl> } else {
ImagingNewBlock ( const char * mode , int xsize , int ysize ) <nl> if ( im -> linesize && <nl> im -> ysize > INT_MAX / im -> linesize ) { <nl> /* punt if we ' re going to overflow */ <nl> - return NULL ; <nl> + ImagingDelete ( im ); <nl> + return ( Imaging ) ImagingError_MemoryError (); <nl> } <nl>  <nl> if ( im -> ysize * im -> linesize <= 0 ) {
 <nl> int xerbla_ ( char * srname , integer * info ) <nl> { <nl> - const char * format = " On entry to %.* s " \ <nl> + char * format = " On entry to %.* s " \ <nl> " parameter number % d had an illegal value "; <nl> char buf [ 60 + 6 + 4 ]; /* 6 for name , 4 for param . num . */ <nl> 
int createEKHandle ( TSS2_SYS_CONTEXT * sapi_context ) <nl> LOG_INFO (" EK create succ .. Handle : 0x % 8 . 8x ", handle2048ek ); <nl>  <nl> if (! ctx . non_persistent_read ) { <nl> + <nl> + if (! ctx . persistent_handle ) { <nl> + LOG_ERR (" Persistent handle for EK was not provided "); <nl> + return 1 ; <nl> + } <nl> + <nl> /* <nl> * To make EK persistent , use own auth <nl> */
static DecodeStatus Mips64Disassembler_getInstruction ( int mode , MCInst * instr , <nl> { <nl> uint32_t Insn ; <nl>  <nl> + if ( code_len < 4 ) <nl> + // not enough data <nl> + return MCDisassembler_Fail ; <nl> + <nl> + if ( instr -> flat_insn -> detail ) { <nl> + memset ( instr -> flat_insn -> detail , 0 , sizeof ( cs_detail )); <nl> + } <nl> + <nl> DecodeStatus Result = readInstruction32 (( unsigned char *) code , & Insn , isBigEndian , false ); <nl> if ( Result == MCDisassembler_Fail ) <nl> return MCDisassembler_Fail ;
CAMLprim value caml_bytes_set ( value str , value index , value newval ) <nl> */ <nl> CAMLprim value caml_string_set ( value str , value index , value newval ) <nl> { <nl> - return caml_string_set ( str , index , newval ); <nl> + return caml_bytes_set ( str , index , newval ); <nl> } <nl>  <nl> 
__no_resolve : <nl> if (( off = lseek ( _state . s_wpafd , 0 , SEEK_CUR )) == ( off_t ) - 1 ) <nl> err ( 1 , " lseek ()"); <nl>  <nl> + if ( lseek ( _state . s_wpafd , 0 , SEEK_SET ) == ( off_t ) - 1 ) <nl> + err ( 1 , " lseek ()"); <nl> + <nl> while ( tot ) { <nl> int l = tot ; <nl> 
int main ( int argc , char ** argv ) <nl> info . subusers . erase ( uiter ); <nl> if ( purge_keys ) { <nl> map < string , RGWAccessKey > * keys_map ; <nl> - access_key = subuser ; <nl> + access_key = info . user_id ; <nl> access_key . append (":"); <nl> access_key . append ( subuser ); <nl> keys_map = & info . swift_keys ;
class MDentryLink : public Message { <nl> dirfrag ( df ), <nl> dn ( n ), <nl> is_primary ( p ) {} <nl> + private : <nl> + ~ MDentryLink () {} <nl>  <nl> + public : <nl> const char * get_type_name () { return " dentry_link ";} <nl> void print ( ostream & o ) { <nl> o << " dentry_link (" << dirfrag << " " << dn << ")";
inline ostream & operator <<( ostream & out , const sockaddr_storage & ss ) <nl>  <nl> inline ostream & operator <<( ostream & out , const sockaddr_in & ss ) <nl> { <nl> - char buf [ NI_MAXHOST ]; <nl> + char buf [ NI_MAXHOST ] = { 0 }; <nl> getnameinfo (( struct sockaddr *)& ss , sizeof ( ss ), buf , sizeof ( buf ), 0 , 0 , NI_NUMERICHOST ); <nl> return out << buf ; <nl> }
void PG :: _compare_scrubmaps ( const map < int , ScrubMap *> & maps , <nl> set < int > cur_missing ; <nl> set < int > cur_inconsistent ; <nl> for ( j = maps . begin (); j != maps . end (); ++ j ) { <nl> + if ( j == auth ) <nl> + continue ; <nl> if ( j -> second -> objects . count (* k )) { <nl> // Compare <nl> stringstream ss ;
public : <nl> */ <nl> void get_leaves_under ( frag_t x , std :: list < frag_t >& ls ) const { <nl> std :: list < frag_t > q ; <nl> - q . push_back ( get_branch ( x )); <nl> + q . push_back ( get_branch_or_leaf ( x )); <nl> while (! q . empty ()) { <nl> frag_t t = q . front (); <nl> q . pop_front ();
void CInode :: validate_disk_state ( CInode :: validated_data * results , <nl> } else if ( fin ) { <nl> fin -> complete ( get_rval ()); <nl> } <nl> + delete this ; <nl> } <nl> }; <nl> 
int aio_bench ( Rados & rados , rados_pool_t pool , int secondsToRun , int concurrenti <nl> time (& initialTime ); <nl> stringstream initialTimeS (""); <nl> initialTimeS << initialTime ; <nl> - const char * iTime = initialTimeS . str (). c_str (); <nl> + char iTime [ 100 ]; <nl> + strcpy ( iTime , initialTimeS . str (). c_str ()); <nl> maxLatency . set_from_double ( 0 ); <nl> // set up writes so I can start them together <nl> for ( int i = 0 ; i < concurrentios ; ++ i ) {
void PG :: scrub () <nl> ss << ", " << fixed << " fixed "; <nl> osd -> get_logclient ()-> log ( errors ? LOG_ERROR : LOG_INFO , ss ); <nl>  <nl> - if (!( errors - fixed ) && repair ) <nl> + if ( errors == 0 || ( repair && ( errors - fixed ) == 0 )) <nl> state_clear ( PG_STATE_INCONSISTENT ); <nl> state_clear ( PG_STATE_REPAIR ); <nl> 
int ceph_do_lookup ( struct super_block * sb , struct dentry * dentry , int mask ) <nl> struct ceph_mds_request_head * rhead ; <nl> int err ; <nl>  <nl> + if ( dentry -> d_name . len > NAME_MAX ) <nl> + return - ENAMETOOLONG ; <nl> + <nl> dout ( 10 , " do_lookup % p mask % d \ n ", dentry , CEPH_STAT_MASK_INODE_ALL ); <nl> path = ceph_build_dentry_path ( dentry , & pathlen ); <nl> if ( IS_ERR ( path ))
void Locker :: xlock_finish ( SimpleLock * lock , Mutation * mut ) <nl> lock -> get_num_client_lease () == 0 ) { <nl> assert (! lock -> is_stable ()); <nl> lock -> get_parent ()-> auth_unpin ( lock ); <nl> - lock -> set_state ( LOCK_LOCK ); <nl> + if ( lock -> get_type () != CEPH_LOCK_DN && (( CInode *) lock -> get_parent ())-> get_loner () >= 0 ) <nl> + lock -> set_state ( LOCK_EXCL ); <nl> + else <nl> + lock -> set_state ( LOCK_LOCK ); <nl> } <nl>  <nl> // others waiting ?
void PG :: start_peering_interval ( <nl> state_clear ( PG_STATE_REMAPPED ); <nl>  <nl> int role = osdmap -> calc_pg_role ( osd -> whoami , acting , acting . size ()); <nl> - if ( role == pg_whoami . shard ) <nl> + if ( pool . info . is_replicated () || role == pg_whoami . shard ) <nl> set_role ( role ); <nl> else <nl> set_role (- 1 );
bool OSDMonitor :: prepare_command_impl ( MonOpRequestRef op , <nl> } <nl>  <nl> if ( tunable == " straw_calc_version ") { <nl> - if ( value < 0 || value > 2 ) { <nl> + if ( value < 0 || value > 1 ) { <nl> ss << " value must be 0 or 1 ; got " << value ; <nl> err = - EINVAL ; <nl> goto reply ;
void Server :: _rename_prepare ( MDRequestRef & mdr , <nl> } <nl> if ( tpi ) { <nl> tpi -> ctime = mdr -> get_op_stamp (); <nl> + destdn -> make_path_string ( tpi -> stray_prior_path ); <nl> tpi -> nlink --; <nl> if ( tpi -> nlink == 0 ) <nl> oldin -> state_set ( CInode :: STATE_ORPHAN );
done : <nl> handler -> put_op ( op ); <nl> rgwstore -> destroy_context ( s -> obj_ctx ); <nl> FCGX_Finish_r ( fcgx ); <nl> - delete req ; <nl>  <nl> dout ( 1 ) << "====== req done req =" << hex << req << dec << " http_status =" << http_ret << " ======" << dendl ; <nl> + delete req ; <nl> } <nl>  <nl> class C_InitTimeout : public Context {
int RGWRados :: prepare_atomic_for_write ( RGWRadosCtx * rctx , rgw_obj & obj , librados <nl> do { <nl> r = prepare_atomic_for_write_impl ( rctx , obj , io_ctx , actual_obj , op , pstate ); <nl> } while ( r == - ECANCELED ); <nl> + <nl> + return r ; <nl> } <nl>  <nl> /**
public : <nl> param ( NULL ) {} <nl> ~ CryptoAESKeyHandler () { <nl> SECITEM_FreeItem ( param , PR_TRUE ); <nl> - PK11_FreeSymKey ( key ); <nl> - PK11_FreeSlot ( slot ); <nl> + if ( key ) <nl> + PK11_FreeSymKey ( key ); <nl> + if ( slot ) <nl> + PK11_FreeSlot ( slot ); <nl> } <nl>  <nl> int init ( const bufferptr & s , ostringstream & err ) {
int OSD :: init_op_flags ( OpRequestRef op ) <nl> } <nl> } <nl>  <nl> + if ( op -> rmw_flags == 0 ) <nl> + return - EINVAL ; <nl> + <nl> return 0 ; <nl> }
int main ( int argc , const char ** argv ) <nl> derr << " ERROR : failed initializing frontend " << dendl ; <nl> return - r ; <nl> } <nl> - fe -> run (); <nl> + r = fe -> run (); <nl> + if ( r < 0 ) { <nl> + derr << " ERROR : failed run " << dendl ; <nl> + return - r ; <nl> + } <nl>  <nl> fes . push_back ( fe ); <nl> }
bool CephXAuthorizer :: verify_reply ( bufferlist :: iterator & indata ) <nl> } <nl> } catch ( buffer :: error * e ) { <nl> dout ( 0 ) << " verify_authorizer_reply exception in decode_decrypt with " << session_key << dendl ; <nl> + delete e ; <nl> return false ; <nl> } <nl> 
void Server :: handle_client_setlayout ( MDRequest * mdr ) <nl> // validate layout <nl> // FIXME : only set striping parameters , for now . <nl> ceph_file_layout layout ; <nl> + memset (& layout , 0 , sizeof ( layout )); <nl>  <nl> if ( req -> head . args . setlayout . layout . fl_object_size > 0 ) <nl> layout . fl_object_size = req -> head . args . setlayout . layout . fl_object_size ;
void SaveVCalendar ( TNEFStruct TNEF , int isMtgReq ) { <nl> if ( isMtgReq ) { <nl> CreateUniqueFilename ( ifilename , MAX_FILENAME_SIZE , " MtgReq ", " ics ", filepath ); <nl> } else { <nl> - CreateUniqueFilename ( ifilename , MAX_FILENAME_SIZE , " calendar ", " vcf ", filepath ); <nl> + CreateUniqueFilename ( ifilename , MAX_FILENAME_SIZE , " calendar ", " ics ", filepath ); <nl> } <nl>  <nl> printf ("% s \ n ", ifilename );
int der_decode_raw_bit_string ( const unsigned char * in , unsigned long inlen , <nl> blen = (( dlen - 1 ) << 3 ) - ( in [ x ++] & 7 ); <nl>  <nl> /* too many bits ? */ <nl> - if ( blen > * outlen ) { <nl> + if ( blen / 8 > * outlen ) { <nl> * outlen = blen ; <nl> return CRYPT_BUFFER_OVERFLOW ; <nl> }
uint64 ReadCodedSizeValue ( const binary * InBuffer , uint32 & BufferSize , uint64 & <nl> // ID found <nl> PossibleSizeLength = SizeIdx + 1 ; <nl> SizeBitMask >>= SizeIdx ; <nl> + <nl> + // Guard against invalid memory accesses with incomplete IDs . <nl> + if ( PossibleSizeLength > BufferSize ) <nl> + break ; <nl> + <nl> for ( SizeIdx = 0 ; SizeIdx < PossibleSizeLength ; SizeIdx ++) { <nl> PossibleSize [ SizeIdx ] = InBuffer [ SizeIdx ]; <nl> }
static char * check_dir_or_file ( const char * name ) { <nl> if ( ptr && strlen ( ptr ) == strlen ("/ firejail ")) { <nl> if ( arg_debug ) <nl> printf (" firejail exec symlink detected \ n "); <nl> + free ( actual_path ); <nl> free ( fname ); <nl> fname = NULL ; <nl> i ++; <nl> continue ; <nl> } <nl> + free ( actual_path ); <nl> } <nl>  <nl> }
rsvg_characters_impl ( RsvgHandle * ctx , const xmlChar * ch , int len ) <nl>  <nl> if ( ctx -> priv -> currentnode ) <nl> rsvg_node_add_child ( ctx -> priv -> currentnode , node ); <nl> + <nl> + node = rsvg_node_unref ( node ); <nl> } <nl>  <nl> static void
int ares_init_options_with_socket_function ( ares_channel * channelptr , struct ares <nl> channel -> ndomains = - 1 ; <nl> channel -> nsort = - 1 ; <nl> channel -> lookups = NULL ; <nl> + channel -> servers = NULL ; <nl>  <nl> /* Initialize configuration by each of the four sources , from highest <nl> * precedence to lowest .
static Image * ReadTIFFImage ( const ImageInfo * image_info , <nl> /* <nl> Convert stripped TIFF image . <nl> */ <nl> - extent = 4 *( samples_per_pixel + 1 )* TIFFStripSize ( tiff ); <nl> + extent = 4 *(( image -> depth + 7 )/ 8 )*( samples_per_pixel + 1 )* TIFFStripSize ( tiff ); <nl> strip_pixels =( unsigned char *) AcquireQuantumMemory ( extent , <nl> sizeof (* strip_pixels )); <nl> if ( strip_pixels == ( unsigned char *) NULL )
virDomainGetTime ( virDomainPtr dom , <nl> virResetLastError (); <nl>  <nl> virCheckDomainReturn ( dom , - 1 ); <nl> + virCheckReadOnlyGoto ( dom -> conn -> flags , error ); <nl>  <nl> if ( dom -> conn -> driver -> domainGetTime ) { <nl> int ret = dom -> conn -> driver -> domainGetTime ( dom , seconds ,
ofproto_rule_insert__ ( struct ofproto * ofproto , struct rule * rule ) <nl> const struct rule_actions * actions = rule_get_actions ( rule ); <nl>  <nl> /* A rule may not be reinserted . */ <nl> - ovs_assert ( rule -> state == RULE_INITIALIZED ); <nl> + ovs_assert ( rule -> state != RULE_INSERTED ); <nl>  <nl> if ( rule -> hard_timeout || rule -> idle_timeout ) { <nl> ovs_list_insert (& ofproto -> expirable , & rule -> expirable );
uint32_t skip ( Protocol_ & prot , TType arg_type ) { <nl> result += prot . readListEnd (); <nl> return result ; <nl> } <nl> - default : <nl> - return 0 ; <nl> + default : { <nl> + TProtocolException :: throwInvalidSkipType ( arg_type ); <nl> + } <nl> } <nl> } <nl> 
innobase_start_or_create_for_mysql ( void ) <nl> sum_of_new_sizes += srv_data_file_sizes [ i ]; <nl> } <nl>  <nl> - if ( sum_of_new_sizes < 640 ) { <nl> + if ( sum_of_new_sizes < 10485760 / UNIV_PAGE_SIZE ) { <nl> fprintf ( stderr , <nl> " InnoDB : Error : tablespace size must be " <nl> " at least 10 MB \ n ");
multi_delete :: multi_delete ( THD * thd_arg , TABLE_LIST * dt , <nl> table -> used_keys = 0 ; <nl> tempfiles [ counter ] = new Unique ( refposcmp2 , <nl> ( void *) & table -> file -> ref_length , <nl> - table -> file -> ref_length + 1 , <nl> + table -> file -> ref_length , <nl> MEM_STRIP_BUF_SIZE ); <nl> } <nl> }
int <nl> Tablespace_client :: get_tablespace_info ( CreateFilegroupImplReq * rep ) <nl> { <nl> Ptr < Tsman :: Tablespace > ts_ptr ; <nl> - if ( m_tsman -> m_tablespace_hash . find ( ts_ptr , m_tablespace_id )); <nl> + if ( m_tsman -> m_tablespace_hash . find ( ts_ptr , m_tablespace_id )) <nl> { <nl> rep -> tablespace . extent_size = ts_ptr . p -> m_extent_size ; <nl> rep -> tablespace . logfile_group_id =
buf_page_init_for_read ( <nl> } <nl> } <nl>  <nl> + ut_a (! block -> page . buf_fix_count ); <nl> + block -> page . buf_fix_count ++;; <nl> rw_lock_x_lock (& block -> lock ); <nl> mutex_exit (& block -> mutex ); <nl> mutex_exit (& buf_pool -> zip_mutex ); <nl> buf_page_init_for_read ( <nl> } <nl>  <nl> buf_zip_decompress ( block , srv_use_checksums ); <nl> + mutex_enter (& block -> mutex ); <nl> + block -> page . buf_fix_count --; <nl> + mutex_exit (& block -> mutex ); <nl> rw_lock_x_unlock (& block -> lock ); <nl>  <nl> return ( NULL );
int TLSX_ValidateEllipticCurves ( CYASSL * ssl , byte first , byte second ) { <nl> int sig = 0 ; /* valitade signature */ <nl> int key = 0 ; /* validate key */ <nl>  <nl> + ( void ) oid ; <nl> + ( void ) octets ; <nl> + <nl> if (! extension ) <nl> return 1 ; /* no suite restriction */ <nl> 
void wolfSSL_X509_STORE_CTX_set_time ( WOLFSSL_X509_STORE_CTX * ctx , <nl> { <nl> ( void ) flags ; <nl>  <nl> + if ( ctx == NULL ) <nl> + return ; <nl> + <nl> ctx -> param -> check_time = t ; <nl> ctx -> param -> flags |= WOLFSSL_USE_CHECK_TIME ; <nl> }
void InitX509Name ( WOLFSSL_X509_NAME * name , int dynamicFlag ) <nl> # ifdef OPENSSL_EXTRA <nl> XMEMSET (& name -> fullName , 0 , sizeof ( DecodedName )); <nl> XMEMSET (& name -> cnEntry , 0 , sizeof ( WOLFSSL_X509_NAME_ENTRY )); <nl> + XMEMSET (& name -> extra , 0 , sizeof ( name -> extra )); <nl> name -> cnEntry . value = &( name -> cnEntry . data ); /* point to internal data */ <nl> name -> cnEntry . nid = ASN_COMMON_NAME ; <nl> name -> x509 = NULL ;
EXPORT_SYMBOL ( _find_next_zero_bit_be ); <nl> EXPORT_SYMBOL ( _find_first_bit_be ); <nl> EXPORT_SYMBOL ( _find_next_bit_be ); <nl> # endif <nl> + <nl> + EXPORT_SYMBOL ( copy_page );
static ssize_t xenbus_file_write ( struct file * filp , <nl> goto out ; <nl>  <nl> /* Can ' t write a xenbus message larger we can buffer */ <nl> - if (( len + u -> len ) > sizeof ( u -> u . buffer )) { <nl> + if ( len > sizeof ( u -> u . buffer ) - u -> len ) { <nl> /* On error , dump existing buffer */ <nl> u -> len = 0 ; <nl> rc = - EINVAL ;
void ath6kl_destroy ( struct net_device * dev , unsigned int unregister ) <nl>  <nl> wlan_node_table_cleanup (& ar -> scan_table ); <nl>  <nl> + kfree ( ar -> fw_board ); <nl> + kfree ( ar -> fw_otp ); <nl> + kfree ( ar -> fw ); <nl> + kfree ( ar -> fw_patch ); <nl> + <nl> ath6kl_cfg80211_deinit ( ar ); <nl> }
static int xemaclite_send ( struct sk_buff * orig_skb , struct net_device * dev ) <nl> skb_tx_timestamp ( new_skb ); <nl>  <nl> dev -> stats . tx_bytes += len ; <nl> - dev_kfree_skb ( new_skb ); <nl> + dev_consume_skb_any ( new_skb ); <nl>  <nl> return 0 ; <nl> }
static int skfp_ioctl ( struct net_device * dev , struct ifreq * rq , int cmd ) <nl> break ; <nl> case SKFP_CLR_STATS : /* Zero out the driver statistics */ <nl> if (! capable ( CAP_NET_ADMIN )) { <nl> - memset (& lp -> MacStat , 0 , sizeof ( lp -> MacStat )); <nl> - } else { <nl> status = - EPERM ; <nl> + } else { <nl> + memset (& lp -> MacStat , 0 , sizeof ( lp -> MacStat )); <nl> } <nl> break ; <nl> default :
static ssize_t auerchar_write ( struct file * file , const char __user * buf , size_t <nl> int ret ; <nl> wait_queue_t wait ; <nl>  <nl> - dbg (" auerchar_write % d bytes ", len ); <nl> + dbg (" auerchar_write % zd bytes ", len ); <nl>  <nl> /* Error checking */ <nl> if (! ccp )
static struct omap2_hsmmc_info mmc [] = { <nl> { <nl> . mmc = 1 , <nl> . caps = MMC_CAP_4_BIT_DATA | MMC_CAP_8_BIT_DATA , <nl> + . gpio_cd = - EINVAL , <nl> . gpio_wp = - EINVAL , <nl> }, <nl> {} /* Terminator */
static int clk_wzrd_probe ( struct platform_device * pdev ) <nl> reg = ( readl ( clk_wzrd -> base + WZRD_CLK_CFG_REG ( 0 )) & <nl> WZRD_DIVCLK_DIVIDE_MASK ) >> WZRD_DIVCLK_DIVIDE_SHIFT ; <nl> clk_name = kasprintf ( GFP_KERNEL , "% s_mul_div ", dev_name (& pdev -> dev )); <nl> + if (! clk_name ) { <nl> + ret = - ENOMEM ; <nl> + goto err_rm_int_clk ; <nl> + } <nl> + <nl> clk_wzrd -> clks_internal [ wzrd_clk_mul_div ] = clk_register_fixed_factor ( <nl> & pdev -> dev , clk_name , <nl> __clk_get_name ( clk_wzrd -> clks_internal [ wzrd_clk_mul ]),
static int palmas_gpio_probe ( struct platform_device * pdev ) <nl> const struct palmas_device_data * dev_data ; <nl>  <nl> match = of_match_device ( of_palmas_gpio_match , & pdev -> dev ); <nl> + if (! match ) <nl> + return - ENODEV ; <nl> dev_data = match -> data ; <nl> if (! dev_data ) <nl> dev_data = & palmas_dev_data ;
static int pcmuio_attach ( struct comedi_device * dev , struct comedi_devconfig * it ) <nl>  <nl> /* save the ioport address for each ' port ' of 8 channels in the <nl> subdevice */ <nl> - for ( byte_no = 0 ; byte_no < PORTS_PER_SUBDEV ; ++ byte_no , ++ port ) { <nl> + for ( byte_no = 0 ; byte_no < PORTS_PER_SUBDEV ; <nl> + ++ byte_no , ++ port ) { <nl> if ( port >= PORTS_PER_ASIC ) { <nl> port = 0 ; <nl> ++ asic ;
int ext4_group_add_blocks ( handle_t * handle , struct super_block * sb , <nl>  <nl> ext4_debug (" Adding block ( s ) % llu -% llu \ n ", block , block + count - 1 ); <nl>  <nl> + if ( count == 0 ) <nl> + return 0 ; <nl> + <nl> ext4_get_group_no_and_offset ( sb , block , & block_group , & bit ); <nl> /* <nl> * Check to see if we are freeing blocks across a group
void __devinit bttv_init_card2 ( struct bttv * btv ) <nl> } <nl> btv -> pll . pll_current = - 1 ; <nl>  <nl> - bttv_reset_audio ( btv ); <nl> - <nl> /* tuner configuration ( from card list / autodetect / insmod option ) */ <nl> if ( UNSET != bttv_tvcards [ btv -> c . type ]. tuner_type ) <nl> if ( UNSET == btv -> tuner_type )
int of_dma_controller_register ( struct device_node * np , <nl> if (! nbcells ) { <nl> pr_err ("% s : # dma - cells property is missing or invalid \ n ", <nl> __func__ ); <nl> + kfree ( ofdma ); <nl> return - EINVAL ; <nl> } <nl> 
static void clear_subscriber_list ( struct snd_seq_client * client , <nl> list_del (& subs -> dest_list ); <nl> else <nl> list_del (& subs -> src_list ); <nl> + up_write (& agrp -> list_mutex ); <nl> unsubscribe_port ( c , aport , agrp , & subs -> info , 1 ); <nl> kfree ( subs ); <nl> - up_write (& agrp -> list_mutex ); <nl> snd_seq_port_unlock ( aport ); <nl> snd_seq_client_unlock ( c ); <nl> }
ext3_set_acl ( handle_t * handle , struct inode * inode , int type , <nl> return error ; <nl> else { <nl> inode -> i_mode = mode ; <nl> + inode -> i_ctime = CURRENT_TIME_SEC ; <nl> ext3_mark_inode_dirty ( handle , inode ); <nl> if ( error == 0 ) <nl> acl = NULL ;
static void _ceph_msgr_exit ( void ) <nl> ceph_msgr_slab_exit (); <nl>  <nl> BUG_ON ( zero_page == NULL ); <nl> - kunmap ( zero_page ); <nl> page_cache_release ( zero_page ); <nl> zero_page = NULL ; <nl> }
ext4_move_extents ( struct file * o_filp , struct file * d_filp , <nl> orig_inode -> i_ino , donor_inode -> i_ino ); <nl> return - EINVAL ; <nl> } <nl> - <nl> + /* TODO : This is non obvious task to swap blocks for inodes with full <nl> + jornaling enabled */ <nl> + if ( ext4_should_journal_data ( orig_inode ) || <nl> + ext4_should_journal_data ( donor_inode )) { <nl> + return - EINVAL ; <nl> + } <nl> /* Protect orig and donor inodes against a truncate */ <nl> mext_inode_double_lock ( orig_inode , donor_inode ); <nl> 
static unsigned long __meminit compute_pernodesize ( int node ) <nl> pernodesize += node * L1_CACHE_BYTES ; <nl> pernodesize += L1_CACHE_ALIGN ( sizeof ( pg_data_t )); <nl> pernodesize += L1_CACHE_ALIGN ( sizeof ( struct ia64_node_data )); <nl> + pernodesize += L1_CACHE_ALIGN ( sizeof ( pg_data_t )); <nl> pernodesize = PAGE_ALIGN ( pernodesize ); <nl> return pernodesize ; <nl> }
static ssize_t cxlflash_show_port_status ( struct device * dev , <nl> u64 * fc_regs ; <nl>  <nl> rc = kstrtouint (( attr -> attr . name + 4 ), 10 , & port ); <nl> - if ( rc || ( port > NUM_FC_PORTS )) <nl> + if ( rc || ( port >= NUM_FC_PORTS )) <nl> return 0 ; <nl>  <nl> fc_regs = & afu -> afu_map -> global . fc_regs [ port ][ 0 ];
static int __devinit corgipm_init ( void ) <nl> { <nl> int ret ; <nl>  <nl> + if (! machine_is_corgi () && ! machine_is_shepherd () <nl> + && ! machine_is_husky ()) <nl> + return - ENODEV ; <nl> + <nl> corgipm_device = platform_device_alloc (" sharpsl - pm ", - 1 ); <nl> if (! corgipm_device ) <nl> return - ENOMEM ;
struct pcmcia_device * pcmcia_device_add ( struct pcmcia_socket * s , unsigned int f <nl> p_dev -> socket = s ; <nl> p_dev -> device_no = ( s -> device_count ++); <nl> p_dev -> func = function ; <nl> - if ( s -> functions < function ) <nl> - s -> functions = function ; <nl> + if ( s -> functions <= function ) <nl> + s -> functions = function + 1 ; <nl>  <nl> p_dev -> dev . bus = & pcmcia_bus_type ; <nl> p_dev -> dev . parent = s -> dev . dev ;
static int __ath10k_pci_hif_power_up ( struct ath10k * ar , bool cold_reset ) <nl> irq_mode = " legacy "; <nl>  <nl> if (! test_bit ( ATH10K_FLAG_FIRST_BOOT_DONE , & ar -> dev_flags )) <nl> - ath10k_info (" pci irq % s \ n ", irq_mode ); <nl> + ath10k_info (" pci irq % s irq_mode % d reset_mode % d \ n ", <nl> + irq_mode , ath10k_pci_irq_mode , <nl> + ath10k_pci_reset_mode ); <nl>  <nl> return 0 ; <nl> 
static int imx6ul_tsc_probe ( struct platform_device * pdev ) <nl> } <nl>  <nl> adc_irq = platform_get_irq ( pdev , 1 ); <nl> - if ( adc_irq <= 0 ) { <nl> + if ( adc_irq < 0 ) { <nl> dev_err (& pdev -> dev , " no adc irq resource ?\ n "); <nl> return adc_irq ; <nl> }
static ssize_t ath6kl_fwlog_block_read ( struct file * file , <nl>  <nl> ret = wait_for_completion_interruptible ( <nl> & ar -> debug . fwlog_completion ); <nl> - if ( ret == - ERESTARTSYS ) <nl> + if ( ret == - ERESTARTSYS ) { <nl> + vfree ( buf ); <nl> return ret ; <nl> + } <nl>  <nl> spin_lock (& ar -> debug . fwlog_queue . lock ); <nl> }
static int do_pages_stat ( struct mm_struct * mm , unsigned long nr_pages , <nl> int err ; <nl>  <nl> for ( i = 0 ; i < nr_pages ; i += chunk_nr ) { <nl> - if ( chunk_nr + i > nr_pages ) <nl> + if ( chunk_nr > nr_pages - i ) <nl> chunk_nr = nr_pages - i ; <nl>  <nl> err = copy_from_user ( chunk_pages , & pages [ i ],
static void brcmf_fws_dequeue_worker ( struct work_struct * worker ) <nl> fws = container_of ( worker , struct brcmf_fws_info , fws_dequeue_work ); <nl>  <nl> brcmf_fws_lock ( fws -> drvr , flags ); <nl> - for ( fifo = NL80211_NUM_ACS ; fifo >= 0 && ! fws -> bus_flow_blocked ; <nl> + for ( fifo = BRCMF_FWS_FIFO_BCMC ; fifo >= 0 && ! fws -> bus_flow_blocked ; <nl> fifo --) { <nl> while (( fws -> fifo_credit [ fifo ]) || ((! fws -> bcmc_credit_check ) && <nl> ( fifo == BRCMF_FWS_FIFO_BCMC ))) {
static int fuse_rename ( struct inode * olddir , struct dentry * oldent , <nl> fuse_invalidate_attr ( newdir ); <nl>  <nl> /* newent will end up negative */ <nl> - if ( newent -> d_inode ) <nl> + if ( newent -> d_inode ) { <nl> + fuse_invalidate_attr ( newent -> d_inode ); <nl> fuse_invalidate_entry_cache ( newent ); <nl> + } <nl> } else if ( err == - EINTR ) { <nl> /* If request was interrupted , DEITY only knows if the <nl> rename actually took place . If the invalidation
static int sirfsoc_gpio_probe ( struct device_node * np ) <nl> if ( err ) { <nl> dev_err (& pdev -> dev , <nl> " could not connect irqchip to gpiochip \ n "); <nl> - goto out ; <nl> + goto out_banks ; <nl> } <nl>  <nl> for ( i = 0 ; i < SIRFSOC_GPIO_NO_OF_BANKS ; i ++) {
skip_msix : <nl> } else <nl> ql_log ( ql_log_warn , vha , 0x0039 , <nl> " MSI - X ; Falling back - to INTa mode -- % d .\ n ", ret ); <nl> + <nl> + /* Skip INTx on ISP82xx . */ <nl> + if (! ha -> flags . msi_enabled && IS_QLA82XX ( ha )) <nl> + return QLA_FUNCTION_FAILED ; <nl> + <nl> skip_msi : <nl>  <nl> ret = request_irq ( ha -> pdev -> irq , ha -> isp_ops -> intr_handler ,
static __cpuinit int mce_device_create ( unsigned int cpu ) <nl> if (! mce_available (& boot_cpu_data )) <nl> return - EIO ; <nl>  <nl> - memset (& dev -> kobj , 0 , sizeof ( struct kobject )); <nl> + memset ( dev , 0 , sizeof ( struct device )); <nl> dev -> id = cpu ; <nl> dev -> bus = & mce_subsys ; <nl> 
void __init spear13xx_l2x0_init ( void ) <nl> * write alloc and ' Full line of zero ' options <nl> * <nl> */ <nl> + if (! IS_ENABLED ( CONFIG_CACHE_L2X0 )) <nl> + return ; <nl>  <nl> writel_relaxed ( 0x06 , VA_L2CC_BASE + L2X0_PREFETCH_CTRL ); <nl> 
 <nl> # define DRV_MODULE_NAME " tg3 " <nl> # define PFX DRV_MODULE_NAME ": " <nl> -# define DRV_MODULE_VERSION " 3 . 81 " <nl> -# define DRV_MODULE_RELDATE " September 5 , 2007 " <nl> +# define DRV_MODULE_VERSION " 3 . 82 " <nl> +# define DRV_MODULE_RELDATE " October 5 , 2007 " <nl>  <nl> # define TG3_DEF_MAC_MODE 0 <nl> # define TG3_DEF_RX_MODE 0
static int tiadc_buffer_preenable ( struct iio_dev * indio_dev ) <nl> for ( i = 0 ; i < fifo1count ; i ++) <nl> read = tiadc_readl ( adc_dev , REG_FIFO1 ); <nl>  <nl> - return iio_sw_buffer_preenable ( indio_dev ); <nl> + return 0 ; <nl> } <nl>  <nl> static int tiadc_buffer_postenable ( struct iio_dev * indio_dev )
static int __devinit tg3_get_invariants ( struct tg3 * tp ) <nl> if ( err ) <nl> return err ; <nl>  <nl> + if ( GET_ASIC_REV ( tp -> pci_chip_rev_id ) == ASIC_REV_5717 && <nl> + ( tp -> pci_chip_rev_id != CHIPREV_ID_5717_A0 || <nl> + ( tp -> tg3_flags2 & TG3_FLG2_MII_SERDES ))) <nl> + return - ENOTSUPP ; <nl> + <nl> /* Initialize data / descriptor byte / word swapping . */ <nl> val = tr32 ( GRC_MODE ); <nl> val &= GRC_MODE_HOST_STACKUP ;
ecryptfs_setxattr ( struct dentry * dentry , const char * name , const void * value , <nl> } <nl>  <nl> rc = vfs_setxattr ( lower_dentry , name , value , size , flags ); <nl> - if (! rc ) <nl> + if (! rc && dentry -> d_inode ) <nl> fsstack_copy_attr_all ( dentry -> d_inode , lower_dentry -> d_inode ); <nl> out : <nl> return rc ;
done : <nl> "", ( margins ) ? " with margins " : "", ( interlace ) ? <nl> " interlaced " : ""); <nl>  <nl> + memset (& cvt_mode , 0 , sizeof ( cvt_mode )); <nl> cvt_mode . xres = xres ; <nl> cvt_mode . yres = yres ; <nl> cvt_mode . refresh = ( refresh ) ? refresh : 60 ;
static int GLOB_SBD_init ( void ) <nl> int i ; <nl>  <nl> /* Set debug output level ( 0 ~ 3 ) here . 3 is most verbose */ <nl> - nand_debug_level = 0 ; <nl> - <nl> printk ( KERN_ALERT " Spectra : % s \ n ", GLOB_version ); <nl>  <nl> mutex_init (& spectra_lock );
static void svm_get_segment ( struct kvm_vcpu * vcpu , <nl> if ( seg == VCPU_SREG_CS ) <nl> var -> g = s -> limit > 0xfffff ; <nl>  <nl> + /* <nl> + * Work around a bug where the busy flag in the tr selector <nl> + * isn ' t exposed <nl> + */ <nl> + if ( seg == VCPU_SREG_TR ) <nl> + var -> type |= 0x2 ; <nl> + <nl> var -> unusable = ! var -> present ; <nl> } <nl> 
static int iio_channel_read ( struct iio_channel * chan , int * val , int * val2 , <nl> if ( val2 == NULL ) <nl> val2 = & unused ; <nl>  <nl> + if (! iio_channel_has_info ( chan -> channel , info )) <nl> + return - EINVAL ; <nl> + <nl> if ( chan -> indio_dev -> info -> read_raw_multi ) { <nl> ret = chan -> indio_dev -> info -> read_raw_multi ( chan -> indio_dev , <nl> chan -> channel , INDIO_MAX_RAW_ELEMENTS ,
static int ath9k_sta_state ( struct ieee80211_hw * hw , <nl> } <nl>  <nl> if ( ath9k_is_chanctx_enabled ()) { <nl> - if ( old_state == IEEE80211_STA_ASSOC && <nl> - new_state == IEEE80211_STA_AUTHORIZED ) <nl> - ath_chanctx_event ( sc , vif , <nl> - ATH_CHANCTX_EVENT_AUTHORIZED ); <nl> + if ( vif -> type == NL80211_IFTYPE_STATION ) { <nl> + if ( old_state == IEEE80211_STA_ASSOC && <nl> + new_state == IEEE80211_STA_AUTHORIZED ) <nl> + ath_chanctx_event ( sc , vif , <nl> + ATH_CHANCTX_EVENT_AUTHORIZED ); <nl> + } <nl> } <nl>  <nl> return ret ;
int dasd_eer_enable ( struct dasd_device * device ) <nl> cqr -> device = device ; <nl> cqr -> retries = 255 ; <nl> cqr -> expires = 10 * HZ ; <nl> + clear_bit ( DASD_CQR_FLAGS_USE_ERP , & cqr -> flags ); <nl>  <nl> cqr -> cpaddr -> cmd_code = DASD_ECKD_CCW_SNSS ; <nl> cqr -> cpaddr -> count = SNSS_DATA_SIZE ;
static int mv643xx_eth_stop ( struct net_device * dev ) <nl> struct mv643xx_eth_private * mp = netdev_priv ( dev ); <nl> int i ; <nl>  <nl> + wrlp ( mp , INT_MASK_EXT , 0x00000000 ); <nl> wrlp ( mp , INT_MASK , 0x00000000 ); <nl> rdlp ( mp , INT_MASK ); <nl> 
__alloc_bootmem_core ( struct bootmem_data * bdata , unsigned long size , <nl> if ( limit && bdata -> node_boot_start >= limit ) <nl> return NULL ; <nl>  <nl> + /* on nodes without memory - bootmem_map is NULL */ <nl> + if (! bdata -> node_bootmem_map ) <nl> + return NULL ; <nl> + <nl> end_pfn = bdata -> node_low_pfn ; <nl> limit = PFN_DOWN ( limit ); <nl> if ( limit && end_pfn > limit )
static int _search_rsb ( struct dlm_ls * ls , char * name , int len , int b , <nl> kref_get (& r -> res_ref ); <nl> goto out ; <nl> } <nl> + if ( error == - ENOTBLK ) <nl> + goto out ; <nl> + <nl> error = dlm_search_rsb_tree (& ls -> ls_rsbtbl [ b ]. toss , name , len , flags , & r ); <nl> if ( error ) <nl> goto out ;
static int ncp_rename ( struct inode * old_dir , struct dentry * old_dentry , <nl> case 0x00 : <nl> ncp_dbg ( 1 , " renamed % pd -> % pd \ n ", <nl> old_dentry , new_dentry ); <nl> + ncp_d_prune ( old_dentry ); <nl> + ncp_d_prune ( new_dentry ); <nl> break ; <nl> case 0x9E : <nl> error = - ENAMETOOLONG ;
* differently than other MIPS interrupts . <nl> */ <nl>  <nl> - static void gt64120_irq ( int irq , void * dev_id ) <nl> + static irqreturn_t gt64120_irq ( int irq , void * dev_id ) <nl> { <nl> unsigned int irq_src , int_high_src , irq_src_mask , int_high_src_mask ; <nl> int handled = 0 ; <nl> static void gt64120_irq ( int irq , void * dev_id ) <nl>  <nl> GT_WRITE ( GT_INTRCAUSE_OFS , 0 ); <nl> GT_WRITE ( GT_HINTRCAUSE_OFS , 0 ); <nl> + <nl> + return IRQ_HANDLED ; <nl> } <nl>  <nl> /*
static void __init tegra210_pll_init ( void __iomem * clk_base , <nl>  <nl> /* PLLU_VCO */ <nl> val = readl ( clk_base + pll_u_vco_params . base_reg ); <nl> - val &= ~ BIT ( 24 ); /* disable PLLU_OVERRIDE */ <nl> + val &= ~ PLLU_BASE_OVERRIDE ; /* disable PLLU_OVERRIDE */ <nl> writel ( val , clk_base + pll_u_vco_params . base_reg ); <nl>  <nl> clk = tegra_clk_register_pllre (" pll_u_vco ", " pll_ref ", clk_base , pmc ,
static int hda_reg_write ( void * context , unsigned int reg , unsigned int val ) <nl> unsigned int verb ; <nl> int i , bytes , err ; <nl>  <nl> + if ( codec -> caps_overwriting ) <nl> + return 0 ; <nl> + <nl> reg &= ~ 0x00080000U ; /* drop GET bit */ <nl> reg |= ( codec -> addr << 28 ); <nl> verb = get_verb ( reg );
static int hostap_enable_hostapd ( PSDevice pDevice , int rtnl_locked ) <nl> if ( ret ) { <nl> DBG_PRT ( MSG_LEVEL_DEBUG , KERN_INFO "% s : register_netdevice ( AP ) failed !\ n ", <nl> dev -> name ); <nl> + free_netdev ( pDevice -> apdev ); <nl> + pDevice -> apdev = NULL ; <nl> return - 1 ; <nl> } <nl> 
 <nl> # define FIRST_VM86_IRQ 3 <nl> # define LAST_VM86_IRQ 15 <nl> -# define invalid_vm86_irq ( irq ) (( irq ) < 3 || ( irq ) > 15 ) <nl> + <nl> +# ifndef __ASSEMBLY__ <nl> + static inline int invalid_vm86_irq ( int irq ) <nl> +{ <nl> + return irq < 3 || irq > 15 ; <nl> +} <nl> +# endif <nl>  <nl> /* <nl> * Size the maximum number of interrupts .
static int __do_index ( struct sw842_param * p , u8 size , u8 bits , u64 fsize ) <nl> /* this is where the current fifo is */ <nl> u64 section = round_down ( total , fsize ); <nl> /* the current pos in the fifo */ <nl> - u64 pos = total % fsize ; <nl> + u64 pos = total - section ; <nl>  <nl> /* if the offset is past / at the pos , we need to <nl> * go back to the last fifo section
static int stmmac_set_coalesce ( struct net_device * dev , <nl> ( ec -> tx_max_coalesced_frames == 0 )) <nl> return - EINVAL ; <nl>  <nl> - if (( ec -> tx_coalesce_usecs > STMMAC_COAL_TX_TIMER ) || <nl> + if (( ec -> tx_coalesce_usecs > STMMAC_MAX_COAL_TX_TICK ) || <nl> ( ec -> tx_max_coalesced_frames > STMMAC_TX_MAX_FRAMES )) <nl> return - EINVAL ; <nl> 
static int get_skb_hdr ( struct sk_buff * skb , void ** iphdr , <nl> * tcph = tcp_hdr ( skb ); <nl>  <nl> /* check if ip header and tcp header are complete */ <nl> - if ( iph -> tot_len < ip_len + tcp_hdrlen ( skb )) <nl> + if ( ntohs ( iph -> tot_len ) < ip_len + tcp_hdrlen ( skb )) <nl> return - 1 ; <nl>  <nl> * hdr_flags = LRO_IPV4 | LRO_TCP ;
free_work : <nl> out_hang : <nl> intel_crtc_wait_for_pending_flips ( crtc ); <nl> ret = intel_pipe_set_base ( crtc , crtc -> x , crtc -> y , fb ); <nl> - if ( ret == 0 && event ) <nl> + if ( ret == 0 && event ) { <nl> + spin_lock_irqsave (& dev -> event_lock , flags ); <nl> drm_send_vblank_event ( dev , pipe , event ); <nl> + spin_unlock_irqrestore (& dev -> event_lock , flags ); <nl> + } <nl> } <nl> return ret ; <nl> }
static int __devinit sdhci_probe_slot ( struct pci_dev * pdev , int slot ) <nl>  <nl> version = readw ( host -> ioaddr + SDHCI_HOST_VERSION ); <nl> version = ( version & SDHCI_SPEC_VER_MASK ) >> SDHCI_SPEC_VER_SHIFT ; <nl> - if ( version != 0 ) { <nl> + if ( version > 1 ) { <nl> printk ( KERN_ERR "% s : Unknown controller version (% d ). " <nl> " You may experience problems .\ n ", host -> slot_descr , <nl> version );
dispatch_ioctl ( struct client * client , unsigned int cmd , void __user * arg ) <nl> return - EFAULT ; <nl> } <nl>  <nl> - return 0 ; <nl> + return retval ; <nl> } <nl>  <nl> static long
static int r820t_signal ( struct dvb_frontend * fe , u16 * strength ) <nl>  <nl> /* A higher gain at LNA means a lower signal strength */ <nl> * strength = ( 45 - rc ) << 4 | 0xff ; <nl> + if (* strength == 0xff ) <nl> + * strength = 0 ; <nl> } else { <nl> * strength = 0 ; <nl> }
static int uio_pdrv_remove ( struct platform_device * pdev ) <nl>  <nl> uio_unregister_device ( pdata -> uioinfo ); <nl>  <nl> + kfree ( pdata ); <nl> + <nl> return 0 ; <nl> } <nl> 
struct i810fb_par { <nl> struct i810fb_i2c_chan chan [ 3 ]; <nl> struct mutex open_lock ; <nl> unsigned int use_count ; <nl> - u32 pseudo_palette [ 17 ]; <nl> + u32 pseudo_palette [ 16 ]; <nl> unsigned long mmio_start_phys ; <nl> u8 __iomem * mmio_start_virtual ; <nl> u8 * edid ;
void dump_trace ( struct task_struct * task , struct pt_regs * regs , <nl> if ( UNW_SP (& info ) >= PAGE_OFFSET ) { <nl> ops -> warning ( data , " Leftover inexact backtrace :\ n "); <nl> stack = ( void *) UNW_SP (& info ); <nl> + if (! stack ) <nl> + return ; <nl> } else <nl> ops -> warning ( data , " Full inexact backtrace again :\ n "); <nl> } else if ( call_trace >= 1 )
static int __dma_supported ( struct device * dev , u64 mask , bool warn ) <nl> */ <nl> if ( sizeof ( mask ) != sizeof ( dma_addr_t ) && <nl> mask > ( dma_addr_t )~ 0 && <nl> - dma_to_pfn ( dev , ~ 0 ) < max_pfn ) { <nl> + dma_to_pfn ( dev , ~ 0 ) < max_pfn - 1 ) { <nl> if ( warn ) { <nl> dev_warn ( dev , " Coherent DMA mask %# llx is larger than dma_addr_t allows \ n ", <nl> mask );
static int dispatch_procfs_write ( struct file * file , <nl>  <nl> if (! ibm || ! ibm -> write ) <nl> return - EINVAL ; <nl> + if ( count > PAGE_SIZE - 2 ) <nl> + return - EINVAL ; <nl>  <nl> kernbuf = kmalloc ( count + 2 , GFP_KERNEL ); <nl> if (! kernbuf )
intel_dp_max_link_bw ( struct intel_dp * intel_dp ) <nl> case DP_LINK_BW_1_62 : <nl> case DP_LINK_BW_2_7 : <nl> break ; <nl> + case DP_LINK_BW_5_4 : /* 1 . 2 capable displays may advertise higher bw */ <nl> + max_link_bw = DP_LINK_BW_2_7 ; <nl> + break ; <nl> default : <nl> + WARN ( 1 , " invalid max DP link bw val % x , using 1 . 62Gbps \ n ", <nl> + max_link_bw ); <nl> max_link_bw = DP_LINK_BW_1_62 ; <nl> break ; <nl> }
 <nl> # include < linux / seq_file . h > <nl> # include < linux / list . h > <nl> +# include < linux / vmalloc . h > <nl> # include " debug . h " <nl> # include " ath5k . h " <nl> # include " reg . h "
static int twlreg_disable ( struct regulator_dev * rdev ) <nl> return grp ; <nl>  <nl> if ( twl_class_is_4030 ()) <nl> - grp &= ~ P1_GRP_4030 ; <nl> + grp &= ~( P1_GRP_4030 | P2_GRP_4030 | P3_GRP_4030 ); <nl> else <nl> - grp &= ~ P1_GRP_6030 ; <nl> + grp &= ~( P1_GRP_6030 | P2_GRP_6030 | P3_GRP_6030 ); <nl>  <nl> return twlreg_write ( info , TWL_MODULE_PM_RECEIVER , VREG_GRP , grp ); <nl> }
static int wanxl_pci_init_one ( struct pci_dev * pdev , <nl> if ( pci_set_consistent_dma_mask ( pdev , DMA_BIT_MASK ( 28 )) || <nl> pci_set_dma_mask ( pdev , DMA_BIT_MASK ( 28 ))) { <nl> pr_err (" No usable DMA configuration \ n "); <nl> + pci_disable_device ( pdev ); <nl> return - EIO ; <nl> } <nl> 
void igb_power_up_link ( struct igb_adapter * adapter ) <nl> igb_power_up_phy_copper (& adapter -> hw ); <nl> else <nl> igb_power_up_serdes_link_82575 (& adapter -> hw ); <nl> + igb_reset_phy (& adapter -> hw ); <nl> } <nl>  <nl> /**
int __scm_send ( struct socket * sock , struct msghdr * msg , struct scm_cookie * p ) <nl> goto error ; <nl>  <nl> cred -> uid = cred -> euid = p -> creds . uid ; <nl> - cred -> gid = cred -> egid = p -> creds . uid ; <nl> + cred -> gid = cred -> egid = p -> creds . gid ; <nl> put_cred ( p -> cred ); <nl> p -> cred = cred ; <nl> }
nouveau_abi16_ioctl_channel_alloc ( ABI16_IOCTL_ARGS ) <nl>  <nl> if ( unlikely (! abi16 )) <nl> return - ENOMEM ; <nl> + <nl> + if (! drm -> channel ) <nl> + return nouveau_abi16_put ( abi16 , - ENODEV ); <nl> + <nl> client = nv_client ( abi16 -> client ); <nl>  <nl> if ( init -> fb_ctxdma_handle == ~ 0 || init -> tt_ctxdma_handle == ~ 0 )
EXPORT_SYMBOL_GPL ( usbnet_resume ); <nl>  <nl> static int __init usbnet_init ( void ) <nl> { <nl> - /* compiler should optimize this out */ <nl> - BUILD_BUG_ON ( sizeof ((( struct sk_buff *) 0 )-> cb ) <nl> - < sizeof ( struct skb_data )); <nl> + /* Compiler should optimize this out . */ <nl> + BUILD_BUG_ON ( <nl> + FIELD_SIZEOF ( struct sk_buff , cb ) < sizeof ( struct skb_data )); <nl>  <nl> random_ether_addr ( node_id ); <nl> return 0 ;
static int process_counter ( struct perf_evsel * counter ) <nl> int i , ret ; <nl>  <nl> aggr -> val = aggr -> ena = aggr -> run = 0 ; <nl> - memset ( ps -> res_stats , 0 , sizeof ( ps -> res_stats )); <nl> + init_stats ( ps -> res_stats ); <nl>  <nl> if ( counter -> per_pkg ) <nl> zero_per_pkg ( counter );
static int afiucv_hs_rcv ( struct sk_buff * skb , struct net_device * dev , <nl> break ; <nl> case 0 : <nl> /* plain data frame */ <nl> + memcpy ( CB_TRGCLS ( skb ), & trans_hdr -> iucv_hdr . class , <nl> + CB_TRGCLS_LEN ); <nl> err = afiucv_hs_callback_rx ( sk , skb ); <nl> break ; <nl> default :
static __inline__ struct page * drm_do_vm_shm_nopage ( struct vm_area_struct * vma , <nl>  <nl> offset = address - vma -> vm_start ; <nl> i = ( unsigned long ) map -> handle + offset ; <nl> - page = vmalloc_to_page (( void *) i ); <nl> + page = ( map -> type == _DRM_CONSISTENT ) ? <nl> + virt_to_page (( void *) i ) : vmalloc_to_page (( void *) i ); <nl> if (! page ) <nl> return NOPAGE_OOM ; <nl> get_page ( page );
xfs_itruncate_start ( <nl> mp = ip -> i_mount ; <nl>  <nl> /* wait for the completion of any pending DIOs */ <nl> - if ( new_size < ip -> i_size ) <nl> + if ( new_size == 0 || new_size < ip -> i_size ) <nl> vn_iowait ( ip ); <nl>  <nl> /*
int usb_sg_init ( struct usb_sg_request * io , struct usb_device * dev , <nl> } <nl>  <nl> /* initialize all the urbs we ' ll use */ <nl> - io -> urbs = kmalloc ( io -> entries * sizeof * io -> urbs , mem_flags ); <nl> + io -> urbs = kmalloc ( io -> entries * sizeof (* io -> urbs ), mem_flags ); <nl> if (! io -> urbs ) <nl> goto nomem ; <nl> 
void xenbus_dev_changed ( const char * node , struct xen_bus_type * bus ) <nl>  <nl> kfree ( root ); <nl> } <nl> + EXPORT_SYMBOL_GPL ( xenbus_dev_changed ); <nl>  <nl> static void frontend_changed ( struct xenbus_watch * watch , <nl> const char ** vec , unsigned int len )
void prune_icache_sb ( struct super_block * sb , int nr_to_scan ) <nl> * inode to the back of the list so we don ' t spin on it . <nl> */ <nl> if (! spin_trylock (& inode -> i_lock )) { <nl> - list_move (& inode -> i_lru , & sb -> s_inode_lru ); <nl> + list_move_tail (& inode -> i_lru , & sb -> s_inode_lru ); <nl> continue ; <nl> } <nl> 
int main ( int ac , char ** av ) <nl> single_menu_mode = 1 ; <nl> } <nl>  <nl> + initscr (); <nl> + <nl> getyx ( stdscr , saved_y , saved_x ); <nl> if ( init_dialog ( NULL )) { <nl> fprintf ( stderr , N_ (" Your display is too small to run Menuconfig !\ n "));
out : <nl> return err ; <nl> no_route : <nl> kfree_skb ( nskb ); <nl> - IP_INC_STATS_BH ( sock_net ( asoc -> base . sk ), IPSTATS_MIB_OUTNOROUTES ); <nl> + IP_INC_STATS ( sock_net ( asoc -> base . sk ), IPSTATS_MIB_OUTNOROUTES ); <nl>  <nl> /* FIXME : Returning the ' err ' will effect all the associations <nl> * associated with a socket , although only one of the paths of the
static int soc_post_component_init ( struct snd_soc_card * card , <nl>  <nl> # ifdef CONFIG_DEBUG_FS <nl> /* add DPCM sysfs entries */ <nl> - if (! dai_link -> dynamic ) <nl> + if (! dailess && ! dai_link -> dynamic ) <nl> goto out ; <nl>  <nl> ret = soc_dpcm_debugfs_add ( rtd );
static int __init thermal_init ( void ) <nl> idr_destroy (& thermal_cdev_idr ); <nl> mutex_destroy (& thermal_idr_lock ); <nl> mutex_destroy (& thermal_list_lock ); <nl> + return result ; <nl> } <nl> result = genetlink_init (); <nl> return result ;
static int annotate_browser__run ( struct annotate_browser * browser , <nl> nd = browser -> curr_hot ; <nl> break ; <nl> case K_UNTAB : <nl> - if ( nd != NULL ) <nl> + if ( nd != NULL ) { <nl> nd = rb_next ( nd ); <nl> if ( nd == NULL ) <nl> nd = rb_first (& browser -> entries ); <nl> - else <nl> + } else <nl> nd = browser -> curr_hot ; <nl> break ; <nl> case K_F1 :
static int f2fs_write_end ( struct file * file , <nl> if ( pos + copied > i_size_read ( inode )) { <nl> i_size_write ( inode , pos + copied ); <nl> mark_inode_dirty ( inode ); <nl> - update_inode_page ( inode ); <nl> } <nl>  <nl> f2fs_put_page ( page , 1 );
static int snd_pcm_drain ( struct snd_pcm_substream * substream ) <nl>  <nl> snd_pcm_stream_lock_irq ( substream ); <nl> /* resume pause */ <nl> - if ( runtime -> status -> state == SNDRV_PCM_STATE_PAUSED ) <nl> + if ( substream -> runtime -> status -> state == SNDRV_PCM_STATE_PAUSED ) <nl> snd_pcm_pause ( substream , 0 ); <nl>  <nl> /* pre - start / stop - all running streams are changed to DRAINING state */
static int drm_helper_probe_single_connector_modes_merge_bits ( struct drm_connect <nl> mode -> status = MODE_UNVERIFIED ; <nl>  <nl> if ( connector -> force ) { <nl> - if ( connector -> force == DRM_FORCE_ON ) <nl> + if ( connector -> force == DRM_FORCE_ON || <nl> + connector -> force == DRM_FORCE_ON_DIGITAL ) <nl> connector -> status = connector_status_connected ; <nl> else <nl> connector -> status = connector_status_disconnected ;
static long btrfs_ioctl_qgroup_assign ( struct file * file , void __user * arg ) <nl> sa -> src , sa -> dst ); <nl> } <nl>  <nl> + /* update qgroup status and info */ <nl> + err = btrfs_run_qgroups ( trans , root -> fs_info ); <nl> + if ( err < 0 ) <nl> + btrfs_error ( root -> fs_info , ret , <nl> + " failed to update qgroup status and info \ n "); <nl> err = btrfs_end_transaction ( trans , root ); <nl> if ( err && ! ret ) <nl> ret = err ;
int ath10k_wmi_event_mgmt_rx ( struct ath10k * ar , struct sk_buff * skb ) <nl> ret = ath10k_wmi_pull_mgmt_rx ( ar , skb , & arg ); <nl> if ( ret ) { <nl> ath10k_warn ( ar , " failed to parse mgmt rx event : % d \ n ", ret ); <nl> + dev_kfree_skb ( skb ); <nl> return ret ; <nl> } <nl> 
static int da9052_rtc_probe ( struct platform_device * pdev ) <nl> return ret ; <nl> } <nl>  <nl> + device_init_wakeup (& pdev -> dev , true ); <nl> + <nl> rtc -> rtc = devm_rtc_device_register (& pdev -> dev , pdev -> name , <nl> & da9052_rtc_ops , THIS_MODULE ); <nl> return PTR_ERR_OR_ZERO ( rtc -> rtc );
static netdev_tx_t r6040_start_xmit ( struct sk_buff * skb , <nl> /* Set TX descriptor & Transmit it */ <nl> lp -> tx_free_desc --; <nl> descptr = lp -> tx_insert_ptr ; <nl> - if ( skb -> len < MISR ) <nl> - descptr -> len = MISR ; <nl> + if ( skb -> len < ETH_ZLEN ) <nl> + descptr -> len = ETH_ZLEN ; <nl> else <nl> descptr -> len = skb -> len ; <nl> 
struct phy_device * get_phy_device ( struct mii_bus * bus , int addr ) <nl> if ( r ) <nl> return ERR_PTR ( r ); <nl>  <nl> - /* If the phy_id is all Fs , there is no device there */ <nl> - if ( 0xffffffff == phy_id ) <nl> + /* If the phy_id is all Fs or all 0s , there is no device there */ <nl> + if (( 0xffff == phy_id ) || ( 0x00 == phy_id )) <nl> return NULL ; <nl>  <nl> dev = phy_device_create ( bus , addr , phy_id );
static int i40evf_request_misc_irq ( struct i40evf_adapter * adapter ) <nl> int err ; <nl>  <nl> snprintf ( adapter -> misc_vector_name , <nl> - sizeof ( adapter -> misc_vector_name ) - 1 , " i40evf : mbx "); <nl> + sizeof ( adapter -> misc_vector_name ) - 1 , " i40evf -% s : mbx ", <nl> + dev_name (& adapter -> pdev -> dev )); <nl> err = request_irq ( adapter -> msix_entries [ 0 ]. vector , <nl> & i40evf_msix_aq , 0 , <nl> adapter -> misc_vector_name , netdev );
static struct of_device_id octeon_cf_match [] = { <nl> }, <nl> {}, <nl> }; <nl> - MODULE_DEVICE_TABLE ( of , octeon_i2c_match ); <nl> + MODULE_DEVICE_TABLE ( of , octeon_cf_match ); <nl>  <nl> static struct platform_driver octeon_cf_driver = { <nl> . probe = octeon_cf_probe ,
acpi_ns_lookup ( union acpi_generic_state * scope_info , <nl> * segments ). <nl> */ <nl> if ( this_node -> type == ACPI_TYPE_LOCAL_ALIAS ) { <nl> + if (! this_node -> object ) { <nl> + return_ACPI_STATUS ( AE_NOT_EXIST ); <nl> + } <nl> + <nl> if ( acpi_ns_opens_scope <nl> ((( struct acpi_namespace_node *) this_node -> <nl> object )-> type )) {
drm_property_create_blob ( struct drm_device * dev , size_t length , <nl> struct drm_property_blob * blob ; <nl> int ret ; <nl>  <nl> - if (! length ) <nl> + if (! length || length > ULONG_MAX - sizeof ( struct drm_property_blob )) <nl> return ERR_PTR (- EINVAL ); <nl>  <nl> blob = kzalloc ( sizeof ( struct drm_property_blob )+ length , GFP_KERNEL );
static inline struct ata_link * ata_port_next_link ( struct ata_link * link ) <nl> return ap -> pmp_link ; <nl> } <nl>  <nl> - if (++ link - ap -> pmp_link < ap -> nr_pmp_links ) <nl> + if (++ link < ap -> nr_pmp_links + ap -> pmp_link ) <nl> return link ; <nl> return NULL ; <nl> }
again : <nl> smp_mb (); <nl> if ( cur_trans -> state >= TRANS_STATE_BLOCKED && <nl> may_wait_transaction ( root , type )) { <nl> + current -> journal_info = h ; <nl> btrfs_commit_transaction ( h , root ); <nl> goto again ; <nl> }
static int sst_platform_pcm_trigger ( struct snd_pcm_substream * substream , <nl> struct snd_soc_pcm_runtime * rtd = substream -> private_data ; <nl>  <nl> dev_dbg ( rtd -> dev , " sst_platform_pcm_trigger called \ n "); <nl> + if ( substream -> pcm -> internal ) <nl> + return 0 ; <nl> stream = substream -> runtime -> private_data ; <nl> str_id = stream -> stream_info . str_id ; <nl> switch ( cmd ) {
int __init dc21285_setup ( int nr , struct pci_sys_data * sys ) <nl>  <nl> sys -> mem_offset = DC21285_PCI_MEM ; <nl>  <nl> - pci_ioremap_io ( 0 , DC21285_PCI_IO ); <nl> - <nl> pci_add_resource_offset (& sys -> resources , & res [ 0 ], sys -> mem_offset ); <nl> pci_add_resource_offset (& sys -> resources , & res [ 1 ], sys -> mem_offset ); <nl> 
static int sprom_extract ( struct ssb_bus * bus , struct ssb_sprom * out , <nl> ssb_printk ( KERN_WARNING PFX " Unsupported SPROM " <nl> " revision % d detected . Will extract " <nl> " v1 \ n ", out -> revision ); <nl> + out -> revision = 1 ; <nl> sprom_extract_r123 ( out , in ); <nl> } <nl> }
static bool g4x_compute_wm0 ( struct drm_device * dev , <nl> int entries , tlb_miss ; <nl>  <nl> crtc = intel_get_crtc_for_plane ( dev , plane ); <nl> - if ( crtc -> fb == NULL || ! crtc -> enabled ) <nl> + if ( crtc -> fb == NULL || ! crtc -> enabled ) { <nl> + * cursor_wm = cursor -> guard_size ; <nl> + * plane_wm = display -> guard_size ; <nl> return false ; <nl> + } <nl>  <nl> htotal = crtc -> mode . htotal ; <nl> hdisplay = crtc -> mode . hdisplay ;
int __kvm_set_memory_region ( struct kvm * kvm , <nl> goto out_free ; <nl> } <nl>  <nl> - kvm_free_physmem_slot (& old , & new ); <nl> + kvm_free_physmem_slot (& old , npages ? & new : NULL ); <nl> + /* Slot deletion case : we have to update the current slot */ <nl> + if (! npages ) <nl> + * memslot = old ; <nl> # ifdef CONFIG_DMAR <nl> /* map the pages in iommu page table */ <nl> r = kvm_iommu_map_pages ( kvm , base_gfn , npages );
restart : <nl> mutex_unlock (& mutex ); <nl> } <nl>  <nl> +/* <nl> + * sync everything . Start out by waking pdflush , because that writes back <nl> + * all queues in parallel . <nl> + */ <nl> SYSCALL_DEFINE0 ( sync ) <nl> { <nl> + wakeup_pdflush ( 0 ); <nl> sync_filesystems ( 0 ); <nl> sync_filesystems ( 1 ); <nl> if ( unlikely ( laptop_mode ))
good_area : <nl> return handle_mm_fault ( mm , vma , addr & PAGE_MASK , flags ); <nl>  <nl> check_stack : <nl> - if ( vma -> vm_flags & VM_GROWSDOWN && ! expand_stack ( vma , addr )) <nl> + /* Don ' t allow expansion below FIRST_USER_ADDRESS */ <nl> + if ( vma -> vm_flags & VM_GROWSDOWN && <nl> + addr >= FIRST_USER_ADDRESS && ! expand_stack ( vma , addr )) <nl> goto good_area ; <nl> out : <nl> return fault ;
ath5k_ani_init ( struct ath5k_hw * ah , enum ath5k_ani_mode mode ) <nl> if ( ah -> ah_version < AR5K_AR5212 ) <nl> return ; <nl>  <nl> + if ( mode < ATH5K_ANI_MODE_OFF || mode > ATH5K_ANI_MODE_AUTO ) { <nl> + ATH5K_ERR ( ah -> ah_sc , " ANI mode % d out of range ", mode ); <nl> + return ; <nl> + } <nl> + <nl> /* clear old state information */ <nl> memset (& ah -> ah_sc -> ani_state , 0 , sizeof ( ah -> ah_sc -> ani_state )); <nl> 
int perf_event__parse_sample ( const union perf_event * event , u64 type , <nl> u32 val32 [ 2 ]; <nl> } u ; <nl>  <nl> - <nl> + memset ( data , 0 , sizeof (* data )); <nl> data -> cpu = data -> pid = data -> tid = - 1 ; <nl> data -> stream_id = data -> id = data -> time = - 1ULL ; <nl> 
rpcrdma_register_frmr_external ( struct rpcrdma_mr_seg * seg , <nl> if ( rc ) { <nl> dprintk (" RPC : % s : failed ib_post_send for register ," <nl> " status % i \ n ", __func__ , rc ); <nl> + ib_update_fast_reg_key ( mr , -- key ); <nl> goto out_err ; <nl> } else { <nl> seg1 -> mr_rkey = mr -> rkey ;
static int __cpuinit comp_pool_callback ( struct notifier_block * nfb , <nl> ehca_gen_dbg (" CPU : % x ( CPU_PREPARE )", cpu ); <nl> if (! create_comp_task ( pool , cpu )) { <nl> ehca_gen_err (" Can ' t create comp_task for cpu : % x ", cpu ); <nl> - return NOTIFY_BAD ; <nl> + return notifier_from_errno (- ENOMEM ); <nl> } <nl> break ; <nl> case CPU_UP_CANCELED :
ieee80211_rx_h_michael_mic_verify ( struct ieee80211_rx_data * rx ) <nl> if ( status -> flag & RX_FLAG_MMIC_ERROR ) <nl> goto mic_fail ; <nl>  <nl> - if (!( status -> flag & RX_FLAG_IV_STRIPPED )) <nl> + if (!( status -> flag & RX_FLAG_IV_STRIPPED ) && rx -> key ) <nl> goto update_iv ; <nl>  <nl> return RX_CONTINUE ;
static void cyberjack_read_int_callback ( struct urb * urb ) <nl>  <nl> old_rdtodo = priv -> rdtodo ; <nl>  <nl> - if ( old_rdtodo + size < old_rdtodo ) { <nl> + if ( old_rdtodo > SHRT_MAX - size ) { <nl> dev_dbg ( dev , " To many bulk_in urbs to do .\ n "); <nl> spin_unlock (& priv -> lock ); <nl> goto resubmit ;
static void scatterwalk_pagedone ( struct scatter_walk * walk , int out , <nl> struct page * page ; <nl>  <nl> page = sg_page ( walk -> sg ) + (( walk -> offset - 1 ) >> PAGE_SHIFT ); <nl> - flush_dcache_page ( page ); <nl> + if (! PageSlab ( page )) <nl> + flush_dcache_page ( page ); <nl> } <nl>  <nl> if ( more ) {
static int blktrans_open ( struct block_device * bdev , fmode_t mode ) <nl>  <nl> mutex_lock (& dev -> lock ); <nl>  <nl> - if ( dev -> open ++) <nl> + if ( dev -> open ) <nl> goto unlock ; <nl>  <nl> kref_get (& dev -> ref ); <nl> static int blktrans_open ( struct block_device * bdev , fmode_t mode ) <nl> goto error_release ; <nl>  <nl> unlock : <nl> + dev -> open ++; <nl> mutex_unlock (& dev -> lock ); <nl> blktrans_dev_put ( dev ); <nl> return ret ;
int radeon_info_ioctl ( struct drm_device * dev , void * data , struct drm_file * filp ) <nl> */ <nl> int radeon_driver_firstopen_kms ( struct drm_device * dev ) <nl> { <nl> + struct radeon_device * rdev = dev -> dev_private ; <nl> + <nl> + if ( rdev -> powered_down ) <nl> + return - EINVAL ; <nl> return 0 ; <nl> } <nl> 
static int i2o_cfg_gethrt ( unsigned long arg ) <nl> put_user ( len , kcmd . reslen ); <nl> if ( len > reslen ) <nl> ret = - ENOBUFS ; <nl> - if ( copy_to_user ( kcmd . resbuf , ( void *) hrt , len )) <nl> + else if ( copy_to_user ( kcmd . resbuf , ( void *) hrt , len )) <nl> ret = - EFAULT ; <nl>  <nl> return ret ;
int fib_nh_match ( struct fib_config * cfg , struct fib_info * fi ) <nl> return 1 ; <nl>  <nl> attrlen = rtnh_attrlen ( rtnh ); <nl> - if ( attrlen < 0 ) { <nl> + if ( attrlen > 0 ) { <nl> struct nlattr * nla , * attrs = rtnh_attrs ( rtnh ); <nl>  <nl> nla = nla_find ( attrs , attrlen , RTA_GATEWAY );
static void ipw_handle_data_packet ( struct ipw_priv * priv , <nl> IPW_DEBUG_RX (" Rx packet of % d bytes .\ n ", rxb -> skb -> len ); <nl>  <nl> /* HW decrypt will not clear the WEP bit , MIC , PN , etc . */ <nl> - if (! priv -> ieee -> host_decrypt ) <nl> + if (! priv -> ieee -> host_decrypt && priv -> ieee -> iw_mode != IW_MODE_MONITOR ) <nl> ipw_rebuild_decrypted_skb ( priv , rxb -> skb ); <nl>  <nl> if (! ieee80211_rx ( priv -> ieee , rxb -> skb , stats ))
static int rxq_process ( struct ieee80211_hw * hw , int index , int limit ) <nl> rmb (); <nl>  <nl> skb = rxq -> rx_skb [ rxq -> rx_head ]; <nl> + if ( skb == NULL ) <nl> + break ; <nl> rxq -> rx_skb [ rxq -> rx_head ] = NULL ; <nl>  <nl> rxq -> rx_head = ( rxq -> rx_head + 1 ) % MWL8K_RX_DESCS ;
static void tg3_adjust_link ( struct net_device * dev ) <nl>  <nl> if ( phydev -> speed == SPEED_100 || phydev -> speed == SPEED_10 ) <nl> mac_mode |= MAC_MODE_PORT_MODE_MII ; <nl> - else <nl> + else if ( phydev -> speed == SPEED_1000 || <nl> + GET_ASIC_REV ( tp -> pci_chip_rev_id ) != ASIC_REV_5785 ) <nl> mac_mode |= MAC_MODE_PORT_MODE_GMII ; <nl> + else <nl> + mac_mode |= MAC_MODE_PORT_MODE_MII ; <nl>  <nl> if ( phydev -> duplex == DUPLEX_HALF ) <nl> mac_mode |= MAC_MODE_HALF_DUPLEX ;
static int init_timers_cpu ( int cpu ) <nl> /* <nl> * The APs use this path later in boot <nl> */ <nl> - base = kmalloc_node ( sizeof (* base ), <nl> - GFP_KERNEL | __GFP_ZERO , <nl> - cpu_to_node ( cpu )); <nl> + base = kzalloc_node ( sizeof (* base ), GFP_KERNEL , <nl> + cpu_to_node ( cpu )); <nl> if (! base ) <nl> return - ENOMEM ; <nl> 
int intel_framebuffer_init ( struct drm_device * dev , <nl> case DRM_FORMAT_UYVY : <nl> case DRM_FORMAT_YVYU : <nl> case DRM_FORMAT_VYUY : <nl> - if ( INTEL_INFO ( dev )-> gen < 6 ) <nl> + if ( INTEL_INFO ( dev )-> gen < 5 ) <nl> return - EINVAL ; <nl> break ; <nl> default :
ia64_global_tlb_purge ( struct mm_struct * mm , unsigned long start , <nl> { <nl> static DEFINE_SPINLOCK ( ptcg_lock ); <nl>  <nl> - if ( mm != current -> active_mm ) { <nl> + if ( mm != current -> active_mm || ! current -> mm ) { <nl> flush_tlb_all (); <nl> return ; <nl> }
int MoxaDriverIoctl ( unsigned int cmd , unsigned long arg , int port ) <nl> case MOXA_FIND_BOARD : <nl> case MOXA_LOAD_C320B : <nl> case MOXA_LOAD_CODE : <nl> + if (! capable ( CAP_SYS_RAWIO )) <nl> + return - EPERM ; <nl> break ; <nl> } <nl> 
static int exynos_drm_crtc_mode_set_base ( struct drm_crtc * crtc , int x , int y , <nl>  <nl> DRM_DEBUG_KMS ("% s \ n ", __FILE__ ); <nl>  <nl> + /* when framebuffer changing is requested , crtc ' s dpms should be on */ <nl> + if ( exynos_crtc -> dpms > DRM_MODE_DPMS_ON ) { <nl> + DRM_ERROR (" failed framebuffer changing request .\ n "); <nl> + return - EPERM ; <nl> + } <nl> + <nl> crtc_w = crtc -> fb -> width - x ; <nl> crtc_h = crtc -> fb -> height - y ; <nl> 
static int dmx_section_feed_release_filter ( struct dmx_section_feed * feed , <nl> return - EINVAL ; <nl> } <nl>  <nl> - if ( feed -> is_filtering ) <nl> + if ( feed -> is_filtering ) { <nl> + /* release dvbdmx -> mutex as far as <nl> + it is acquired by stop_filtering () itself */ <nl> + mutex_unlock (& dvbdmx -> mutex ); <nl> feed -> stop_filtering ( feed ); <nl> + mutex_lock (& dvbdmx -> mutex ); <nl> + } <nl>  <nl> spin_lock_irq (& dvbdmx -> lock ); <nl> f = dvbdmxfeed -> filter ;
void usb_serial_generic_process_read_urb ( struct urb * urb ) <nl> char * ch = ( char *) urb -> transfer_buffer ; <nl> int i ; <nl>  <nl> + if (! urb -> actual_length ) <nl> + return ; <nl> + <nl> tty = tty_port_tty_get (& port -> port ); <nl> if (! tty ) <nl> return ;
void iscsi_boot_destroy_kset ( struct iscsi_boot_kset * boot_kset ) <nl> iscsi_boot_remove_kobj ( boot_kobj ); <nl>  <nl> kset_unregister ( boot_kset -> kset ); <nl> + kfree ( boot_kset ); <nl> } <nl> EXPORT_SYMBOL_GPL ( iscsi_boot_destroy_kset );
static void intel_dp_commit ( struct drm_encoder * encoder ) <nl>  <nl> if ( IS_eDP ( intel_dp ) || IS_PCH_eDP ( intel_dp )) <nl> ironlake_edp_backlight_on ( dev ); <nl> + intel_dp -> dpms_mode = DRM_MODE_DPMS_ON ; <nl> } <nl>  <nl> static void
static int get_dma_channel ( struct device_node * ssi_np , <nl> * dai -> platform name should already point to an allocated buffer . <nl> */ <nl> ret = of_address_to_resource ( dma_channel_np , 0 , & res ); <nl> - if ( ret ) <nl> + if ( ret ) { <nl> + of_node_put ( dma_channel_np ); <nl> return ret ; <nl> + } <nl> snprintf (( char *) dai -> platform_name , DAI_NAME_SIZE , "% llx .% s ", <nl> ( unsigned long long ) res . start , dma_channel_np -> name ); <nl> 
again : <nl> * refill the WL pool synchronous . */ <nl> if ( pool -> used == pool -> size || wl_pool -> used == wl_pool -> size ) { <nl> spin_unlock (& ubi -> wl_lock ); <nl> - ubi_update_fastmap ( ubi ); <nl> + ret = ubi_update_fastmap ( ubi ); <nl> + if ( ret ) { <nl> + ubi_msg ( ubi , " Unable to write a new fastmap : % i ", ret ); <nl> + return - ENOSPC ; <nl> + } <nl> spin_lock (& ubi -> wl_lock ); <nl> } <nl> 
static void parse_elf ( void * output ) <nl> default : /* Ignore other PT_ * */ break ; <nl> } <nl> } <nl> + <nl> + free ( phdrs ); <nl> } <nl>  <nl> asmlinkage void decompress_kernel ( void * rmode , memptr heap ,
static struct dmi_system_id __initdata acpisleep_dmi_table [] = { <nl> DMI_MATCH ( DMI_PRODUCT_NAME , " Macmini1 , 1 "), <nl> }, <nl> }, <nl> + { <nl> + . callback = init_old_suspend_ordering , <nl> + . ident = " Asus Pundit P1 - AH2 ( M2N8L motherboard )", <nl> + . matches = { <nl> + DMI_MATCH ( DMI_BOARD_VENDOR , " ASUSTek Computer INC ."), <nl> + DMI_MATCH ( DMI_BOARD_NAME , " M2N8L "), <nl> + }, <nl> + }, <nl> {}, <nl> }; <nl> # endif /* CONFIG_SUSPEND */
i915_gem_object_bind_to_gtt ( struct drm_gem_object * obj , unsigned alignment ) <nl> bool retry_alloc = false ; <nl> int ret ; <nl>  <nl> - if ( dev_priv -> mm . suspended ) <nl> - return - EBUSY ; <nl> - <nl> if ( obj_priv -> madv != I915_MADV_WILLNEED ) { <nl> DRM_ERROR (" Attempting to bind a purgeable object \ n "); <nl> return - EINVAL ;
static int beiscsi_eh_device_reset ( struct scsi_cmnd * sc ) <nl> if (! abrt_task -> sc || abrt_task -> state == ISCSI_TASK_FREE ) <nl> continue ; <nl>  <nl> - if ( abrt_task -> sc -> device -> lun != abrt_task -> sc -> device -> lun ) <nl> + if ( sc -> device -> lun != abrt_task -> sc -> device -> lun ) <nl> continue ; <nl>  <nl> /* Invalidate WRB Posted for this Task */
static int gfar_spauseparam ( struct net_device * dev , <nl> struct gfar __iomem * regs = priv -> gfargrp [ 0 ]. regs ; <nl> u32 oldadv , newadv ; <nl>  <nl> + if (! phydev ) <nl> + return - ENODEV ; <nl> + <nl> if (!( phydev -> supported & SUPPORTED_Pause ) || <nl> (!( phydev -> supported & SUPPORTED_Asym_Pause ) && <nl> ( epause -> rx_pause != epause -> tx_pause )))
out : <nl> if ( rc != MIGRATEPAGE_SUCCESS && put_new_page ) <nl> put_new_page ( new_hpage , private ); <nl> else <nl> - put_page ( new_hpage ); <nl> + putback_active_hugepage ( new_hpage ); <nl>  <nl> if ( result ) { <nl> if ( rc )
static void mv_otg_work ( struct work_struct * work ) <nl> struct usb_otg * otg ; <nl> int old_state ; <nl>  <nl> - mvotg = container_of (( struct delayed_work *) work , struct mv_otg , work ); <nl> + mvotg = container_of ( to_delayed_work ( work ), struct mv_otg , work ); <nl>  <nl> run : <nl> /* work queue is single thread , or we need spin_lock to protect */
static void sbp2_prep_command_orb_sg ( struct sbp2_command_orb * orb , <nl>  <nl> /* loop through and fill out our SBP - 2 page tables <nl> * ( and split up anything too large ) */ <nl> - for ( i = 0 , sg_count = 0 ; i < count ; i ++, sgpnt ++) { <nl> + for ( i = 0 , sg_count = 0 ; i < count ; i ++, sgpnt = sg_next ( sgpnt )) { <nl> sg_len = sg_dma_len ( sgpnt ); <nl> sg_addr = sg_dma_address ( sgpnt ); <nl> while ( sg_len ) {
radeon_user_framebuffer_create ( struct drm_device * dev , <nl> if ( ret ) { <nl> kfree ( radeon_fb ); <nl> drm_gem_object_unreference_unlocked ( obj ); <nl> - return NULL ; <nl> + return ERR_PTR ( ret ); <nl> } <nl>  <nl> return & radeon_fb -> base ;
__perf_counter_exit_task ( struct task_struct * child , <nl> } <nl> } <nl>  <nl> - kfree ( child_counter ); <nl> + if (! child_counter -> filp || ! atomic_long_read (& child_counter -> filp -> f_count )) <nl> + kfree ( child_counter ); <nl> } <nl>  <nl> /*
int iwl_mvm_sched_scan_start ( struct iwl_mvm * mvm , <nl> return - EBUSY ; <nl> } <nl>  <nl> + /* we don ' t support " match all " in the firmware */ <nl> + if (! req -> n_match_sets ) <nl> + return - EOPNOTSUPP ; <nl> + <nl> ret = iwl_mvm_check_running_scans ( mvm , type ); <nl> if ( ret ) <nl> return ret ;
static int era_is_congested ( struct dm_target_callbacks * cb , int bdi_bits ) <nl>  <nl> static void era_destroy ( struct era * era ) <nl> { <nl> - metadata_close ( era -> md ); <nl> + if ( era -> md ) <nl> + metadata_close ( era -> md ); <nl>  <nl> if ( era -> wq ) <nl> destroy_workqueue ( era -> wq );
befs_fill_super ( struct super_block * sb , void * data , int silent ) <nl> brelse ( bh ); <nl>  <nl> unacquire_priv_sbp : <nl> + kfree ( befs_sb -> mount_opts . iocharset ); <nl> kfree ( sb -> s_fs_info ); <nl>  <nl> unacquire_none :
static void bnx2fc_recv_frame ( struct sk_buff * skb ) <nl> break ; <nl> } <nl> } <nl> + <nl> + if ( fh -> fh_r_ctl == FC_RCTL_BA_ABTS ) { <nl> + /* Drop incoming ABTS */ <nl> + put_cpu (); <nl> + kfree_skb ( skb ); <nl> + return ; <nl> + } <nl> + <nl> if ( le32_to_cpu ( fr_crc ( fp )) != <nl> ~ crc32 (~ 0 , skb -> data , fr_len )) { <nl> if ( stats -> InvalidCRCCount < 5 )
static const struct mfd_cell s5m8767_devs [] = { <nl> static const struct mfd_cell s2mps11_devs [] = { <nl> { <nl> . name = " s2mps11 - pmic ", <nl> + }, { <nl> + . name = " s2mps14 - rtc ", <nl> }, { <nl> . name = " s2mps11 - clk ", <nl> . of_compatible = " samsung , s2mps11 - clk ",
extern int scsi_execute_async ( struct scsi_device * sdev , <nl> void (* done )( void *, char *, int , int ), <nl> gfp_t gfp ); <nl>  <nl> - static inline void scsi_device_reprobe ( struct scsi_device * sdev ) <nl> + static inline int __must_check scsi_device_reprobe ( struct scsi_device * sdev ) <nl> { <nl> - device_reprobe (& sdev -> sdev_gendev ); <nl> + return device_reprobe (& sdev -> sdev_gendev ); <nl> } <nl>  <nl> static inline unsigned int sdev_channel ( struct scsi_device * sdev )
static dma_cookie_t imxdma_tx_submit ( struct dma_async_tx_descriptor * tx ) <nl> unsigned long flags ; <nl>  <nl> spin_lock_irqsave (& imxdma -> lock , flags ); <nl> + list_move_tail ( imxdmac -> ld_free . next , & imxdmac -> ld_queue ); <nl> cookie = dma_cookie_assign ( tx ); <nl> spin_unlock_irqrestore (& imxdma -> lock , flags ); <nl> 
static void handle_swbp ( struct pt_regs * regs ) <nl> if ( unlikely (! test_bit ( UPROBE_COPY_INSN , & uprobe -> flags ))) <nl> goto out ; <nl>  <nl> + /* Tracing handlers use -> utask to communicate with fetch methods */ <nl> + if (! get_utask ()) <nl> + goto out ; <nl> + <nl> handler_chain ( uprobe , regs ); <nl> if ( can_skip_sstep ( uprobe , regs )) <nl> goto out ;
xfs_fs_geometry ( <nl> xfs_fsop_geom_t * geo , <nl> int new_version ) <nl> { <nl> + <nl> + memset ( geo , 0 , sizeof (* geo )); <nl> + <nl> geo -> blocksize = mp -> m_sb . sb_blocksize ; <nl> geo -> rtextsize = mp -> m_sb . sb_rextsize ; <nl> geo -> agblocks = mp -> m_sb . sb_agblocks ;
static int uevent_net_init ( struct net * net ) <nl> if (! ue_sk -> sk ) { <nl> printk ( KERN_ERR <nl> " kobject_uevent : unable to create netlink socket !\ n "); <nl> + kfree ( ue_sk ); <nl> return - ENODEV ; <nl> } <nl> mutex_lock (& uevent_sock_mutex );
i915_gem_object_create_from_data ( struct drm_device * dev , <nl> i915_gem_object_pin_pages ( obj ); <nl> sg = obj -> pages ; <nl> bytes = sg_copy_from_buffer ( sg -> sgl , sg -> nents , ( void *) data , size ); <nl> + obj -> dirty = 1 ; /* Backing store is now out of date */ <nl> i915_gem_object_unpin_pages ( obj ); <nl>  <nl> if ( WARN_ON ( bytes != size )) {
static int __init crossbar_of_init ( struct device_node * node ) <nl> int i , size , max , reserved = 0 , entry ; <nl> const __be32 * irqsr ; <nl>  <nl> - cb = kzalloc ( sizeof ( struct cb_device *), GFP_KERNEL ); <nl> + cb = kzalloc ( sizeof (* cb ), GFP_KERNEL ); <nl>  <nl> if (! cb ) <nl> return - ENOMEM ;
int radeonfb_create ( struct drm_device * dev , <nl> goto out_unref ; <nl> } <nl>  <nl> + rdev -> fbdev_info = info ; <nl> rfbdev = info -> par ; <nl> rfbdev -> helper . funcs = & radeon_fb_helper_funcs ; <nl> rfbdev -> helper . dev = dev ;
void assert_pipe ( struct drm_i915_private * dev_priv , <nl> u32 val ; <nl> bool cur_state ; <nl>  <nl> + /* if we need the pipe A quirk it must be always on */ <nl> + if ( pipe == PIPE_A && dev_priv -> quirks & QUIRK_PIPEA_FORCE ) <nl> + state = true ; <nl> + <nl> reg = PIPECONF ( pipe ); <nl> val = I915_READ ( reg ); <nl> cur_state = !!( val & PIPECONF_ENABLE );
static int hfsplus_fill_super ( struct super_block * sb , void * data , int silent ) <nl> u64 last_fs_block , last_fs_page ; <nl> int err ; <nl>  <nl> - err = - EINVAL ; <nl> + err = - ENOMEM ; <nl> sbi = kzalloc ( sizeof (* sbi ), GFP_KERNEL ); <nl> if (! sbi ) <nl> goto out ;
static int tpm_tis_init ( struct device * dev , struct tpm_info * tpm_info , <nl> iowrite32 ( intmask , <nl> chip -> vendor . iobase + <nl> TPM_INT_ENABLE ( chip -> vendor . locality )); <nl> + <nl> + devm_free_irq ( dev , i , chip ); <nl> } <nl> } <nl> if ( chip -> vendor . irq ) {
static int mga_vram_init ( struct mga_device * mdev ) <nl> aper -> count = 1 ; <nl>  <nl> remove_conflicting_framebuffers ( aper , " mgafb ", true ); <nl> + kfree ( aper ); <nl>  <nl> if (! request_mem_region ( mdev -> mc . vram_base , mdev -> mc . vram_window , <nl> " mgadrmfb_vram ")) {
int i2c_dw_probe ( struct dw_i2c_dev * dev ) <nl>  <nl> snprintf ( adap -> name , sizeof ( adap -> name ), <nl> " Synopsys DesignWare I2C adapter "); <nl> + adap -> retries = 3 ; <nl> adap -> algo = & i2c_dw_algo ; <nl> adap -> dev . parent = dev -> dev ; <nl> i2c_set_adapdata ( adap , dev );
static int add_new_gdb ( handle_t * handle , struct inode * inode , <nl> return err ; <nl>  <nl> exit_inode : <nl> + kfree ( n_group_desc ); <nl> /* ext4_handle_release_buffer ( handle , iloc . bh ); */ <nl> brelse ( iloc . bh ); <nl> exit_dindj :
__acquires ( musb -> lock ) <nl> musb -> g . a_alt_hnp_support = 1 ; <nl> break ; <nl> # endif <nl> + case USB_DEVICE_DEBUG_MODE : <nl> + handled = 0 ; <nl> + break ; <nl> stall : <nl> default : <nl> handled = - EINVAL ;
static unsigned int xuartps_set_baud_rate ( struct uart_port * port , <nl> unsigned int baud ) <nl> { <nl> unsigned int calc_baud ; <nl> - u32 cd , bdiv ; <nl> + u32 cd = 0 , bdiv = 0 ; <nl> u32 mreg ; <nl> int div8 ; <nl> struct xuartps * xuartps = port -> private_data ;
intel_sdvo_tv_init ( struct intel_sdvo * intel_sdvo , int type ) <nl> return true ; <nl>  <nl> err : <nl> - intel_sdvo_destroy_enhance_property ( connector ); <nl> - kfree ( intel_sdvo_connector ); <nl> + intel_sdvo_destroy ( connector ); <nl> return false ; <nl> } <nl>  <nl> intel_sdvo_lvds_init ( struct intel_sdvo * intel_sdvo , int device ) <nl> return true ; <nl>  <nl> err : <nl> - intel_sdvo_destroy_enhance_property ( connector ); <nl> - kfree ( intel_sdvo_connector ); <nl> + intel_sdvo_destroy ( connector ); <nl> return false ; <nl> } <nl> 
static int parse_gfp_flags ( struct perf_evsel * evsel , struct perf_sample * sample , <nl> . size = sample -> raw_size , <nl> }; <nl> struct trace_seq seq ; <nl> - char * str , * pos ; <nl> + char * str , * pos = NULL ; <nl>  <nl> if ( nr_gfps ) { <nl> struct gfp_flag key = {
static struct dma_chan * of_dma_sirfsoc_xlate ( struct of_phandle_args * dma_spec , <nl> struct sirfsoc_dma * sdma = ofdma -> of_dma_data ; <nl> unsigned int request = dma_spec -> args [ 0 ]; <nl>  <nl> - if ( request > SIRFSOC_DMA_CHANNELS ) <nl> + if ( request >= SIRFSOC_DMA_CHANNELS ) <nl> return NULL ; <nl>  <nl> return dma_get_slave_channel (& sdma -> channels [ request ]. chan );
static int rt5640_probe ( struct snd_soc_codec * codec ) <nl> rt5639_specific_dapm_routes , <nl> ARRAY_SIZE ( rt5639_specific_dapm_routes )); <nl> break ; <nl> + default : <nl> + dev_err ( codec -> dev , <nl> + " The driver is for RT5639 RT5640 or RT5642 only \ n "); <nl> + return - ENODEV ; <nl> } <nl>  <nl> return 0 ;
parahotplug_request_create ( struct controlvm_message * msg ) <nl> { <nl> struct parahotplug_request * req ; <nl>  <nl> - req = kmalloc ( sizeof (* req ), GFP_KERNEL | __GFP_NORETRY ); <nl> + req = kmalloc ( sizeof (* req ), GFP_KERNEL | __GFP_NORETRY ); <nl> if (! req ) <nl> return NULL ; <nl> 
void bcm43xx_phy_set_baseband_attenuation ( struct bcm43xx_private * bcm , <nl> return ; <nl> } <nl>  <nl> - if ( phy -> analog > 1 ) { <nl> + if ( phy -> analog == 1 ) { <nl> value = bcm43xx_phy_read ( bcm , 0x0060 ) & ~ 0x003C ; <nl> value |= ( baseband_attenuation << 2 ) & 0x003C ; <nl> } else {
device_release_WPADEV ( pDevice ); <nl> free_netdev ( pDevice -> dev ); <nl> } <nl>  <nl> - kfree ( pDevice ); <nl> DBG_PRT ( MSG_LEVEL_DEBUG , KERN_INFO " device_disconnect3 .. \ n "); <nl> } <nl> 
static int snd_pcm_update_hw_ptr0 ( struct snd_pcm_substream * substream , <nl> * the elapsed time to detect xruns . <nl> */ <nl> jdelta = jiffies - runtime -> hw_ptr_jiffies ; <nl> + if ( jdelta < runtime -> hw_ptr_buffer_jiffies / 2 ) <nl> + goto no_delta_check ; <nl> hdelta = jdelta - delta * HZ / runtime -> rate ; <nl> while ( hdelta > runtime -> hw_ptr_buffer_jiffies / 2 + 1 ) { <nl> delta += runtime -> buffer_size ;
static int cgroup_attach_proc ( struct cgroup * cgrp , struct task_struct * leader ) <nl> if (! group ) <nl> return - ENOMEM ; <nl> /* pre - allocate to guarantee space while iterating in rcu read - side . */ <nl> - retval = flex_array_prealloc ( group , 0 , group_size - 1 , GFP_KERNEL ); <nl> + retval = flex_array_prealloc ( group , 0 , group_size , GFP_KERNEL ); <nl> if ( retval ) <nl> goto out_free_group_list ; <nl> 
static int __devinit cobalt_raq_led_probe ( struct platform_device * pdev ) <nl> if (! res ) <nl> return - EBUSY ; <nl>  <nl> - led_port = ioremap ( res -> start , res -> end - res -> start + 1 ); <nl> + led_port = ioremap ( res -> start , resource_size ( res )); <nl> if (! led_port ) <nl> return - ENOMEM ; <nl> 
static void cleanup_one_si ( struct smi_info * to_clean ) <nl> if (! to_clean ) <nl> return ; <nl>  <nl> + if ( to_clean -> dev ) <nl> + dev_set_drvdata ( to_clean -> dev , NULL ); <nl> + <nl> list_del (& to_clean -> link ); <nl>  <nl> /* Tell the driver that we are shutting down . */
irqreturn_t ath_isr ( int irq , void * dev ) <nl>  <nl> if (!( ah -> caps . hw_caps & ATH9K_HW_CAP_AUTOSLEEP )) <nl> if ( status & ATH9K_INT_TIM_TIMER ) { <nl> + if ( ATH_DBG_WARN_ON_ONCE ( sc -> ps_idle )) <nl> + goto chip_reset ; <nl> /* Clear RxAbort bit so that we can <nl> * receive frames */ <nl> ath9k_setpower ( sc , ATH9K_PM_AWAKE );
static void sc_kref_release ( struct kref * kref ) <nl> sc -> sc_node = NULL ; <nl>  <nl> r2net_debug_del_sc ( sc ); <nl> + <nl> + if ( sc -> sc_page ) <nl> + __free_page ( sc -> sc_page ); <nl> kfree ( sc ); <nl> } <nl> 
int ocfs2_cluster_connect ( const char * stack_name , <nl>  <nl> strlcpy ( new_conn -> cc_name , group , GROUP_NAME_MAX + 1 ); <nl> new_conn -> cc_namelen = grouplen ; <nl> - strlcpy ( new_conn -> cc_cluster_name , cluster_name , CLUSTER_NAME_MAX + 1 ); <nl> + if ( cluster_name_len ) <nl> + strlcpy ( new_conn -> cc_cluster_name , cluster_name , <nl> + CLUSTER_NAME_MAX + 1 ); <nl> new_conn -> cc_cluster_name_len = cluster_name_len ; <nl> new_conn -> cc_recovery_handler = recovery_handler ; <nl> new_conn -> cc_recovery_data = recovery_data ;
nouveau_bo_move_m2mf ( struct ttm_buffer_object * bo , int evict , bool intr , <nl> bool no_wait_gpu , struct ttm_mem_reg * new_mem ) <nl> { <nl> struct nouveau_drm * drm = nouveau_bdev ( bo -> bdev ); <nl> - struct nouveau_channel * chan = chan = drm -> ttm . chan ; <nl> + struct nouveau_channel * chan = drm -> ttm . chan ; <nl> struct nouveau_bo * nvbo = nouveau_bo ( bo ); <nl> struct ttm_mem_reg * old_mem = & bo -> mem ; <nl> int ret ;
static void tgfx_attach ( struct parport * pp ) <nl> n_buttons = tgfx_cfg [ port_idx ]. args + 1 ; <nl> n_devs = tgfx_cfg [ port_idx ]. nargs - 1 ; <nl>  <nl> + memset (& tgfx_parport_cb , 0 , sizeof ( tgfx_parport_cb )); <nl> tgfx_parport_cb . flags = PARPORT_FLAG_EXCL ; <nl>  <nl> pd = parport_register_dev_model ( pp , " turbografx ", & tgfx_parport_cb ,
static bool ath_rx_edma_buf_link ( struct ath_softc * sc , <nl> static void ath_rx_addbuffer_edma ( struct ath_softc * sc , <nl> enum ath9k_rx_qtype qtype , int size ) <nl> { <nl> - struct ath_rx_edma * rx_edma ; <nl> struct ath_common * common = ath9k_hw_common ( sc -> sc_ah ); <nl> u32 nbuf = 0 ; <nl>  <nl> - rx_edma = & sc -> rx . rx_edma [ qtype ]; <nl> if ( list_empty (& sc -> rx . rxbuf )) { <nl> ath_print ( common , ATH_DBG_QUEUE , " No free rx buf available \ n "); <nl> return ;
int madvise_free_huge_pmd ( struct mmu_gather * tlb , struct vm_area_struct * vma , <nl> int ret = 0 ; <nl>  <nl> if (! pmd_trans_huge_lock ( pmd , vma , & ptl )) <nl> - goto out ; <nl> + goto out_unlocked ; <nl>  <nl> orig_pmd = * pmd ; <nl> if ( is_huge_zero_pmd ( orig_pmd )) {
int ath_cmn_process_fft ( struct ath_spec_scan_priv * spec_priv , struct ieee80211_h <nl> } <nl>  <nl> /* Process a normal frame */ <nl> - if ( sample_bytes == sample_len ) { <nl> - memcpy ( sample_buf , sample_start , sample_len ); <nl> - ret = fft_handler ( rs , spec_priv , sample_buf , <nl> + if ( sample_bytes == sample_len ) <nl> + ret = fft_handler ( rs , spec_priv , sample_start , <nl> tsf , freq , chan_type ); <nl> - } <nl>  <nl> /* Short report processed , break out of the <nl> * loop .
static int generic_hdmi_build_controls ( struct hda_codec * codec ) <nl> struct snd_pcm_chmap * chmap ; <nl> struct snd_kcontrol * kctl ; <nl> int i ; <nl> + <nl> + if (! codec -> pcm_info [ pin_idx ]. pcm ) <nl> + break ; <nl> err = snd_pcm_add_chmap_ctls ( codec -> pcm_info [ pin_idx ]. pcm , <nl> SNDRV_PCM_STREAM_PLAYBACK , <nl> NULL , 0 , pin_idx , & chmap );
static const struct of_device_id spinand_dt [] = { <nl> { . compatible = " spinand , mt29f ", }, <nl> {} <nl> }; <nl> + MODULE_DEVICE_TABLE ( of , spinand_dt ); <nl>  <nl> /* <nl> * Device name structure description
static int add_tracepoint_multi ( struct list_head ** list , int * idx , <nl> ret = add_tracepoint ( list , idx , sys_name , evt_ent -> d_name ); <nl> } <nl>  <nl> + closedir ( evt_dir ); <nl> return ret ; <nl> } <nl> 
fail : <nl> kvm_unregister_irq_mask_notifier ( kvm , 0 , & pit -> mask_notifier ); <nl> kvm_unregister_irq_ack_notifier ( kvm , & pit_state -> irq_ack_notifier ); <nl> kvm_free_irq_source_id ( kvm , pit -> irq_source_id ); <nl> - <nl> + destroy_workqueue ( pit -> wq ); <nl> kfree ( pit ); <nl> return NULL ; <nl> }
static int imx1_pinctrl_parse_functions ( struct device_node * np , <nl> /* Initialise function */ <nl> func -> name = np -> name ; <nl> func -> num_groups = of_get_child_count ( np ); <nl> - if ( func -> num_groups <= 0 ) <nl> + if ( func -> num_groups == 0 ) <nl> return - EINVAL ; <nl>  <nl> func -> groups = devm_kzalloc ( info -> dev ,
int shpchprm_set_hpp ( <nl> pci_bus -> number = func -> bus ; <nl> devfn = PCI_DEVFN ( func -> device , func -> function ); <nl>  <nl> - ab = find_acpi_bridge_by_bus ( acpi_bridges_head , ctrl -> seg , ctrl -> bus ); <nl> + ab = find_acpi_bridge_by_bus ( acpi_bridges_head , ctrl -> seg , ctrl -> slot_bus ); <nl>  <nl> if ( ab ) { <nl> if ( ab -> _hpp ) {
static void wait_for_writer ( struct btrfs_trans_handle * trans , <nl> mutex_unlock (& root -> log_mutex ); <nl> if ( atomic_read (& root -> log_writers )) <nl> schedule (); <nl> - mutex_lock (& root -> log_mutex ); <nl> finish_wait (& root -> log_writer_wait , & wait ); <nl> + mutex_lock (& root -> log_mutex ); <nl> } <nl> } <nl> 
void atari_kbd_leds ( unsigned int leds ) <nl>  <nl> static int atari_keyb_done = 0 ; <nl>  <nl> - int __init atari_keyb_init ( void ) <nl> + int atari_keyb_init ( void ) <nl> { <nl> if ( atari_keyb_done ) <nl> return 0 ; <nl> int __init atari_keyb_init ( void ) <nl> atari_keyb_done = 1 ; <nl> return 0 ; <nl> } <nl> + EXPORT_SYMBOL_GPL ( atari_keyb_init ); <nl>  <nl> int atari_kbd_translate ( unsigned char keycode , unsigned char * keycodep , char raw_mode ) <nl> {
static struct iommu_table * vio_build_iommu_table ( struct vio_dev * dev ) <nl> return NULL ; <nl>  <nl> tbl = kmalloc ( sizeof (* tbl ), GFP_KERNEL ); <nl> + if ( tbl == NULL ) <nl> + return NULL ; <nl>  <nl> of_parse_dma_window ( dev -> dev . archdata . of_node , dma_window , <nl> & tbl -> it_index , & offset , & size );
/* to align the pointer to the ( next ) page boundary */ <nl> # define PAGE_ALIGN ( addr ) ((( addr )+ PAGE_SIZE - 1 )& PAGE_MASK ) <nl>  <nl> -# define __PHYSICAL_MASK (((( phys_addr_t ) 1 ) << __PHYSICAL_MASK_SHIFT ) - 1 ) <nl> +# define __PHYSICAL_MASK (( phys_addr_t )( 1ULL << __PHYSICAL_MASK_SHIFT ) - 1 ) <nl> # define __VIRTUAL_MASK (( 1UL << __VIRTUAL_MASK_SHIFT ) - 1 ) <nl>  <nl> # ifndef __ASSEMBLY__
struct sk_buff * ieee80211_beacon_get ( struct ieee80211_hw * hw , <nl> " no rate found \ n ", <nl> wiphy_name ( local -> hw . wiphy )); <nl> } <nl> - dev_kfree_skb ( skb ); <nl> + dev_kfree_skb_any ( skb ); <nl> skb = NULL ; <nl> goto out ; <nl> }
static int perf_exclude_event ( struct perf_event * event , <nl> struct pt_regs * regs ) <nl> { <nl> if ( event -> hw . state & PERF_HES_STOPPED ) <nl> - return 0 ; <nl> + return 1 ; <nl>  <nl> if ( regs ) { <nl> if ( event -> attr . exclude_user && user_mode ( regs ))
static int biovec_create_pools ( struct bio_set * bs , int pool_entries , int scale ) <nl> struct biovec_slab * bp = bvec_slabs + i ; <nl> mempool_t ** bvp = bs -> bvec_pools + i ; <nl>  <nl> - if ( i >= scale ) <nl> + if ( pool_entries > 1 && i >= scale ) <nl> pool_entries >>= 1 ; <nl>  <nl> * bvp = mempool_create_slab_pool ( pool_entries , bp -> slab );
static ssize_t eisa_eeprom_read ( struct file * file , <nl> ssize_t ret ; <nl> int i ; <nl>  <nl> - if (* ppos >= HPEE_MAX_LENGTH ) <nl> + if (* ppos < 0 || * ppos >= HPEE_MAX_LENGTH ) <nl> return 0 ; <nl>  <nl> count = * ppos + count < HPEE_MAX_LENGTH ? count : HPEE_MAX_LENGTH - * ppos ;
void sctp_transport_burst_limited ( struct sctp_transport * t ) <nl> u32 old_cwnd = t -> cwnd ; <nl> u32 max_burst_bytes ; <nl>  <nl> - if ( t -> burst_limited ) <nl> + if ( t -> burst_limited || asoc -> max_burst == 0 ) <nl> return ; <nl>  <nl> max_burst_bytes = t -> flight_size + ( asoc -> max_burst * asoc -> pathmtu );
int do_sys_settimeofday ( struct timespec * tv , struct timezone * tz ) <nl> static int firsttime = 1 ; <nl> int error = 0 ; <nl>  <nl> + if (! timespec_valid ( tv )) <nl> + return - EINVAL ; <nl> + <nl> error = security_settime ( tv , tz ); <nl> if ( error ) <nl> return error ;
do { \ <nl> if ( EXT4_FITS_IN_INODE ( raw_inode , einode , xtime )) \ <nl> ( einode )-> xtime . tv_sec = \ <nl> ( signed ) le32_to_cpu (( raw_inode )-> xtime ); \ <nl> + else \ <nl> + ( einode )-> xtime . tv_sec = 0 ; \ <nl> if ( EXT4_FITS_IN_INODE ( raw_inode , einode , xtime ## _extra )) \ <nl> ext4_decode_extra_time (&( einode )-> xtime , \ <nl> raw_inode -> xtime ## _extra ); \
static int snd_pcm_update_hw_ptr0 ( struct snd_pcm_substream * substream , <nl> new_hw_ptr = hw_base + pos ; <nl> } <nl> __delta : <nl> - delta = ( new_hw_ptr - old_hw_ptr ) % runtime -> boundary ; <nl> + delta = new_hw_ptr - old_hw_ptr ; <nl> + if ( delta < 0 ) <nl> + delta += runtime -> boundary ; <nl> if ( xrun_debug ( substream , in_interrupt ? <nl> XRUN_DEBUG_PERIODUPDATE : XRUN_DEBUG_HWPTRUPDATE )) { <nl> char name [ 16 ];
static void __devexit slic_entry_remove ( struct pci_dev * pcidev ) <nl> } <nl> free_netdev ( dev ); <nl> pci_release_regions ( pcidev ); <nl> + pci_disable_device ( pcidev ); <nl> } <nl>  <nl> static int slic_entry_halt ( struct net_device * dev )
mt7601u_extra_power_over_mac ( struct mt7601u_dev * dev ) <nl> static void <nl> mt7601u_set_power_rate ( struct power_per_rate * rate , s8 delta , u8 value ) <nl> { <nl> + /* Invalid ? Note : vendor driver does not handle this */ <nl> + if ( value == 0xff ) <nl> + return ; <nl> + <nl> rate -> raw = s6_validate ( value ); <nl> rate -> bw20 = s6_to_int ( value ); <nl> /* Note : vendor driver does cap the value to s6 right away */
void print2byte ( int input , struct iio_channel_info * info ) <nl> * Shift before conversion to avoid sign extension <nl> * of left aligned data <nl> */ <nl> - input = input >> info -> shift ; <nl> + input >>= info -> shift ; <nl> if ( info -> is_signed ) { <nl> int16_t val = input ; <nl> 
_xfs_buf_find ( <nl> * have to check that the buffer falls within the filesystem bounds . <nl> */ <nl> eofs = XFS_FSB_TO_BB ( btp -> bt_mount , btp -> bt_mount -> m_sb . sb_dblocks ); <nl> - if ( blkno >= eofs ) { <nl> + if ( blkno < 0 || blkno >= eofs ) { <nl> /* <nl> * XXX ( dgc ): we should really be returning - EFSCORRUPTED here , <nl> * but none of the higher level infrastructure supports
int spu_acquire_runnable ( struct spu_context * ctx ) <nl>  <nl> if ( ctx -> state == SPU_STATE_SAVED ) { <nl> ret = spu_activate ( ctx , 0 ); <nl> + if ( ret ) <nl> + goto out ; <nl> ctx -> state = SPU_STATE_RUNNABLE ; <nl> } <nl> - if ( ret ) <nl> - goto out ; <nl>  <nl> downgrade_write (& ctx -> state_sema ); <nl> /* On success , we return holding the lock */
nvc0_fb_init ( struct drm_device * dev ) <nl> priv = dev_priv -> engine . fb . priv ; <nl>  <nl> nv_wr32 ( dev , 0x100c10 , priv -> r100c10 >> 8 ); <nl> + nv_mask ( dev , 0x17e820 , 0x00100000 , 0x00000000 ); /* NV_PLTCG_INTR_EN */ <nl> return 0 ; <nl> } <nl> 
static struct sk_buff * ieee80211_build_hdr ( struct ieee80211_sub_if_data * sdata , <nl> authorized = test_sta_flag ( sta , WLAN_STA_AUTHORIZED ); <nl> wme_sta = sta -> sta . wme ; <nl> have_station = true ; <nl> + } else if ( sdata -> wdev . use_4addr ) { <nl> + ret = - ENOLINK ; <nl> + goto free ; <nl> } <nl> ap_sdata = container_of ( sdata -> bss , struct ieee80211_sub_if_data , <nl> u . ap );
int cx25821_video_register ( struct cx25821_dev * dev ) <nl>  <nl> spin_lock_init (& dev -> slock ); <nl>  <nl> - for ( i = 0 ; i < MAX_VID_CHANNEL_NUM - 1 ; ++ i ) { <nl> + for ( i = 0 ; i < VID_CHANNEL_NUM ; ++ i ) { <nl> cx25821_init_controls ( dev , i ); <nl>  <nl> cx25821_risc_stopper ( dev -> pci , & dev -> channels [ i ]. vidq . stopper ,
static int dtv_property_legacy_params_sync ( struct dvb_frontend * fe , <nl>  <nl> static bool has_get_frontend ( struct dvb_frontend * fe ) <nl> { <nl> - return fe -> ops . get_frontend ; <nl> + return fe -> ops . get_frontend != NULL ; <nl> } <nl>  <nl> /*
static int aac_send_raw_srb ( struct aac_dev * dev , void __user * arg ) <nl> AAC_OPT_NEW_COMM ) ? <nl> ( dev -> scsi_host_ptr -> max_sectors << 9 ) : <nl> 65536 )) { <nl> + kfree ( usg ); <nl> rcode = - EINVAL ; <nl> goto cleanup ; <nl> }
static int pl2303_tiocmset ( struct tty_struct * tty , <nl> spin_unlock_irqrestore (& priv -> lock , flags ); <nl>  <nl> mutex_lock (& serial -> disc_mutex ); <nl> - if (! serial -> disconnected ) <nl> + if (! serial -> disconnected ) { <nl> ret = pl2303_set_control_lines ( port , control ); <nl> - else <nl> + if ( ret ) <nl> + ret = usb_translate_errors ( ret ); <nl> + } else { <nl> ret = - ENODEV ; <nl> + } <nl> mutex_unlock (& serial -> disc_mutex ); <nl>  <nl> return ret ;
_xfs_buf_ioapply ( <nl> int size ; <nl> int i ; <nl>  <nl> + /* <nl> + * Make sure we capture only current IO errors rather than stale errors <nl> + * left over from previous use of the buffer ( e . g . failed readahead ). <nl> + */ <nl> + bp -> b_error = 0 ; <nl> + <nl> if ( bp -> b_flags & XBF_WRITE ) { <nl> if ( bp -> b_flags & XBF_SYNCIO ) <nl> rw = WRITE_SYNC ;
int ip6_xmit ( struct sock * sk , struct sk_buff * skb , struct flowi * fl , <nl> skb_reset_network_header ( skb ); <nl> hdr = ipv6_hdr ( skb ); <nl>  <nl> + /* Allow local fragmentation . */ <nl> + if ( ipfragok ) <nl> + skb -> local_df = 1 ; <nl> + <nl> /* <nl> * Fill in the IPv6 header <nl> */
static void resample_shrink ( struct snd_pcm_plugin * plugin , <nl> while ( dst_frames1 > 0 ) { <nl> S1 = S2 ; <nl> if ( src_frames1 -- > 0 ) { <nl> - S1 = * src ; <nl> + S2 = * src ; <nl> src += src_step ; <nl> } <nl> if ( pos & ~ R_MASK ) {
static int filter_ack ( struct ieee80211_hw * hw , struct ieee80211_hdr * rx_hdr , <nl> struct ieee80211_hdr * tx_hdr ; <nl>  <nl> tx_hdr = ( struct ieee80211_hdr *) skb -> data ; <nl> - if ( likely (! compare_ether_addr ( tx_hdr -> addr2 , rx_hdr -> addr1 ))) <nl> + if ( likely (! memcmp ( tx_hdr -> addr2 , rx_hdr -> addr1 , ETH_ALEN ))) <nl> { <nl> __skb_unlink ( skb , q ); <nl> tx_status ( hw , skb , IEEE80211_TX_STAT_ACK , stats -> signal , 1 );
void free_initmem ( void ) <nl> if (! have_of ) <nl> FREESEC ( openfirmware ); <nl> printk ("\ n "); <nl> + ppc_md . progress = NULL ; <nl> # undef FREESEC <nl> } <nl> 
static int msp430_ir_init ( struct budget_ci * budget_ci ) <nl> dev -> input_phys = budget_ci -> ir . phys ; <nl> dev -> input_id . bustype = BUS_PCI ; <nl> dev -> input_id . version = 1 ; <nl> + dev -> scanmask = 0xff ; <nl> if ( saa -> pci -> subsystem_vendor ) { <nl> dev -> input_id . vendor = saa -> pci -> subsystem_vendor ; <nl> dev -> input_id . product = saa -> pci -> subsystem_device ;
static u64 bpf_get_current_comm ( u64 r1 , u64 size , u64 r3 , u64 r4 , u64 r5 ) <nl> if (! task ) <nl> return - EINVAL ; <nl>  <nl> - memcpy ( buf , task -> comm , min_t ( size_t , size , sizeof ( task -> comm ))); <nl> + strlcpy ( buf , task -> comm , min_t ( size_t , size , sizeof ( task -> comm ))); <nl> return 0 ; <nl> } <nl> 
scsi_reset_provider ( struct scsi_device * dev , int flag ) <nl> rtn = FAILED ; <nl> } <nl>  <nl> - scsi_delete_timer ( scmd ); <nl> scsi_next_command ( scmd ); <nl> return rtn ; <nl> }
xlog_recover_add_to_trans ( <nl> " bad number of regions (% d ) in inode log format ", <nl> in_f -> ilf_size ); <nl> ASSERT ( 0 ); <nl> + free ( ptr ); <nl> return XFS_ERROR ( EIO ); <nl> } <nl> 
static inline void i2c_pnx_arm_timer ( struct i2c_adapter * adap ) <nl> struct timer_list * timer = & data -> mif . timer ; <nl> int expires = I2C_PNX_TIMEOUT / ( 1000 / HZ ); <nl>  <nl> + if ( expires <= 1 ) <nl> + expires = 2 ; <nl> + <nl> del_timer_sync ( timer ); <nl>  <nl> dev_dbg (& adap -> dev , " Timer armed at % lu plus % u jiffies .\ n ",
static int at86rf230_hw_init ( struct at86rf230_local * lp ) <nl> return - EINVAL ; <nl> } <nl>  <nl> + /* Force setting slotted operation bit to 0 . Sometimes the atben <nl> + * sets this bit and I don ' t know why . We set this always force <nl> + * to zero while probing . <nl> + */ <nl> + rc = at86rf230_write_subreg ( lp , SR_SLOTTED_OPERATION , 0 ); <nl> + if ( rc ) <nl> + return rc ; <nl> + <nl> return 0 ; <nl> } <nl> 
struct sta_info * sta_info_alloc ( struct ieee80211_sub_if_data * sdata , <nl> memcpy ( sta -> sta . addr , addr , ETH_ALEN ); <nl> sta -> local = local ; <nl> sta -> sdata = sdata ; <nl> + sta -> last_rx = jiffies ; <nl>  <nl> ewma_init (& sta -> avg_signal , 1024 , 8 ); <nl> 
struct request { <nl>  <nl> unsigned short ioprio ; <nl>  <nl> + unsigned int timeout ; <nl> + <nl> void * special ; /* opaque pointer available for LLD use */ <nl>  <nl> int errors ; <nl> struct request { <nl>  <nl> unsigned long deadline ; <nl> struct list_head timeout_list ; <nl> - unsigned int timeout ; <nl>  <nl> /* <nl> * completion callback .
int mac_partition ( struct parsed_partitions * state , struct block_device * bdev ) <nl> be32_to_cpu ( part -> start_block ) * ( secsize / 512 ), <nl> be32_to_cpu ( part -> block_count ) * ( secsize / 512 )); <nl>  <nl> + if (! strnicmp ( part -> type , " Linux_RAID ", 10 )) <nl> + state -> parts [ slot ]. flags = 1 ; <nl> # ifdef CONFIG_PPC_PMAC <nl> /* <nl> * If this is the first bootable partition , tell the
qla24xx_reset_adapter ( scsi_qla_host_t * vha ) <nl> WRT_REG_DWORD (& reg -> hccr , HCCRX_REL_RISC_PAUSE ); <nl> RD_REG_DWORD (& reg -> hccr ); <nl> spin_unlock_irqrestore (& ha -> hardware_lock , flags ); <nl> + <nl> + if ( IS_NOPOLLING_TYPE ( ha )) <nl> + ha -> isp_ops -> enable_intrs ( ha ); <nl> } <nl>  <nl> /* On sparc systems , obtain port and node WWN from firmware
static int do_proc_dointvec_jiffies_conv ( bool * negp , unsigned long * lvalp , <nl> int write , void * data ) <nl> { <nl> if ( write ) { <nl> - if (* lvalp > LONG_MAX / HZ ) <nl> + if (* lvalp > INT_MAX / HZ ) <nl> return 1 ; <nl> * valp = * negp ? -(* lvalp * HZ ) : (* lvalp * HZ ); <nl> } else {
static void conf_message_callback ( const char * fmt , va_list ap ) <nl>  <nl> static void show_help ( struct menu * menu ) <nl> { <nl> - struct gstr help = str_new (); <nl> + struct gstr help ; <nl> + <nl> + if (! menu ) <nl> + return ; <nl> + <nl> + help = str_new (); <nl> menu_get_ext_help ( menu , & help ); <nl> show_scroll_win ( main_window , _ ( menu_get_prompt ( menu )), str_get (& help )); <nl> str_free (& help );
static struct eg20t_port * pch_uart_init_port ( struct pci_dev * pdev , <nl> priv -> port . line = num ++; <nl> priv -> trigger = PCH_UART_HAL_TRIGGER_M ; <nl>  <nl> + spin_lock_init (& priv -> port . lock ); <nl> + <nl> pci_set_drvdata ( pdev , priv ); <nl> pch_uart_hal_request ( pdev , fifosize , base_baud ); <nl> 
static void udf_sb_free_partitions ( struct super_block * sb ) <nl> { <nl> struct udf_sb_info * sbi = UDF_SB ( sb ); <nl> int i ; <nl> - <nl> + if ( sbi -> s_partmaps == NULL ) <nl> + return ; <nl> for ( i = 0 ; i < sbi -> s_partitions ; i ++) <nl> udf_free_partition (& sbi -> s_partmaps [ i ]); <nl> kfree ( sbi -> s_partmaps );
void btrfs_evict_inode ( struct inode * inode ) <nl> btrfs_orphan_del ( NULL , inode ); <nl> goto no_delete ; <nl> } <nl> + rsv -> size = min_size ; <nl>  <nl> btrfs_i_size_write ( inode , 0 ); <nl>  <nl> static int btrfs_truncate ( struct inode * inode ) <nl> rsv = btrfs_alloc_block_rsv ( root ); <nl> if (! rsv ) <nl> return - ENOMEM ; <nl> + rsv -> size = min_size ; <nl>  <nl> /* <nl> * 1 for the truncate slack space
static int set_wep_key ( struct airo_info * ai , u16 index , const char * key , <nl> WepKeyRid wkr ; <nl> int rc ; <nl>  <nl> - WARN_ON ( keylen == 0 ); <nl> + if ( WARN_ON ( keylen == 0 )) <nl> + return - 1 ; <nl>  <nl> memset (& wkr , 0 , sizeof ( wkr )); <nl> wkr . len = cpu_to_le16 ( sizeof ( wkr ));
static struct task_struct * first_tid ( struct task_struct * leader , <nl> pos = NULL ; <nl> if ( nr && nr >= get_nr_threads ( leader )) <nl> goto out ; <nl> + /* It could be unhashed before we take rcu lock */ <nl> + if (! pid_alive ( leader )) <nl> + goto out ; <nl>  <nl> /* If we haven ' t found our starting place yet start <nl> * with the leader and walk nr threads forward .
int btrfs_kobj_rm_device ( struct btrfs_fs_info * fs_info , <nl> if (! fs_info -> device_dir_kobj ) <nl> return - EINVAL ; <nl>  <nl> - if ( one_device ) { <nl> + if ( one_device && one_device -> bdev ) { <nl> disk = one_device -> bdev -> bd_part ; <nl> disk_kobj = & part_to_dev ( disk )-> kobj ; <nl> 
int dw_mci_probe ( struct dw_mci * host ) <nl> } <nl> } <nl>  <nl> - if ( host -> pdata -> num_slots > 1 ) { <nl> + if ( host -> pdata -> num_slots < 1 ) { <nl> dev_err ( host -> dev , <nl> " Platform data must supply num_slots .\ n "); <nl> return - ENODEV ;
static int __cpufreq_set_policy ( struct cpufreq_policy * data , <nl> memcpy (& policy -> cpuinfo , & data -> cpuinfo , <nl> sizeof ( struct cpufreq_cpuinfo )); <nl>  <nl> - if ( policy -> min > data -> min && policy -> min > policy -> max ) { <nl> + if ( policy -> min > data -> max || policy -> max < data -> min ) { <nl> ret = - EINVAL ; <nl> goto error_out ; <nl> }
static void hidinput_configure_usage ( struct hid_input * hidinput , struct hid_fiel <nl> break ; <nl>  <nl> case HID_UP_BUTTON : <nl> - code = (( usage -> hid - 1 ) & 0xf ); <nl> + code = (( usage -> hid - 1 ) & HID_USAGE ); <nl>  <nl> switch ( field -> application ) { <nl> case HID_GD_MOUSE :
ext4_move_extents ( struct file * o_filp , struct file * d_filp , <nl> orig_inode -> i_ino , donor_inode -> i_ino ); <nl> return - EINVAL ; <nl> } <nl> - <nl> + /* TODO : This is non obvious task to swap blocks for inodes with full <nl> + jornaling enabled */ <nl> + if ( ext4_should_journal_data ( orig_inode ) || <nl> + ext4_should_journal_data ( donor_inode )) { <nl> + return - EINVAL ; <nl> + } <nl> /* Protect orig and donor inodes against a truncate */ <nl> mext_inode_double_lock ( orig_inode , donor_inode ); <nl> 
static int jfs_rename ( struct inode * old_dir , struct dentry * old_dentry , <nl> */ <nl> rc = dtSearch ( new_dir , & new_dname , & ino , & btstack , JFS_LOOKUP ); <nl> if (! rc ) { <nl> - if (( new_ip == 0 ) || ( ino != new_ip -> i_ino )) { <nl> + if ((! new_ip ) || ( ino != new_ip -> i_ino )) { <nl> rc = - ESTALE ; <nl> goto out3 ; <nl> }
static s32 igb_get_invariants_82575 ( struct e1000_hw * hw ) <nl> * for setting word_size . <nl> */ <nl> size += NVM_WORD_SIZE_BASE_SHIFT ; <nl> + <nl> + /* EEPROM access above 16k is unsupported */ <nl> + if ( size > 14 ) <nl> + size = 14 ; <nl> nvm -> word_size = 1 << size ; <nl>  <nl> /* setup PHY parameters */
static int __devinit sdhci_esdhc_imx_probe ( struct platform_device * pdev ) <nl> clk_prepare_enable ( clk ); <nl> pltfm_host -> clk = clk ; <nl>  <nl> - if (! is_imx25_esdhc ( imx_data )) <nl> - host -> quirks |= SDHCI_QUIRK_BROKEN_TIMEOUT_VAL ; <nl> + host -> quirks |= SDHCI_QUIRK_BROKEN_TIMEOUT_VAL ; <nl>  <nl> if ( is_imx25_esdhc ( imx_data ) || is_imx35_esdhc ( imx_data )) <nl> /* Fix errata ENGcm07207 present on i . MX25 and i . MX35 */
static int of_fsl_spi_get_chipselects ( struct device * dev ) <nl> return 0 ; <nl> } <nl>  <nl> - pinfo -> gpios = kmalloc ( ngpios * sizeof (* pinfo -> gpios ), GFP_KERNEL ); <nl> + pinfo -> gpios = kmalloc_array ( ngpios , sizeof (* pinfo -> gpios ), <nl> + GFP_KERNEL ); <nl> if (! pinfo -> gpios ) <nl> return - ENOMEM ; <nl> memset ( pinfo -> gpios , - 1 , ngpios * sizeof (* pinfo -> gpios ));
static int ml26124_hw_params ( struct snd_pcm_substream * substream , <nl> struct ml26124_priv * priv = snd_soc_codec_get_drvdata ( codec ); <nl> int i = get_coeff ( priv -> mclk , params_rate ( hw_params )); <nl>  <nl> + if ( i < 0 ) <nl> + return i ; <nl> priv -> substream = substream ; <nl> priv -> rate = params_rate ( hw_params ); <nl> 
static void cleanup_single_sta ( struct sta_info * sta ) <nl> * directly by station destruction . <nl> */ <nl> for ( i = 0 ; i < IEEE80211_NUM_TIDS ; i ++) { <nl> + kfree ( sta -> ampdu_mlme . tid_start_tx [ i ]); <nl> tid_tx = rcu_dereference_raw ( sta -> ampdu_mlme . tid_tx [ i ]); <nl> if (! tid_tx ) <nl> continue ;
void btrfs_cleanup_one_transaction ( struct btrfs_transaction * cur_trans , <nl>  <nl> btrfs_destroy_marked_extents ( root , & cur_trans -> dirty_pages , <nl> EXTENT_DIRTY ); <nl> + btrfs_destroy_pinned_extent ( root , <nl> + root -> fs_info -> pinned_extents ); <nl>  <nl> /* <nl> memset ( cur_trans , 0 , sizeof (* cur_trans ));
static void __del_gref ( struct gntalloc_gref * gref ) <nl>  <nl> if (! gnttab_end_foreign_access_ref ( gref -> gref_id , 0 )) <nl> return ; <nl> + <nl> + gnttab_free_grant_reference ( gref -> gref_id ); <nl> } <nl>  <nl> gref_size --;
static int f7188x_gpio_set_single_ended ( struct gpio_chip * chip , <nl> data &= ~ BIT ( offset ); <nl> else <nl> data |= BIT ( offset ); <nl> - superio_outb ( sio -> addr , gpio_data_mode ( bank -> regbase ), data ); <nl> + superio_outb ( sio -> addr , gpio_out_mode ( bank -> regbase ), data ); <nl>  <nl> superio_exit ( sio -> addr ); <nl> return 0 ;
static void acm_waker ( struct work_struct * waker ) <nl> static int acm_tty_open ( struct tty_struct * tty , struct file * filp ) <nl> { <nl> struct acm * acm ; <nl> - int rv = - EINVAL ; <nl> + int rv = - ENODEV ; <nl> int i ; <nl> dbg (" Entering acm_tty_open ."); <nl> 
_return_of_node_put : <nl> of_node_put ( dev_node ); <nl> _return_dev_set_drvdata : <nl> kfree ( priv -> fixed_link ); <nl> - kfree ( priv ); <nl> dev_set_drvdata ( dev , NULL ); <nl> _return : <nl> return err ;
void ath_detach ( struct ath_softc * sc ) <nl>  <nl> ath9k_hw_detach ( sc -> sc_ah ); <nl> ath9k_exit_debug ( sc ); <nl> - ath9k_ps_restore ( sc ); <nl> } <nl>  <nl> static int ath9k_reg_notifier ( struct wiphy * wiphy ,
static void bcm2048_rds_fifo_receive ( struct bcm2048_device * bdev ) <nl> bdev -> rds_info . radio_text , bdev -> fifo_size ); <nl> if ( err != 2 ) { <nl> dev_err (& bdev -> client -> dev , " RDS Read problem \ n "); <nl> + mutex_unlock (& bdev -> mutex ); <nl> return ; <nl> } <nl> 
static void si_apply_state_adjust_rules ( struct radeon_device * rdev , <nl> ( rdev -> pdev -> device == 0x6667 )) { <nl> max_sclk = 75000 ; <nl> } <nl> + } else if ( rdev -> family == CHIP_OLAND ) { <nl> + if (( rdev -> pdev -> device == 0x6604 ) && <nl> + ( rdev -> pdev -> subsystem_vendor == 0x1028 ) && <nl> + ( rdev -> pdev -> subsystem_device == 0x066F )) { <nl> + max_sclk = 75000 ; <nl> + } <nl> } <nl>  <nl> if ( rps -> vce_active ) {
int snd_soc_dapm_stream_event ( struct snd_soc_codec * codec , <nl> } <nl> } <nl> } <nl> - mutex_unlock (& codec -> mutex ); <nl>  <nl> dapm_power_widgets ( codec , event ); <nl> + mutex_unlock (& codec -> mutex ); <nl> dump_dapm ( codec , __func__ ); <nl> return 0 ; <nl> }
struct greybus_host_device * greybus_create_hd ( struct greybus_host_driver * driver <nl>  <nl> if ( buffer_size_max < GB_OPERATION_MESSAGE_SIZE_MIN ) { <nl> dev_err ( parent , " greybus host - device buffers too small \ n "); <nl> - return NULL ; <nl> + return ERR_PTR (- EINVAL ); <nl> } <nl>  <nl> if ( num_cports == 0 || num_cports > CPORT_ID_MAX ) {
static int start_afu ( struct cxlflash_cfg * cfg ) <nl>  <nl> init_pcr ( cfg ); <nl>  <nl> + /* After an AFU reset , RRQ entries are stale , clear them */ <nl> + memset (& afu -> rrq_entry , 0 , sizeof ( afu -> rrq_entry )); <nl> + <nl> /* Initialize RRQ pointers */ <nl> afu -> hrrq_start = & afu -> rrq_entry [ 0 ]; <nl> afu -> hrrq_end = & afu -> rrq_entry [ NUM_RRQ_ENTRY - 1 ];
int bond_enslave ( struct net_device * bond_dev , struct net_device * slave_dev ) <nl> * anyway ( it holds no special properties of the bond device ), <nl> * so we can change it without calling change_active_interface () <nl> */ <nl> - if (! bond -> curr_active_slave ) <nl> + if (! bond -> curr_active_slave && new_slave -> link == BOND_LINK_UP ) <nl> bond -> curr_active_slave = new_slave ; <nl>  <nl> break ;
static int inet6_rtm_getroute ( struct sk_buff * in_skb , struct nlmsghdr * nlh ) <nl> rt = ( struct rt6_info *) ip6_route_output ( net , NULL , & fl6 ); <nl> } <nl>  <nl> + if ( rt == net -> ipv6 . ip6_null_entry ) { <nl> + err = rt -> dst . error ; <nl> + ip6_rt_put ( rt ); <nl> + goto errout ; <nl> + } <nl> + <nl> skb = alloc_skb ( NLMSG_GOODSIZE , GFP_KERNEL ); <nl> if (! skb ) { <nl> ip6_rt_put ( rt );
static int bnx2x_set_pauseparam ( struct net_device * dev , <nl> bp -> link_params . req_flow_ctrl [ cfg_idx ] = <nl> BNX2X_FLOW_CTRL_AUTO ; <nl> } <nl> + bp -> link_params . req_fc_auto_adv = BNX2X_FLOW_CTRL_NONE ; <nl> + if ( epause -> rx_pause ) <nl> + bp -> link_params . req_fc_auto_adv |= BNX2X_FLOW_CTRL_RX ; <nl> + <nl> + if ( epause -> tx_pause ) <nl> + bp -> link_params . req_fc_auto_adv |= BNX2X_FLOW_CTRL_TX ; <nl> } <nl>  <nl> DP ( BNX2X_MSG_ETHTOOL ,
struct uts_namespace ; <nl>  <nl> extern cpumask_var_t cpu_isolated_map ; <nl>  <nl> - extern int runqueue_is_locked ( int cpu ); <nl> - <nl> extern void scheduler_tick ( void ); <nl>  <nl> # define MAX_SCHEDULE_TIMEOUT LONG_MAX
u32 mp_query_psd ( struct adapter * pAdapter , u8 * data ) <nl> sscanf ( data , " pts =% d , start =% d , stop =% d ", & psd_pts , & psd_start , & psd_stop ); <nl> } <nl>  <nl> - _rtw_memset ( data , '\ 0 ', sizeof ( data )); <nl> + _rtw_memset ( data , '\ 0 ', sizeof (* data )); <nl>  <nl> i = psd_start ; <nl> while ( i < psd_stop ) {
int hfsplus_parse_options ( char * input , struct hfsplus_sb_info * sbi ) <nl> return 0 ; <nl> } <nl> p = match_strdup (& args [ 0 ]); <nl> - sbi -> nls = load_nls ( p ); <nl> + if ( p ) <nl> + sbi -> nls = load_nls ( p ); <nl> if (! sbi -> nls ) { <nl> printk ( KERN_ERR " hfs : unable to load nls mapping \"% s \"\ n ", p ); <nl> kfree ( p );
static void mt_feature_mapping ( struct hid_device * hdev , <nl> td -> is_buttonpad = true ; <nl>  <nl> break ; <nl> + case 0xff0000c5 : <nl> + /* Retrieve the Win8 blob once to enable some devices */ <nl> + if ( usage -> usage_index == 0 ) <nl> + mt_get_feature ( hdev , field -> report ); <nl> + break ; <nl> } <nl> } <nl> 
static int chsc_ioctl_info_cu ( void __user * user_cd ) <nl> goto out_free ; <nl> } <nl> scucd_area -> request . length = 0x0010 ; <nl> - scucd_area -> request . code = 0x0028 ; <nl> + scucd_area -> request . code = 0x0026 ; <nl> scucd_area -> m = cd -> m ; <nl> scucd_area -> fmt1 = cd -> fmt ; <nl> scucd_area -> cssid = cd -> cssid ;
int mc13xxx_common_init ( struct mc13xxx * mc13xxx , <nl> err_mask : <nl> err_revision : <nl> mc13xxx_unlock ( mc13xxx ); <nl> - kfree ( mc13xxx ); <nl> return ret ; <nl> } <nl> 
__ip_vs_get_dest_entries ( struct net * net , const struct ip_vs_get_dests * get , <nl> struct ip_vs_dest * dest ; <nl> struct ip_vs_dest_entry entry ; <nl>  <nl> + memset (& entry , 0 , sizeof ( entry )); <nl> list_for_each_entry ( dest , & svc -> destinations , n_list ) { <nl> if ( count >= get -> num_dests ) <nl> break ;
static bool radeon_msi_ok ( struct radeon_device * rdev ) <nl> ( rdev -> pdev -> subsystem_device == 0x0185 )) <nl> return true ; <nl>  <nl> + /* try and enable MSIs by default on all RS690s */ <nl> + if ( rdev -> family == CHIP_RS690 ) <nl> + return true ; <nl> + <nl> /* RV515 seems to have MSI issues where it loses <nl> * MSI rearms occasionally . This leads to lockups and freezes . <nl> * disable it by default .
extern void __chk_io_ptr ( void __iomem *); <nl> # define __deprecated /* unimplemented */ <nl> # endif <nl>  <nl> +# ifdef MODULE <nl> +# define __deprecated_for_modules __deprecated <nl> +# else <nl> +# define __deprecated_for_modules <nl> +# endif <nl> + <nl> # ifndef __must_check <nl> # define __must_check <nl> # endif
static int fsl_pcie_check_link ( struct pci_controller * hose ) <nl> if ( hose -> indirect_type & PPC_INDIRECT_TYPE_FSL_CFG_REG_LINK ) { <nl> if ( hose -> ops -> read == fsl_indirect_read_config ) { <nl> struct pci_bus bus ; <nl> - bus . number = 0 ; <nl> + bus . number = hose -> first_busno ; <nl> bus . sysdata = hose ; <nl> bus . ops = hose -> ops ; <nl> indirect_read_config (& bus , 0 , PCIE_LTSSM , 4 , & val );
err_dvb_unregister_frontend : <nl>  <nl> err_dvb_frontend_detach : <nl> for ( i = MAX_NO_OF_FE_PER_ADAP - 1 ; i >= 0 ; i --) { <nl> - if ( adap -> fe [ i ]) <nl> + if ( adap -> fe [ i ]) { <nl> dvb_frontend_detach ( adap -> fe [ i ]); <nl> + adap -> fe [ i ] = NULL ; <nl> + } <nl> } <nl>  <nl> err :
x86_emulate_insn ( struct x86_emulate_ctxt * ctxt ) <nl> goto done ; <nl> } <nl>  <nl> + if (( c -> d & SrcMask ) == SrcMemFAddr && c -> src . type != OP_MEM ) { <nl> + emulate_ud ( ctxt ); <nl> + goto done ; <nl> + } <nl> + <nl> /* Privileged instruction can be executed only in CPL = 0 */ <nl> if (( c -> d & Priv ) && ops -> cpl ( ctxt -> vcpu )) { <nl> emulate_gp ( ctxt , 0 );
static int dwc3_cleanup_done_reqs ( struct dwc3 * dwc , struct dwc3_ep * dep , <nl> for_each_sg ( sg , s , pending , i ) { <nl> trb = & dep -> trb_pool [ dep -> trb_dequeue ]; <nl>  <nl> + if ( trb -> ctrl & DWC3_TRB_CTRL_HWO ) <nl> + break ; <nl> + <nl> req -> sg = sg_next ( s ); <nl> req -> num_pending_sgs --; <nl> 
static struct omap_board_mux board_mux [] __initdata = { <nl> OMAP4_MUX ( DPM_EMU18 , OMAP_PIN_OUTPUT | OMAP_MUX_MODE5 ), <nl> /* dispc2_data0 */ <nl> OMAP4_MUX ( DPM_EMU19 , OMAP_PIN_OUTPUT | OMAP_MUX_MODE5 ), <nl> + /* NIRQ2 for twl6040 */ <nl> + OMAP4_MUX ( SYS_NIRQ2 , OMAP_MUX_MODE0 | <nl> + OMAP_PIN_INPUT_PULLUP | OMAP_PIN_OFF_WAKEUPENABLE ), <nl> { . reg_offset = OMAP_MUX_TERMINATOR }, <nl> }; <nl> 
static int dummy_udc_probe ( struct platform_device * pdev ) <nl> int rc ; <nl>  <nl> dum = *(( void **) dev_get_platdata (& pdev -> dev )); <nl> + /* Clear usb_gadget region for new registration to udc - core */ <nl> + memzero_explicit (& dum -> gadget , sizeof ( struct usb_gadget )); <nl> dum -> gadget . name = gadget_name ; <nl> dum -> gadget . ops = & dummy_ops ; <nl> dum -> gadget . max_speed = USB_SPEED_SUPER ;
static unsigned long super_cache_scan ( struct shrinker * shrink , <nl> inodes = list_lru_count_node (& sb -> s_inode_lru , sc -> nid ); <nl> dentries = list_lru_count_node (& sb -> s_dentry_lru , sc -> nid ); <nl> total_objects = dentries + inodes + fs_objects + 1 ; <nl> + if (! total_objects ) <nl> + total_objects = 1 ; <nl>  <nl> /* proportion the scan between the caches */ <nl> dentries = mult_frac ( sc -> nr_to_scan , dentries , total_objects );
static int __devinit cpm_i2c_setup ( struct cpm_i2c * cpm ) <nl> init_waitqueue_head (& cpm -> i2c_wait ); <nl>  <nl> cpm -> irq = of_irq_to_resource ( ofdev -> node , 0 , NULL ); <nl> - if ( cpm -> irq == NO_IRQ ) <nl> + if (! cpm -> irq ) <nl> return - EINVAL ; <nl>  <nl> /* Install interrupt handler . */
pnfs_layout_bulk_destroy_byserver_locked ( struct nfs_client * clp , <nl> struct inode * inode ; <nl>  <nl> list_for_each_entry_safe ( lo , next , & server -> layouts , plh_layouts ) { <nl> + if ( test_bit ( NFS_LAYOUT_INVALID_STID , & lo -> plh_flags )) <nl> + continue ; <nl> inode = igrab ( lo -> plh_inode ); <nl> if ( inode == NULL ) <nl> continue ;
mxm_sor_map ( struct nvkm_bios * bios , u8 conn ) <nl> u16 map = nvbios_rd16 ( bios , mxm + 4 ); <nl> if ( map ) { <nl> ver = nvbios_rd08 ( bios , map ); <nl> - if ( ver == 0x10 ) { <nl> + if ( ver == 0x10 || ver == 0x11 ) { <nl> if ( conn < nvbios_rd08 ( bios , map + 3 )) { <nl> map += nvbios_rd08 ( bios , map + 1 ); <nl> map += conn ;
retry_snap : <nl> goto retry_snap ; <nl> } <nl> } else { <nl> + loff_t old_size = inode -> i_size ; <nl> /* <nl> * No need to acquire the i_truncate_mutex . Because <nl> * the MDS revokes Fwb caps before sending truncate <nl> retry_snap : <nl> written = generic_file_buffered_write ( iocb , iov , nr_segs , <nl> pos , & iocb -> ki_pos , <nl> count , 0 ); <nl> + if ( inode -> i_size > old_size ) <nl> + ceph_fscache_update_objectsize ( inode ); <nl> mutex_unlock (& inode -> i_mutex ); <nl> } <nl> 
static int usb_serial_probe ( struct usb_interface * interface , <nl> num_ports = type -> num_ports ; <nl> } <nl>  <nl> + if ( num_ports > MAX_NUM_PORTS ) { <nl> + dev_warn ( ddev , " too many ports requested : % d \ n ", num_ports ); <nl> + num_ports = MAX_NUM_PORTS ; <nl> + } <nl> + <nl> serial -> num_ports = num_ports ; <nl> serial -> num_bulk_in = num_bulk_in ; <nl> serial -> num_bulk_out = num_bulk_out ;
int xhci_urb_enqueue ( struct usb_hcd * hcd , struct urb * urb , gfp_t mem_flags ) <nl> if (! xhci -> devs || ! xhci -> devs [ slot_id ]) { <nl> if (! in_interrupt ()) <nl> dev_warn (& urb -> dev -> dev , " WARN : urb submitted for dev with no Slot ID \ n "); <nl> - return - EINVAL ; <nl> + ret = - EINVAL ; <nl> + goto exit ; <nl> } <nl> if (! test_bit ( HCD_FLAG_HW_ACCESSIBLE , & hcd -> flags )) { <nl> if (! in_interrupt ())
i915_gem_execbuffer ( struct drm_device * dev , void * data , <nl> ( int ) args -> buffers_ptr , args -> buffer_count , args -> batch_len ); <nl> # endif <nl>  <nl> + if ( args -> buffer_count < 1 ) { <nl> + DRM_ERROR (" execbuf with % d buffers \ n ", args -> buffer_count ); <nl> + return - EINVAL ; <nl> + } <nl> /* Copy in the exec list from userland */ <nl> exec_list = drm_calloc ( sizeof (* exec_list ), args -> buffer_count , <nl> DRM_MEM_DRIVER );
void pci_bus_add_device ( struct pci_dev * dev ) <nl>  <nl> dev -> match_driver = true ; <nl> retval = device_attach (& dev -> dev ); <nl> - if ( retval < 0 ) { <nl> + if ( retval < 0 && retval != - EPROBE_DEFER ) { <nl> dev_warn (& dev -> dev , " device attach failed (% d )\ n ", retval ); <nl> pci_proc_detach_device ( dev ); <nl> pci_remove_sysfs_dev_files ( dev );
static irqreturn_t ads7846_irq ( int irq , void * handle ) <nl> msecs_to_jiffies ( TS_POLL_PERIOD )); <nl> } <nl>  <nl> - if ( ts -> pendown ) { <nl> + if ( ts -> pendown && ! ts -> stopped ) { <nl> struct input_dev * input = ts -> input ; <nl>  <nl> input_report_key ( input , BTN_TOUCH , 0 );
static int gb_interface_resume ( struct device * dev ) <nl> return ret ; <nl> } <nl>  <nl> + ret = gb_timesync_schedule_synchronous ( intf ); <nl> + if ( ret ) { <nl> + dev_err ( dev , " failed to synchronize FrameTime : % d \ n ", ret ); <nl> + return ret ; <nl> + } <nl> + <nl> return 0 ; <nl> } <nl> 
static void iwl3945_init_hw_rates ( struct iwl_priv * priv , <nl> { <nl> int i ; <nl>  <nl> - for ( i = 0 ; i < IWL_RATE_COUNT ; i ++) { <nl> + for ( i = 0 ; i < IWL_RATE_COUNT_LEGACY ; i ++) { <nl> rates [ i ]. bitrate = iwl3945_rates [ i ]. ieee * 5 ; <nl> rates [ i ]. hw_value = i ; /* Rate scaling will work on indexes */ <nl> rates [ i ]. hw_value_short = i ;
int ieee80211_radiotap_iterator_init ( <nl> /* find payload start allowing for extended bitmap ( s ) */ <nl>  <nl> if ( iterator -> _bitmap_shifter & ( 1 << IEEE80211_RADIOTAP_EXT )) { <nl> + if (( unsigned long ) iterator -> _arg - <nl> + ( unsigned long ) iterator -> _rtheader + sizeof ( uint32_t ) > <nl> + ( unsigned long ) iterator -> _max_length ) <nl> + return - EINVAL ; <nl> while ( get_unaligned_le32 ( iterator -> _arg ) & <nl> ( 1 << IEEE80211_RADIOTAP_EXT )) { <nl> iterator -> _arg += sizeof ( uint32_t );
static int davinci_pcm_open ( struct snd_pcm_substream * substream ) <nl> int ret = 0 ; <nl>  <nl> snd_soc_set_runtime_hwparams ( substream , & davinci_pcm_hardware ); <nl> + /* ensure that buffer size is a multiple of period size */ <nl> + ret = snd_pcm_hw_constraint_integer ( runtime , <nl> + SNDRV_PCM_HW_PARAM_PERIODS ); <nl> + if ( ret < 0 ) <nl> + return ret ; <nl>  <nl> prtd = kzalloc ( sizeof ( struct davinci_runtime_data ), GFP_KERNEL ); <nl> if ( prtd == NULL )
int radeon_atom_get_mclk_range_table ( struct radeon_device * rdev , <nl> p = ( u8 *) vram_module -> asMemTiming ; <nl> for ( i = 0 ; i < mclk_range_table -> num_entries ; i ++) { <nl> format = ( ATOM_MEMORY_TIMING_FORMAT *) p ; <nl> - mclk_range_table -> mclk [ i ] = format -> ulClkRange ; <nl> + mclk_range_table -> mclk [ i ] = le32_to_cpu ( format -> ulClkRange ); <nl> p += mem_timing_size ; <nl> } <nl> } else
int udf_ioctl ( struct inode * inode , struct file * filp , unsigned int cmd , <nl> static int udf_release_file ( struct inode * inode , struct file * filp ) <nl> { <nl> if ( filp -> f_mode & FMODE_WRITE ) { <nl> + mutex_lock (& inode -> i_mutex ); <nl> lock_kernel (); <nl> udf_discard_prealloc ( inode ); <nl> unlock_kernel (); <nl> + mutex_unlock (& inode -> i_mutex ); <nl> } <nl> return 0 ; <nl> }
static void cfq_dispatch_insert ( struct request_queue * q , struct request * rq ) <nl>  <nl> cfq_log_cfqq ( cfqd , cfqq , " dispatch_insert "); <nl>  <nl> + cfqq -> next_rq = cfq_find_next_rq ( cfqd , cfqq , rq ); <nl> cfq_remove_request ( rq ); <nl> cfqq -> dispatched ++; <nl> elv_dispatch_sort ( q , rq );
static int st_fdma_probe ( struct platform_device * pdev ) <nl> } <nl>  <nl> fdev -> slim_rproc = st_slim_rproc_alloc ( pdev , fdev -> fw_name ); <nl> - if (! fdev -> slim_rproc ) { <nl> + if ( IS_ERR ( fdev -> slim_rproc )) { <nl> ret = PTR_ERR ( fdev -> slim_rproc ); <nl> dev_err (& pdev -> dev , " slim_rproc_alloc failed (% d )\ n ", ret ); <nl> goto err ;
static int vpfe_enum_input ( struct file * file , void * priv , <nl> return - EINVAL ; <nl> } <nl> sdinfo = & vpfe_dev -> cfg -> sub_devs [ subdev ]; <nl> - memcpy ( inp , & sdinfo -> inputs [ index ], sizeof ( struct v4l2_input )); <nl> + * inp = sdinfo -> inputs [ index ]; <nl> return 0 ; <nl> } <nl> 
static int ieee802154_dev_ioctl ( struct sock * sk , struct ifreq __user * arg , <nl> dev_load ( sock_net ( sk ), ifr . ifr_name ); <nl> dev = dev_get_by_name ( sock_net ( sk ), ifr . ifr_name ); <nl>  <nl> + if (! dev ) <nl> + return - ENODEV ; <nl> + <nl> if ( dev -> type == ARPHRD_IEEE802154 && dev -> netdev_ops -> ndo_do_ioctl ) <nl> ret = dev -> netdev_ops -> ndo_do_ioctl ( dev , & ifr , cmd ); <nl> 
static int btrfs_set_acl ( struct btrfs_trans_handle * trans , <nl> ret = posix_acl_equiv_mode ( acl , & inode -> i_mode ); <nl> if ( ret < 0 ) <nl> return ret ; <nl> + if ( ret == 0 ) <nl> + acl = NULL ; <nl> } <nl> ret = 0 ; <nl> break ;
static int ds2760_battery_remove ( struct platform_device * pdev ) <nl> & di -> set_charged_work ); <nl> destroy_workqueue ( di -> monitor_wqueue ); <nl> power_supply_unregister (& di -> bat ); <nl> + kfree ( di ); <nl>  <nl> return 0 ; <nl> }
static struct zonelist * zonelist_policy ( unsigned int __nocast gfp , struct mempol <nl> case MPOL_BIND : <nl> /* Lower zones don ' t get a policy applied */ <nl> /* Careful : current -> mems_allowed might have moved */ <nl> - if ( gfp >= policy_zone ) <nl> + if (( gfp & GFP_ZONEMASK ) >= policy_zone ) <nl> if ( cpuset_zonelist_valid_mems_allowed ( policy -> v . zonelist )) <nl> return policy -> v . zonelist ; <nl> /* FALL THROUGH */
static int xhci_plat_probe ( struct platform_device * pdev ) <nl> if ( ret ) <nl> goto dealloc_usb2_hcd ; <nl>  <nl> + device_enable_async_suspend (& pdev -> dev ); <nl> + <nl> return 0 ; <nl>  <nl> 
struct ifmcaddr6 <nl> struct ip6_sf_list * mca_sources ; <nl> struct ip6_sf_list * mca_tomb ; <nl> unsigned int mca_sfmode ; <nl> + unsigned char mca_crcount ; <nl> unsigned long mca_sfcount [ 2 ]; <nl> struct timer_list mca_timer ; <nl> unsigned mca_flags ; <nl> int mca_users ; <nl> atomic_t mca_refcnt ; <nl> spinlock_t mca_lock ; <nl> - unsigned char mca_crcount ; <nl> unsigned long mca_cstamp ; <nl> unsigned long mca_tstamp ; <nl> };
int ext4_punch_hole ( struct inode * inode , loff_t offset , loff_t length ) <nl> up_write (& EXT4_I ( inode )-> i_data_sem ); <nl> if ( IS_SYNC ( inode )) <nl> ext4_handle_sync ( handle ); <nl> + <nl> + /* Now release the pages again to reduce race window */ <nl> + if ( last_block_offset > first_block_offset ) <nl> + truncate_pagecache_range ( inode , first_block_offset , <nl> + last_block_offset ); <nl> + <nl> inode -> i_mtime = inode -> i_ctime = ext4_current_time ( inode ); <nl> ext4_mark_inode_dirty ( handle , inode ); <nl> out_stop :
static void sil_host_intr ( struct ata_port * ap , u32 bmdma2 ) <nl> u8 status ; <nl>  <nl> if ( unlikely ( bmdma2 & SIL_DMA_SATA_IRQ )) { <nl> - u32 serror ; <nl> + u32 serror = 0xffffffff ; <nl>  <nl> /* SIEN doesn ' t mask SATA IRQs on some 3112s . Those <nl> * controllers continue to assert IRQ as long as
pptp_inbound_pkt ( struct sk_buff ** pskb , <nl> DEBUGP ("% s but no session \ n ", pptp_msg_name [ msg ]); <nl> break ; <nl> } <nl> - if ( info -> sstate != PPTP_CALL_IN_REP <nl> - && info -> sstate != PPTP_CALL_IN_CONF ) { <nl> + if ( info -> cstate != PPTP_CALL_IN_REP <nl> + && info -> cstate != PPTP_CALL_IN_CONF ) { <nl> DEBUGP ("% s but never sent IN_CALL_REPLY \ n ", <nl> pptp_msg_name [ msg ]); <nl> break ;
pte_t xen_make_pte ( unsigned long long pte ) <nl> if ( pte & 1 ) <nl> pte = phys_to_machine ( XPADDR ( pte )). maddr ; <nl>  <nl> + pte &= ~ _PAGE_PCD ; <nl> + <nl> return ( pte_t ){ pte , pte >> 32 }; <nl> } <nl>  <nl> pte_t xen_make_pte ( unsigned long pte ) <nl> if ( pte & _PAGE_PRESENT ) <nl> pte = phys_to_machine ( XPADDR ( pte )). maddr ; <nl>  <nl> + pte &= ~ _PAGE_PCD ; <nl> + <nl> return ( pte_t ){ pte }; <nl> } <nl> 
static int sbp2scsi_slave_configure ( struct scsi_device * sdev ) <nl> blk_queue_dma_alignment ( sdev -> request_queue , ( 512 - 1 )); <nl> sdev -> use_10_for_rw = 1 ; <nl>  <nl> + if ( sdev -> type == TYPE_ROM ) <nl> + sdev -> use_10_for_ms = 1 ; <nl> if ( sdev -> type == TYPE_DISK && <nl> lu -> workarounds & SBP2_WORKAROUND_MODE_SENSE_8 ) <nl> sdev -> skip_ms_page_8 = 1 ;
loff_t mem_lseek ( struct file * file , loff_t offset , int orig ) <nl> static int mem_release ( struct inode * inode , struct file * file ) <nl> { <nl> struct mm_struct * mm = file -> private_data ; <nl> - <nl> - mmput ( mm ); <nl> + if ( mm ) <nl> + mmput ( mm ); <nl> return 0 ; <nl> } <nl> 
static void bus_reset_work ( struct work_struct * work ) <nl> { <nl> struct fw_ohci * ohci = <nl> container_of ( work , struct fw_ohci , bus_reset_work ); <nl> - int self_id_count , i , j , reg ; <nl> - int generation , new_generation ; <nl> + int self_id_count , generation , new_generation , i , j ; <nl> + u32 reg ; <nl> unsigned long flags ; <nl> void * free_rom = NULL ; <nl> dma_addr_t free_rom_bus = 0 ;
static struct scsi_device * scsi_alloc_sdev ( struct scsi_target * starget , <nl> /* release fn is set up in scsi_sysfs_device_initialise , so <nl> * have to free and put manually here */ <nl> put_device (& starget -> dev ); <nl> + kfree ( sdev ); <nl> goto out ; <nl> } <nl> 
static void r8a66597_check_detect_child ( struct r8a66597 * r8a66597 , <nl>  <nl> memset ( now_map , 0 , sizeof ( now_map )); <nl>  <nl> + mutex_lock (& usb_bus_idr_lock ); <nl> bus = idr_find (& usb_bus_idr , hcd -> self . busnum ); <nl> if ( bus && bus -> root_hub ) { <nl> collect_usb_address_map ( bus -> root_hub , now_map ); <nl> update_usb_address_map ( r8a66597 , bus -> root_hub , now_map ); <nl> } <nl> + mutex_unlock (& usb_bus_idr_lock ); <nl> } <nl>  <nl> static int r8a66597_hub_status_data ( struct usb_hcd * hcd , char * buf )
static void acm_softint ( struct work_struct * work ) <nl> static void acm_waker ( struct work_struct * waker ) <nl> { <nl> struct acm * acm = container_of ( waker , struct acm , waker ); <nl> - long flags ; <nl> + unsigned long flags ; <nl> int rv ; <nl>  <nl> rv = usb_autopm_get_interface ( acm -> control );
static int blkpg_ioctl ( struct block_device * bdev , struct blkpg_ioctl_arg __user <nl> || pstart < 0 || plength < 0 || partno > 65535 ) <nl> return - EINVAL ; <nl> } <nl> + /* check if partition is aligned to blocksize */ <nl> + if ( p . start & ( bdev_logical_block_size ( bdev ) - 1 )) <nl> + return - EINVAL ; <nl>  <nl> mutex_lock (& bdev -> bd_mutex ); <nl> 
int btrfs_commit_transaction ( struct btrfs_trans_handle * trans , <nl> spin_unlock (& root -> fs_info -> trans_lock ); <nl>  <nl> wait_for_commit ( root , prev_trans ); <nl> + ret = prev_trans -> aborted ; <nl>  <nl> btrfs_put_transaction ( prev_trans ); <nl> + if ( ret ) <nl> + goto cleanup_transaction ; <nl> } else { <nl> spin_unlock (& root -> fs_info -> trans_lock ); <nl> }
__setup (" vga =", sm712vga_setup ); <nl> * Original init function changed to probe method to be used by pci_drv <nl> * process used to detect chips replaced with kernel process in pci_drv <nl> */ <nl> - static int __init smtcfb_pci_probe ( struct pci_dev * pdev , <nl> + static int __devinit smtcfb_pci_probe ( struct pci_dev * pdev , <nl> const struct pci_device_id * ent ) <nl> { <nl> struct smtcfb_info * sfb ;
int twl4030_madc_conversion ( struct twl4030_madc_request * req ) <nl> u8 ch_msb , ch_lsb ; <nl> int ret ; <nl>  <nl> - if (! req ) <nl> + if (! req || ! twl4030_madc ) <nl> return - EINVAL ; <nl> + <nl> mutex_lock (& twl4030_madc -> lock ); <nl> if ( req -> method < TWL4030_MADC_RT || req -> method > TWL4030_MADC_SW2 ) { <nl> ret = - EINVAL ;
static int vt8500lcd_remove ( struct platform_device * pdev ) <nl> res = platform_get_resource ( pdev , IORESOURCE_MEM , 0 ); <nl> release_mem_region ( res -> start , resource_size ( res )); <nl>  <nl> - kfree ( fbi ); <nl> - <nl> return 0 ; <nl> } <nl> 
static int ds1374_probe ( struct i2c_adapter * adap , int addr , int kind ) <nl> client -> driver = & ds1374_driver ; <nl>  <nl> ds1374_workqueue = create_singlethread_workqueue (" ds1374 "); <nl> + if (! ds1374_workqueue ) { <nl> + kfree ( client ); <nl> + return - ENOMEM ; /* most expected reason */ <nl> + } <nl>  <nl> if (( rc = i2c_attach_client ( client )) != 0 ) { <nl> kfree ( client );
int btrfs_ordered_update_i_size ( struct inode * inode , u64 offset , <nl>  <nl> if ( ordered ) <nl> offset = entry_end ( ordered ); <nl> + else <nl> + offset = ALIGN ( offset , BTRFS_I ( inode )-> root -> sectorsize ); <nl>  <nl> mutex_lock (& tree -> mutex ); <nl> disk_i_size = BTRFS_I ( inode )-> disk_i_size ;
static int gb_connection_hd_cport_quiesce ( struct gb_connection * connection ) <nl> if ( connection -> mode_switch ) <nl> peer_space += sizeof ( struct gb_operation_msg_hdr ); <nl>  <nl> + if (! hd -> driver -> cport_quiesce ) <nl> + return 0 ; <nl> + <nl> ret = hd -> driver -> cport_quiesce ( hd , connection -> hd_cport_id , <nl> peer_space , <nl> GB_CONNECTION_CPORT_QUIESCE_TIMEOUT );
static struct platform_driver axp288_fuel_gauge_driver = { <nl>  <nl> module_platform_driver ( axp288_fuel_gauge_driver ); <nl>  <nl> + MODULE_AUTHOR (" Ramakrishna Pallala < ramakrishna . pallala @ intel . com >"); <nl> MODULE_AUTHOR (" Todd Brandt < todd . e . brandt @ linux . intel . com >"); <nl> MODULE_DESCRIPTION (" Xpower AXP288 Fuel Gauge Driver "); <nl> MODULE_LICENSE (" GPL ");
out : <nl> static int si476x_codec_probe ( struct snd_soc_codec * codec ) <nl> { <nl> codec -> control_data = dev_get_regmap ( codec -> dev -> parent , NULL ); <nl> - return 0 ; <nl> + return snd_soc_codec_set_cache_io ( codec , 0 , 0 , SND_SOC_REGMAP ); <nl> } <nl>  <nl> static struct snd_soc_dai_ops si476x_dai_ops = {
static int batadv_tp_send ( void * arg ) <nl> primary_if = batadv_primary_if_get_selected ( bat_priv ); <nl> if ( unlikely (! primary_if )) { <nl> err = BATADV_TP_REASON_DST_UNREACHABLE ; <nl> + tp_vars -> reason = err ; <nl> goto out ; <nl> } <nl> 
lpfc_send_els_event ( struct lpfc_vport * vport , <nl> sizeof ( struct lpfc_name )); <nl> break ; <nl> default : <nl> + kfree ( els_data ); <nl> return ; <nl> } <nl> memcpy ( els_data -> wwpn , & ndlp -> nlp_portname , sizeof ( struct lpfc_name ));
static struct page * page_chain_del ( struct page ** head , int n ) <nl> BUG_ON (! head ); <nl>  <nl> page = * head ; <nl> + <nl> + if (! page ) <nl> + return NULL ; <nl> + <nl> while ( page ) { <nl> tmp = page_chain_next ( page ); <nl> if (-- n == 0 )
static void gpiodevice_release ( struct device * dev ) <nl> cdev_del (& gdev -> chrdev ); <nl> list_del (& gdev -> list ); <nl> ida_simple_remove (& gpio_ida , gdev -> id ); <nl> + kfree ( gdev ); <nl> } <nl>  <nl> /**
static u32 slic_card_locate ( struct adapter * adapter ) <nl> if (! physcard ) { <nl> /* no structure allocated for this physical card yet */ <nl> physcard = kzalloc ( sizeof ( struct physcard ), GFP_ATOMIC ); <nl> - if (! physcard ) <nl> + if (! physcard ) { <nl> + if ( card_hostid == SLIC_HOSTID_DEFAULT ) <nl> + kfree ( card ); <nl> return - ENOMEM ; <nl> + } <nl>  <nl> physcard -> next = slic_global . phys_card ; <nl> slic_global . phys_card = physcard ;
int tipc_nl_node_get_monitor ( struct sk_buff * skb , struct genl_info * info ) <nl> int err ; <nl>  <nl> msg . skb = nlmsg_new ( NLMSG_GOODSIZE , GFP_KERNEL ); <nl> + if (! msg . skb ) <nl> + return - ENOMEM ; <nl> msg . portid = info -> snd_portid ; <nl> msg . seq = info -> snd_seq ; <nl> 
struct ttm_tt * ttm_tt_create ( struct ttm_bo_device * bdev , unsigned long size , <nl> ttm -> dummy_read_page = dummy_read_page ; <nl>  <nl> ttm_tt_alloc_page_directory ( ttm ); <nl> - if (! ttm -> pages ) { <nl> + if (! ttm -> pages || ! ttm -> dma_address ) { <nl> ttm_tt_destroy ( ttm ); <nl> printk ( KERN_ERR TTM_PFX " Failed allocating page table \ n "); <nl> return NULL ;
void btrfs_rm_dev_replace_srcdev ( struct btrfs_fs_info * fs_info , <nl> fs_devices -> num_devices --; <nl> if ( srcdev -> missing ) { <nl> fs_devices -> missing_devices --; <nl> - fs_devices -> rw_devices ++; <nl> + if (! fs_devices -> seeding ) <nl> + fs_devices -> rw_devices ++; <nl> } <nl> if ( srcdev -> can_discard ) <nl> fs_devices -> num_can_discard --;
static void v4l2_ctrl_del_event ( struct v4l2_subscribed_event * sev ) <nl> { <nl> struct v4l2_ctrl * ctrl = v4l2_ctrl_find ( sev -> fh -> ctrl_handler , sev -> id ); <nl>  <nl> + if ( ctrl == NULL ) <nl> + return ; <nl> + <nl> v4l2_ctrl_lock ( ctrl ); <nl> list_del (& sev -> node ); <nl> v4l2_ctrl_unlock ( ctrl );
static struct config_item_type printer_func_type = { <nl>  <nl> static inline int gprinter_get_minor ( void ) <nl> { <nl> - return ida_simple_get (& printer_ida , 0 , 0 , GFP_KERNEL ); <nl> + int ret ; <nl> + <nl> + ret = ida_simple_get (& printer_ida , 0 , 0 , GFP_KERNEL ); <nl> + if ( ret >= PRINTER_MINORS ) { <nl> + ida_simple_remove (& printer_ida , ret ); <nl> + ret = - ENODEV ; <nl> + } <nl> + <nl> + return ret ; <nl> } <nl>  <nl> static inline void gprinter_put_minor ( int minor )
static int spi_map_buf ( struct spi_master * master , struct device * dev , <nl> } <nl>  <nl> ret = dma_map_sg ( dev , sgt -> sgl , sgt -> nents , dir ); <nl> + if (! ret ) <nl> + ret = - ENOMEM ; <nl> if ( ret < 0 ) { <nl> sg_free_table ( sgt ); <nl> return ret ;
static ssize_t spufs_mfc_write ( struct file * file , const char __user * buffer , <nl> if ( ret ) <nl> goto out ; <nl>  <nl> - spu_acquire_runnable ( ctx , 0 ); <nl> + ret = spu_acquire_runnable ( ctx , 0 ); <nl> + if ( ret ) <nl> + goto out ; <nl> + <nl> if ( file -> f_flags & O_NONBLOCK ) { <nl> ret = ctx -> ops -> send_mfc_command ( ctx , & cmd ); <nl> } else {
static int mtk_pmx_gpio_request_enable ( struct pinctrl_dev * pctldev , <nl> } <nl>  <nl> mtk_pmx_set_mode ( pctldev , offset , muxval ); <nl> + mtk_pconf_set_ies_smt ( pctl , offset , 1 , PIN_CONFIG_INPUT_ENABLE ); <nl>  <nl> return 0 ; <nl> }
static int __init scm_blk_init ( void ) <nl> scm_major = ret ; <nl> ret = scm_alloc_rqs ( nr_requests ); <nl> if ( ret ) <nl> - goto out_unreg ; <nl> + goto out_free ; <nl>  <nl> scm_debug = debug_register (" scm_log ", 16 , 1 , 16 ); <nl> if (! scm_debug ) { <nl> out_dbf : <nl> debug_unregister ( scm_debug ); <nl> out_free : <nl> scm_free_rqs (); <nl> - out_unreg : <nl> unregister_blkdev ( scm_major , " scm "); <nl> out : <nl> return ret ;
static void ixgbe_watchdog_link_is_up ( struct ixgbe_adapter * adapter ) <nl> ( flow_tx ? " TX " : " None ")))); <nl>  <nl> netif_carrier_on ( netdev ); <nl> -# ifdef HAVE_IPLINK_VF_CONFIG <nl> ixgbe_check_vf_rate_limit ( adapter ); <nl> -# endif /* HAVE_IPLINK_VF_CONFIG */ <nl> } <nl>  <nl> /**
static int __init early_get_pnodeid ( void ) <nl> break ; <nl> case UV3_HUB_PART_NUMBER : <nl> case UV3_HUB_PART_NUMBER_X : <nl> - uv_min_hub_revision_id += UV3_HUB_REVISION_BASE - 1 ; <nl> + uv_min_hub_revision_id += UV3_HUB_REVISION_BASE ; <nl> break ; <nl> } <nl> 
i915_gem_object_get_pages_gtt ( struct drm_i915_gem_object * obj ) <nl>  <nl> page_count = obj -> base . size / PAGE_SIZE ; <nl> if ( sg_alloc_table ( st , page_count , GFP_KERNEL )) { <nl> - sg_free_table ( st ); <nl> kfree ( st ); <nl> return - ENOMEM ; <nl> }
static int rndis_wlan_bind ( struct usbnet * usbdev , struct usb_interface * intf ) <nl>  <nl> /* because rndis_command () sleeps we need to use workqueue */ <nl> priv -> workqueue = create_singlethread_workqueue (" rndis_wlan "); <nl> + if (! priv -> workqueue ) { <nl> + wiphy_free ( wiphy ); <nl> + return - ENOMEM ; <nl> + } <nl> INIT_WORK (& priv -> work , rndis_wlan_worker ); <nl> INIT_DELAYED_WORK (& priv -> dev_poller_work , rndis_device_poller ); <nl> INIT_DELAYED_WORK (& priv -> scan_work , rndis_get_scan_results );
static struct drm_driver tegra_drm_driver = { <nl> . debugfs_cleanup = tegra_debugfs_cleanup , <nl> # endif <nl>  <nl> - . gem_free_object = tegra_bo_free_object , <nl> + . gem_free_object_unlocked = tegra_bo_free_object , <nl> . gem_vm_ops = & tegra_bo_vm_ops , <nl>  <nl> . prime_handle_to_fd = drm_gem_prime_handle_to_fd ,
static void vnt_bss_info_changed ( struct ieee80211_hw * hw , <nl>  <nl> priv -> current_aid = conf -> aid ; <nl>  <nl> - if ( changed & BSS_CHANGED_BSSID ) { <nl> + if ( changed & BSS_CHANGED_BSSID && conf -> bssid ) { <nl> unsigned long flags ; <nl>  <nl> spin_lock_irqsave (& priv -> lock , flags );
static const struct key_entry eeepc_wmi_keymap [] = { <nl> { KE_KEY , 0xcc , { KEY_SWITCHVIDEOMODE } }, <nl> { KE_KEY , 0xe0 , { KEY_PROG1 } }, <nl> { KE_KEY , 0xe1 , { KEY_F14 } }, <nl> - { KE_KEY , 0xe9 , { KEY_DISPLAY_OFF } }, <nl> + { KE_KEY , 0xe9 , { KEY_BRIGHTNESS_ZERO } }, <nl> { KE_END , 0 }, <nl> }; <nl> 
late_initcall ( geneve_init_module ); <nl> static void __exit geneve_cleanup_module ( void ) <nl> { <nl> destroy_workqueue ( geneve_wq ); <nl> + unregister_pernet_subsys (& geneve_net_ops ); <nl> } <nl> module_exit ( geneve_cleanup_module ); <nl> 
static int bnx2x_get_hwinfo ( struct bnx2x * bp ) <nl> } else <nl> BNX2X_DEV_INFO (" illegal OV for SD \ n "); <nl> break ; <nl> + case SHARED_FEAT_CFG_FORCE_SF_MODE_FORCED_SF : <nl> + bp -> mf_config [ vn ] = 0 ; <nl> + break ; <nl> default : <nl> /* Unknown configuration : reset mf_config */ <nl> bp -> mf_config [ vn ] = 0 ;
get_more_pages : <nl> ci -> i_truncate_seq , <nl> ci -> i_truncate_size , <nl> & inode -> i_mtime , true , 1 , 0 ); <nl> + <nl> + if (! req ) { <nl> + rc = - ENOMEM ; <nl> + unlock_page ( page ); <nl> + break ; <nl> + } <nl> + <nl> max_pages = req -> r_num_pages ; <nl>  <nl> alloc_page_vec ( fsc , req );
static struct page * balloon_next_page ( struct page * page ) <nl>  <nl> static enum bp_state update_schedule ( enum bp_state state ) <nl> { <nl> + if ( state == BP_ECANCELED ) <nl> + return BP_ECANCELED ; <nl> + <nl> if ( state == BP_DONE ) { <nl> balloon_stats . schedule_delay = 1 ; <nl> balloon_stats . retry_count = 1 ;
ieee80211_tx_h_rate_ctrl ( struct ieee80211_tx_data * tx ) <nl> IEEE80211_TX_RC_USE_RTS_CTS ; <nl>  <nl> /* RC is busted */ <nl> - if ( WARN_ON ( info -> control . rates [ i ]. idx >= <nl> - sband -> n_bitrates )) { <nl> + if ( WARN_ON_ONCE ( info -> control . rates [ i ]. idx >= <nl> + sband -> n_bitrates )) { <nl> info -> control . rates [ i ]. idx = - 1 ; <nl> continue ; <nl> }
static void discard_cap_releases ( struct ceph_mds_client * mdsc , <nl> num = le32_to_cpu ( head -> num ); <nl> dout (" discard_cap_releases mds % d % p % u \ n ", session -> s_mds , msg , num ); <nl> head -> num = cpu_to_le32 ( 0 ); <nl> + msg -> front . iov_len = sizeof (* head ); <nl> session -> s_num_cap_releases += num ; <nl>  <nl> /* requeue completed messages */
static int ascot2e_write_regs ( struct ascot2e_priv * priv , <nl> } <nl> }; <nl>  <nl> - if ( len + 1 >= sizeof ( buf )) { <nl> + if ( len + 1 > sizeof ( buf )) { <nl> dev_warn (& priv -> i2c -> dev ," wr reg =% 04x : len =% d is too big !\ n ", <nl> reg , len + 1 ); <nl> return - E2BIG ;
int ll_fid2path ( struct inode * inode , void __user * arg ) <nl> if ( get_user ( pathlen , & gfin -> gf_pathlen )) <nl> return - EFAULT ; <nl>  <nl> + if ( pathlen > PATH_MAX ) <nl> + return - EINVAL ; <nl> + <nl> outsize = sizeof (* gfout ) + pathlen ; <nl>  <nl> OBD_ALLOC ( gfout , outsize );
static int tcp_ack_update_window ( struct sock * sk , struct tcp_sock * tp , <nl> /* Note , it is the only place , where <nl> * fast path is recovered for sending TCP . <nl> */ <nl> + tp -> pred_flags = 0 ; <nl> tcp_fast_path_check ( sk , tp ); <nl>  <nl> if ( nwin > tp -> max_window ) {
bool gw_out_of_range ( struct bat_priv * bat_priv , <nl> } <nl>  <nl> neigh_old = find_router ( bat_priv , orig_dst_node , NULL ); <nl> - if (!! neigh_old ) <nl> + if (! neigh_old ) <nl> goto out ; <nl>  <nl> if ( curr_tq_avg - neigh_old -> tq_avg > GW_THRESHOLD )
static int sil24_softreset ( struct ata_port * ap , unsigned int * class ) <nl> goto err ; <nl> } <nl>  <nl> - /* <nl> - * XXX : Not sure whether the following sleep is needed or not . <nl> - * The original driver had it . So .... <nl> - */ <nl> - msleep ( 10 ); <nl> - <nl> + /* do SRST */ <nl> prb -> ctrl = PRB_CTRL_SRST ; <nl> prb -> fis [ 1 ] = 0 ; /* no PM yet */ <nl> 
static void free_sa_defrag_extent ( struct new_sa_defrag_extent * new ) <nl> return ; <nl>  <nl> list_for_each_entry_safe ( old , tmp , & new -> head , list ) { <nl> - list_del (& old -> list ); <nl> kfree ( old ); <nl> } <nl> kfree ( new );
lpfc_els_retry ( struct lpfc_hba * phba , struct lpfc_iocbq * cmdiocb , <nl> /* FLOGI retry policy */ <nl> retry = 1 ; <nl> /* retry FLOGI forever */ <nl> - maxretry = 0 ; <nl> + if ( phba -> link_flag != LS_LOOPBACK_MODE ) <nl> + maxretry = 0 ; <nl> + else <nl> + maxretry = 2 ; <nl> + <nl> if ( cmdiocb -> retry >= 100 ) <nl> delay = 5000 ; <nl> else if ( cmdiocb -> retry >= 32 )
static bool gfar_add_rx_frag ( struct gfar_rx_buff * rxb , u32 lstatus , <nl> } <nl>  <nl> /* try reuse page */ <nl> - if ( unlikely ( page_count ( page ) != 1 )) <nl> + if ( unlikely ( page_count ( page ) != 1 || page_is_pfmemalloc ( page ))) <nl> return false ; <nl>  <nl> /* change offset to the other half */
static struct sk_buff * fill_packet_ipv4 ( struct net_device * odev , <nl> /* Eth + IPh + UDPh + mpls */ <nl> datalen = pkt_dev -> cur_pkt_size - 14 - 20 - 8 - <nl> pkt_dev -> pkt_overhead ; <nl> - if ( datalen < sizeof ( struct pktgen_hdr )) <nl> + if ( datalen < 0 || datalen < sizeof ( struct pktgen_hdr )) <nl> datalen = sizeof ( struct pktgen_hdr ); <nl>  <nl> udph -> source = htons ( pkt_dev -> cur_udp_src );
static int davinci_spi_setup_transfer ( struct spi_device * spi , <nl> struct davinci_spi * dspi ; <nl> struct davinci_spi_config * spicfg ; <nl> u8 bits_per_word = 0 ; <nl> - u32 hz = 0 , spifmt = 0 , prescale = 0 ; <nl> + u32 hz = 0 , spifmt = 0 ; <nl> + int prescale ; <nl>  <nl> dspi = spi_master_get_devdata ( spi -> master ); <nl> spicfg = ( struct davinci_spi_config *) spi -> controller_data ;
static ssize_t iio_ev_value_store ( struct device * dev , <nl> unsigned long val ; <nl> int ret ; <nl>  <nl> + if (! indio_dev -> info -> write_event_value ) <nl> + return - EINVAL ; <nl> + <nl> ret = strict_strtoul ( buf , 10 , & val ); <nl> if ( ret ) <nl> return ret ;
static int assign_guest_irq ( struct kvm * kvm , <nl> dev -> irq_requested_type |= guest_irq_type ; <nl> if ( dev -> ack_notifier . gsi != - 1 ) <nl> kvm_register_irq_ack_notifier ( kvm , & dev -> ack_notifier ); <nl> - } else <nl> + } else { <nl> kvm_free_irq_source_id ( kvm , dev -> irq_source_id ); <nl> + dev -> irq_source_id = - 1 ; <nl> + } <nl>  <nl> return r ; <nl> }
void snd_trident_write_voice_regs ( trident_t * trident , <nl> break ; <nl> default : <nl> snd_BUG (); <nl> + return ; <nl> } <nl>  <nl> outb ( voice -> number , TRID_REG ( trident , T4D_LFO_GC_CIR ));
static int get_cac_tdp_table ( <nl>  <nl> hwmgr -> dyn_state . cac_dtp_table = kzalloc ( table_size , GFP_KERNEL ); <nl>  <nl> - if ( NULL == hwmgr -> dyn_state . cac_dtp_table ) <nl> + if ( NULL == hwmgr -> dyn_state . cac_dtp_table ) { <nl> + kfree ( tdp_table ); <nl> return - ENOMEM ; <nl> + } <nl>  <nl> memset ( hwmgr -> dyn_state . cac_dtp_table , 0x00 , table_size ); <nl> 
static int smsc95xx_suspend ( struct usb_interface * intf , pm_message_t message ) <nl> ret = smsc95xx_enter_suspend0 ( dev ); <nl>  <nl> done : <nl> - if ( ret ) <nl> + /* <nl> + * TODO : resume () might need to handle the suspend failure <nl> + * in system sleep <nl> + */ <nl> + if ( ret && PMSG_IS_AUTO ( message )) <nl> usbnet_resume ( intf ); <nl> return ret ; <nl> }
static void sci_io_request_build_ssp_command_iu ( struct isci_request * ireq ) <nl> cmd_iu -> _r_c = 0 ; <nl>  <nl> sci_swab32_cpy (& cmd_iu -> cdb , task -> ssp_task . cmd -> cmnd , <nl> - task -> ssp_task . cmd -> cmd_len / sizeof ( u32 )); <nl> + ( task -> ssp_task . cmd -> cmd_len + 3 ) / sizeof ( u32 )); <nl> } <nl>  <nl> static void sci_task_request_build_ssp_task_iu ( struct isci_request * ireq )
int of_pci_range_to_resource ( struct of_pci_range * range , <nl> } <nl> res -> start = port ; <nl> } else { <nl> + if (( sizeof ( resource_size_t ) < 8 ) && <nl> + upper_32_bits ( range -> cpu_addr )) { <nl> + err = - EINVAL ; <nl> + goto invalid_range ; <nl> + } <nl> + <nl> res -> start = range -> cpu_addr ; <nl> } <nl> res -> end = res -> start + range -> size - 1 ;
static void pn_rx_complete ( struct usb_ep * ep , struct usb_request * req ) <nl> } <nl>  <nl> skb_add_rx_frag ( skb , skb_shinfo ( skb )-> nr_frags , page , <nl> - skb -> len == 0 , req -> actual ); <nl> + skb -> len <= 1 , req -> actual ); <nl> page = NULL ; <nl>  <nl> if ( req -> actual < req -> length ) { /* Last fragment */
static int uevent_net_init ( struct net * net ) <nl> if (! ue_sk -> sk ) { <nl> printk ( KERN_ERR <nl> " kobject_uevent : unable to create netlink socket !\ n "); <nl> + kfree ( ue_sk ); <nl> return - ENODEV ; <nl> } <nl> mutex_lock (& uevent_sock_mutex );
xfs_find_handle ( <nl> int hsize ; <nl> xfs_handle_t handle ; <nl> struct inode * inode ; <nl> - struct fd f ; <nl> + struct fd f = { 0 }; <nl> struct path path ; <nl> int error ; <nl> struct xfs_inode * ip ;
static int nsp_cs_config ( struct pcmcia_device * link ) <nl>  <nl> nsp_dbg ( NSP_DEBUG_INIT , " in "); <nl>  <nl> - cfg_mem = kzalloc ( sizeof ( cfg_mem ), GFP_KERNEL ); <nl> + cfg_mem = kzalloc ( sizeof (* cfg_mem ), GFP_KERNEL ); <nl> if (! cfg_mem ) <nl> return - ENOMEM ; <nl> cfg_mem -> data = data ;
static int __init camellia_aesni_init ( void ) <nl> { <nl> const char * feature_name ; <nl>  <nl> + if (! cpu_has_avx || ! cpu_has_aes || ! cpu_has_osxsave ) { <nl> + pr_info (" AVX or AES - NI instructions are not detected .\ n "); <nl> + return - ENODEV ; <nl> + } <nl> + <nl> if (! cpu_has_xfeatures ( XSTATE_SSE | XSTATE_YMM , & feature_name )) { <nl> pr_info (" CPU feature '% s ' is not supported .\ n ", feature_name ); <nl> return - ENODEV ;
static int rt5645_irq_detection ( struct rt5645_priv * rt5645 ) <nl> { <nl> int val , btn_type , gpio_state = 0 , report = 0 ; <nl>  <nl> + if (! rt5645 -> codec ) <nl> + return - EINVAL ; <nl> + <nl> switch ( rt5645 -> pdata . jd_mode ) { <nl> case 0 : /* Not using rt5645 JD */ <nl> if ( rt5645 -> gpiod_hp_det ) {
int irq_domain_simple_dt_translate ( struct irq_domain * d , <nl> return - EINVAL ; <nl> if ( intsize < 1 ) <nl> return - EINVAL ; <nl> + if ( d -> nr_irq && (( intspec [ 0 ] < d -> hwirq_base ) || <nl> + ( intspec [ 0 ] >= d -> hwirq_base + d -> nr_irq ))) <nl> + return - EINVAL ; <nl>  <nl> * out_hwirq = intspec [ 0 ]; <nl> * out_type = IRQ_TYPE_NONE ;
static void squashfs_put_super ( struct super_block * sb ) <nl> kfree ( sbi -> id_table ); <nl> kfree ( sbi -> fragment_index ); <nl> kfree ( sbi -> meta_index ); <nl> + kfree ( sbi -> inode_lookup_table ); <nl> kfree ( sb -> s_fs_info ); <nl> sb -> s_fs_info = NULL ; <nl> }
static bool is_zone_first_populated ( pg_data_t * pgdat , struct zone * zone ) <nl> return zone == compare ; <nl> } <nl>  <nl> - /* The zone must be somewhere ! */ <nl> - WARN_ON_ONCE ( 1 ); <nl> return false ; <nl> } <nl> 
int savagefb_probe_i2c_connector ( struct fb_info * info , u8 ** out_edid ) <nl> } <nl> } <nl>  <nl> - if ( out_edid ) <nl> - * out_edid = edid ; <nl> + * out_edid = edid ; <nl>  <nl> return ( edid ) ? 0 : 1 ; <nl> }
static void alc283_shutup ( struct hda_codec * codec ) <nl>  <nl> alc_write_coef_idx ( codec , 0x43 , 0x9004 ); <nl>  <nl> + /* depop hp during suspend */ <nl> + alc_write_coef_idx ( codec , 0x06 , 0x2100 ); <nl> + <nl> snd_hda_codec_write ( codec , hp_pin , 0 , <nl> AC_VERB_SET_AMP_GAIN_MUTE , AMP_OUT_MUTE ); <nl> 
static int ata_bus_probe ( struct ata_port * ap ) <nl>  <nl> /* reset */ <nl> if ( ap -> ops -> probe_reset ) { <nl> + for ( i = 0 ; i < ATA_MAX_DEVICES ; i ++) <nl> + classes [ i ] = ATA_DEV_UNKNOWN ; <nl> + <nl> rc = ap -> ops -> probe_reset ( ap , classes ); <nl> if ( rc ) { <nl> printk (" ata % u : reset failed ( errno =% d )\ n ", ap -> id , rc );
static u64 tg_prfill_cpu_rwstat ( struct seq_file * sf , <nl> struct blkg_rwstat rwstat = { }, tmp ; <nl> int i , cpu ; <nl>  <nl> + if ( tg -> stats_cpu == NULL ) <nl> + return 0 ; <nl> + <nl> for_each_possible_cpu ( cpu ) { <nl> struct tg_stats_cpu * sc = per_cpu_ptr ( tg -> stats_cpu , cpu ); <nl> 
static int proc_sys_readdir ( struct file * file , struct dir_context * ctx ) <nl> ctl_dir = container_of ( head , struct ctl_dir , header ); <nl>  <nl> if (! dir_emit_dots ( file , ctx )) <nl> - return 0 ; <nl> + goto out ; <nl>  <nl> pos = 2 ; <nl>  <nl> static int proc_sys_readdir ( struct file * file , struct dir_context * ctx ) <nl> break ; <nl> } <nl> } <nl> + out : <nl> sysctl_head_finish ( head ); <nl> return 0 ; <nl> }
static int record_connection ( char * host , char * port , char * busid , int rhport ) <nl> char buff [ MAX_BUFF + 1 ]; <nl> int ret ; <nl>  <nl> - mkdir ( VHCI_STATE_PATH , 0700 ); <nl> + ret = mkdir ( VHCI_STATE_PATH , 0700 ); <nl> + if ( ret < 0 ) <nl> + return - 1 ; <nl>  <nl> snprintf ( path , PATH_MAX , VHCI_STATE_PATH "/ port % d ", rhport ); <nl> 
static int i82875p_setup_overfl_dev ( struct pci_dev * pdev , <nl> "% s (): pci_bus_add_device () Failed \ n ", <nl> __func__ ); <nl> } <nl> + pci_bus_assign_resources ( dev -> bus ); <nl> } <nl>  <nl> * ovrfl_pdev = dev ;
static void e1000_set_rx_mode ( struct net_device * netdev ) <nl> e1000_rar_set ( hw , ha -> addr , i ++); <nl> } <nl>  <nl> - WARN_ON ( i == rar_entries ); <nl> - <nl> netdev_for_each_mc_addr ( ha , netdev ) { <nl> if ( i == rar_entries ) { <nl> /* load any remaining addresses into the hash table */
struct usb_sevsegdev { <nl> * if str commands are used , we would assume the end of string <nl> * so mem commands are used . <nl> */ <nl> - inline size_t my_memlen ( const char * buf , size_t count ) <nl> + static inline size_t my_memlen ( const char * buf , size_t count ) <nl> { <nl> if ( count > 0 && buf [ count - 1 ] == '\ n ') <nl> return count - 1 ;
extern int blk_iopoll_enabled ; <nl> static int sixty = 60 ; <nl> # endif <nl>  <nl> + static int neg_one = - 1 ; <nl> static int zero ; <nl> static int __maybe_unused one = 1 ; <nl> static int __maybe_unused two = 2 ;
static enum ucode_state request_microcode_fw ( int cpu , struct device * device ) <nl> return UCODE_NFOUND ; <nl> } <nl>  <nl> + if (*( u32 *) firmware -> data != UCODE_MAGIC ) { <nl> + printk ( KERN_ERR " microcode : invalid UCODE_MAGIC ( 0x % 08x )\ n ", <nl> + *( u32 *) firmware -> data ); <nl> + return UCODE_ERROR ; <nl> + } <nl> + <nl> ret = generic_load_microcode ( cpu , firmware -> data , firmware -> size ); <nl>  <nl> release_firmware ( firmware );
static struct platform_driver i2c_mux_reg_driver = { <nl> . remove = i2c_mux_reg_remove , <nl> . driver = { <nl> . name = " i2c - mux - reg ", <nl> + . of_match_table = of_match_ptr ( i2c_mux_reg_of_match ), <nl> }, <nl> }; <nl> 
int snd_soc_dapm_device_event ( struct snd_soc_device * socdev , int event ) <nl> struct snd_soc_machine * machine = socdev -> machine ; <nl>  <nl> if ( machine -> dapm_event ) <nl> - machine -> dapm_event ( machine , event ); <nl> + machine -> dapm_event ( machine , event ); <nl> if ( codec -> dapm_event ) <nl> - codec -> dapm_event ( codec , event ); <nl> + codec -> dapm_event ( codec , event ); <nl> return 0 ; <nl> } <nl> EXPORT_SYMBOL_GPL ( snd_soc_dapm_device_event );
retry : <nl> if ( local_flags & __GFP_WAIT ) <nl> local_irq_enable (); <nl> kmem_flagcheck ( cache , flags ); <nl> - obj = kmem_getpages ( cache , flags , - 1 ); <nl> + obj = kmem_getpages ( cache , local_flags , - 1 ); <nl> if ( local_flags & __GFP_WAIT ) <nl> local_irq_disable (); <nl> if ( obj ) {
struct usb_tt { <nl> struct usb_device * hub ; /* upstream highspeed hub */ <nl> int multi ; /* true means one TT per port */ <nl> unsigned think_time ; /* think time in ns */ <nl> + void * hcpriv ; /* HCD private data */ <nl>  <nl> /* for control / bulk error recovery ( CLEAR_TT_BUFFER ) */ <nl> spinlock_t lock ;
static int intel_backlight_device_update_status ( struct backlight_device * bd ) <nl> */ <nl> if ( panel -> backlight . enabled ) { <nl> if ( panel -> backlight_power ) { <nl> - bool enable = bd -> props . power == FB_BLANK_UNBLANK ; <nl> + bool enable = bd -> props . power == FB_BLANK_UNBLANK && <nl> + bd -> props . brightness != 0 ; <nl> panel -> backlight_power ( connector , enable ); <nl> } <nl> } else {
static void das16_interrupt ( struct comedi_device * dev ) <nl> cfc_write_array_to_buffer ( s , <nl> devpriv -> dma_buffer [ buffer_index ], num_bytes ); <nl>  <nl> - cfc_handle_events ( dev , s ); <nl> + comedi_handle_events ( dev , s ); <nl> } <nl>  <nl> static void das16_timer_interrupt ( unsigned long arg )
static int __devinit pmic8xxx_pwrkey_probe ( struct platform_device * pdev ) <nl> unsigned int delay ; <nl> u8 pon_cntl ; <nl> struct pmic8xxx_pwrkey * pwrkey ; <nl> - const struct pm8xxx_pwrkey_platform_data * pdata = mfd_get_data ( pdev ); <nl> + const struct pm8xxx_pwrkey_platform_data * pdata = <nl> + dev_get_platdata (& pdev -> dev ); <nl>  <nl> if (! pdata ) { <nl> dev_err (& pdev -> dev , " power key platform data not supplied \ n ");
static irqreturn_t ad7298_trigger_handler ( int irq , void * p ) <nl> struct iio_dev * indio_dev = pf -> indio_dev ; <nl> struct ad7298_state * st = iio_priv ( indio_dev ); <nl> struct iio_buffer * ring = indio_dev -> buffer ; <nl> - s64 time_ns ; <nl> + s64 time_ns = 0 ; <nl> __u16 buf [ 16 ]; <nl> int b_sent , i ; <nl> 
int trace_parser_get_init ( struct trace_parser * parser , int size ) <nl> void trace_parser_put ( struct trace_parser * parser ) <nl> { <nl> kfree ( parser -> buffer ); <nl> + parser -> buffer = NULL ; <nl> } <nl>  <nl> /*
struct comedi_device * comedi_open ( const char * filename ) <nl> if ( strncmp ( filename , "/ dev / comedi ", 11 ) != 0 ) <nl> return NULL ; <nl>  <nl> - minor = simple_strtoul ( filename + 11 , NULL , 0 ); <nl> + if ( kstrtouint ( filename + 11 , 0 , & minor )) <nl> + return NULL ; <nl>  <nl> if ( minor >= COMEDI_NUM_BOARD_MINORS ) <nl> return NULL ;
ipt_recent_checkentry ( const char * tablename , const void * ip , <nl> GFP_KERNEL ); <nl> if ( t == NULL ) <nl> goto out ; <nl> + t -> refcnt = 1 ; <nl> strcpy ( t -> name , info -> name ); <nl> INIT_LIST_HEAD (& t -> lru_list ); <nl> for ( i = 0 ; i < ip_list_hash_size ; i ++)
int ttm_bo_pipeline_move ( struct ttm_buffer_object * bo , <nl> */ <nl>  <nl> spin_lock (& from -> move_lock ); <nl> - if (! from -> move || fence_is_later ( from -> move , fence )) { <nl> + if (! from -> move || fence_is_later ( fence , from -> move )) { <nl> fence_put ( from -> move ); <nl> from -> move = fence_get ( fence ); <nl> }
* ( you will need to reboot afterwards ) */ <nl> /* # define BNX2X_STOP_ON_ERROR */ <nl>  <nl> -# define DRV_MODULE_VERSION " 1 . 72 . 10 - 0 " <nl> -# define DRV_MODULE_RELDATE " 2012 / 02 / 20 " <nl> +# define DRV_MODULE_VERSION " 1 . 72 . 17 - 0 " <nl> +# define DRV_MODULE_RELDATE " 2012 / 04 / 02 " <nl> # define BNX2X_BC_VER 0x040200 <nl>  <nl> # if defined ( CONFIG_DCB )
static void __init eva_init ( void ) <nl> platform_add_devices ( eva_devices , <nl> ARRAY_SIZE ( eva_devices )); <nl>  <nl> - eva_clock_init (); <nl> - <nl> rmobile_add_device_to_domain (" A4LC ", & lcdc0_device ); <nl> rmobile_add_device_to_domain (" A4LC ", & hdmi_lcdc_device ); <nl> if ( usb ) <nl> static void __init eva_earlytimer_init ( void ) <nl> { <nl> r8a7740_clock_init ( MD_CK0 | MD_CK2 ); <nl> shmobile_earlytimer_init (); <nl> + <nl> + /* the rate of extal1 clock must be set before late_time_init */ <nl> + eva_clock_init (); <nl> } <nl>  <nl> static void __init eva_add_early_devices ( void )
static ssize_t i40e_dbg_command_write ( struct file * filp , <nl> if (! cmd_buf ) <nl> return count ; <nl> bytes_not_copied = copy_from_user ( cmd_buf , buffer , count ); <nl> - if ( bytes_not_copied < 0 ) <nl> + if ( bytes_not_copied < 0 ) { <nl> + kfree ( cmd_buf ); <nl> return bytes_not_copied ; <nl> + } <nl> if ( bytes_not_copied > 0 ) <nl> count -= bytes_not_copied ; <nl> cmd_buf [ count ] = '\ 0 ';
static void bnx2x_tpa_stop ( struct bnx2x * bp , struct bnx2x_fastpath * fp , <nl>  <nl> return ; <nl> } <nl> - bnx2x_frag_free ( fp , new_data ); <nl> + if ( new_data ) <nl> + bnx2x_frag_free ( fp , new_data ); <nl> drop : <nl> /* drop the packet and keep the buffer in the bin */ <nl> DP ( NETIF_MSG_RX_STATUS ,
int snd_pcm_status ( struct snd_pcm_substream * substream , <nl> runtime -> status -> audio_tstamp ; <nl> goto _tstamp_end ; <nl> } <nl> + } else { <nl> + /* get tstamp only in fallback mode and only if enabled */ <nl> + if ( runtime -> tstamp_mode == SNDRV_PCM_TSTAMP_ENABLE ) <nl> + snd_pcm_gettime ( runtime , & status -> tstamp ); <nl> } <nl> - snd_pcm_gettime ( runtime , & status -> tstamp ); <nl> _tstamp_end : <nl> status -> appl_ptr = runtime -> control -> appl_ptr ; <nl> status -> hw_ptr = runtime -> status -> hw_ptr ;
void usbnet_skb_return ( struct usbnet * dev , struct sk_buff * skb ) <nl> return ; <nl> } <nl>  <nl> - skb -> protocol = eth_type_trans ( skb , dev -> net ); <nl> + /* only update if unset to allow minidriver rx_fixup override */ <nl> + if ( skb -> protocol == 0 ) <nl> + skb -> protocol = eth_type_trans ( skb , dev -> net ); <nl> + <nl> dev -> net -> stats . rx_packets ++; <nl> dev -> net -> stats . rx_bytes += skb -> len ; <nl> 
int iwl_mvm_mac_setup_register ( struct iwl_mvm * mvm ) <nl> ! iwlwifi_mod_params . sw_crypto ) <nl> hw -> flags |= IEEE80211_HW_MFP_CAPABLE ; <nl>  <nl> - if ( mvm -> fw -> ucode_capa . flags & IWL_UCODE_TLV_FLAGS_UAPSD_SUPPORT ) { <nl> + if ( 0 && mvm -> fw -> ucode_capa . flags & IWL_UCODE_TLV_FLAGS_UAPSD_SUPPORT ) { <nl> hw -> flags |= IEEE80211_HW_SUPPORTS_UAPSD ; <nl> hw -> uapsd_queues = IWL_UAPSD_AC_INFO ; <nl> hw -> uapsd_max_sp_len = IWL_UAPSD_MAX_SP ;
static const struct mfd_cell cros_devs [] = { <nl> . id = 2 , <nl> . of_compatible = " google , cros - ec - i2c - tunnel ", <nl> }, <nl> + { <nl> + . name = " cros - ec - ctl ", <nl> + . id = 3 , <nl> + }, <nl> }; <nl>  <nl> int cros_ec_register ( struct cros_ec_device * ec_dev )
SYSCALL_DEFINE2 ( getpriority , int , which , int , who ) <nl> if ( which > PRIO_USER || which < PRIO_PROCESS ) <nl> return - EINVAL ; <nl>  <nl> + rcu_read_lock (); <nl> read_lock (& tasklist_lock ); <nl> switch ( which ) { <nl> case PRIO_PROCESS : <nl> SYSCALL_DEFINE2 ( getpriority , int , which , int , who ) <nl> } <nl> out_unlock : <nl> read_unlock (& tasklist_lock ); <nl> + rcu_read_unlock (); <nl>  <nl> return retval ; <nl> }
static void mwifiex_unregister_dev ( struct mwifiex_adapter * adapter ) <nl> { <nl> struct pcie_service_card * card = adapter -> card ; <nl> const struct mwifiex_pcie_card_reg * reg ; <nl> - struct pci_dev * pdev = card -> dev ; <nl> + struct pci_dev * pdev ; <nl> int i ; <nl>  <nl> if ( card ) { <nl> + pdev = card -> dev ; <nl> if ( card -> msix_enable ) { <nl> for ( i = 0 ; i < MWIFIEX_NUM_MSIX_VECTORS ; i ++) <nl> synchronize_irq ( card -> msix_entries [ i ]. vector );
static struct clk * cp110_register_gate ( const char * name , <nl> if (! gate ) <nl> return ERR_PTR (- ENOMEM ); <nl>  <nl> + memset (& init , 0 , sizeof ( init )); <nl> + <nl> init . name = name ; <nl> init . ops = & cp110_gate_ops ; <nl> init . parent_names = & parent_name ;
int pl320_ipc_unregister_notifier ( struct notifier_block * nb ) <nl> } <nl> EXPORT_SYMBOL_GPL ( pl320_ipc_unregister_notifier ); <nl>  <nl> - static int __init pl320_probe ( struct amba_device * adev , <nl> - const struct amba_id * id ) <nl> + static int pl320_probe ( struct amba_device * adev , const struct amba_id * id ) <nl> { <nl> int ret ; <nl> 
static int intel_pstate_set_policy ( struct cpufreq_policy * policy ) <nl> if ( policy -> policy == CPUFREQ_POLICY_PERFORMANCE ) { <nl> limits . min_perf_pct = 100 ; <nl> limits . min_perf = int_tofp ( 1 ); <nl> + limits . max_policy_pct = 100 ; <nl> limits . max_perf_pct = 100 ; <nl> limits . max_perf = int_tofp ( 1 ); <nl> limits . no_turbo = limits . turbo_disabled ;
static int vmx_set_msr ( struct kvm_vcpu * vcpu , u32 msr_index , u64 data ) <nl> msr = find_msr_entry ( vcpu , msr_index ); <nl> if ( msr ) <nl> msr -> data = data ; <nl> - load_msrs ( vcpu -> guest_msrs , NR_BAD_MSRS ); <nl> + if ( vcpu -> vmx_host_state . loaded ) <nl> + load_msrs ( vcpu -> guest_msrs , NR_BAD_MSRS ); <nl> break ; <nl> # endif <nl> case MSR_IA32_SYSENTER_CS :
int drm_mode_page_flip_ioctl ( struct drm_device * dev , <nl> goto out ; <nl> crtc = obj_to_crtc ( obj ); <nl>  <nl> + if ( crtc -> fb == NULL ) { <nl> + /* The framebuffer is currently unbound , presumably <nl> + * due to a hotplug event , that userspace has not <nl> + * yet discovered . <nl> + */ <nl> + ret = - EBUSY ; <nl> + goto out ; <nl> + } <nl> + <nl> if ( crtc -> funcs -> page_flip == NULL ) <nl> goto out ; <nl> 
static void change ( char * dev , char * what , unsigned char * addr , <nl> " buffer \ n "); <nl>  <nl> pid = change_tramp ( argv , output , output_len ); <nl> - if ( pid < 0 ) return ; <nl> + if ( pid < 0 ) { <nl> + kfree ( output ); <nl> + return ; <nl> + } <nl>  <nl> if ( output != NULL ) { <nl> printk ("% s ", output );
void __kvm_migrate_pit_timer ( struct kvm_vcpu * vcpu ) <nl> return ; <nl>  <nl> timer = & pit -> pit_state . timer ; <nl> + mutex_lock (& pit -> pit_state . lock ); <nl> if ( hrtimer_cancel ( timer )) <nl> hrtimer_start_expires ( timer , HRTIMER_MODE_ABS ); <nl> + mutex_unlock (& pit -> pit_state . lock ); <nl> } <nl>  <nl> static void destroy_pit_timer ( struct kvm_pit * pit )
static int imx_es8328_dai_init ( struct snd_soc_pcm_runtime * rtd ) <nl>  <nl> /* Headphone jack detection */ <nl> if ( gpio_is_valid ( data -> jack_gpio )) { <nl> - ret = snd_soc_jack_new ( rtd -> codec , " Headphone ", <nl> - SND_JACK_HEADPHONE | SND_JACK_BTN_0 , <nl> - & headset_jack ); <nl> + ret = snd_soc_card_jack_new ( rtd -> card , " Headphone ", <nl> + SND_JACK_HEADPHONE | SND_JACK_BTN_0 , <nl> + & headset_jack , NULL , 0 ); <nl> if ( ret ) <nl> return ret ; <nl> 
get_pll_register ( struct drm_device * dev , enum pll_types type ) <nl> else { <nl> u8 * plim = & bios -> data [ bios -> pll_limit_tbl_ptr ]; <nl>  <nl> - if ( plim [ 0 ] >= 0x40 ) { <nl> + if ( plim [ 0 ] >= 0x30 ) { <nl> u8 * entry = plim + plim [ 1 ]; <nl> for ( i = 0 ; i < plim [ 3 ]; i ++, entry += plim [ 2 ]) { <nl> if ( entry [ 0 ] == type )
int map_groups__clone ( struct map_groups * mg , <nl> if ( new == NULL ) <nl> goto out_unlock ; <nl> map_groups__insert ( mg , new ); <nl> + map__put ( new ); <nl> } <nl>  <nl> err = 0 ;
int __init init_hw_breakpoint ( void ) <nl> err_alloc : <nl> for_each_possible_cpu ( err_cpu ) { <nl> for ( i = 0 ; i < TYPE_MAX ; i ++) <nl> - kfree ( per_cpu ( nr_task_bp_pinned [ i ], cpu )); <nl> + kfree ( per_cpu ( nr_task_bp_pinned [ i ], err_cpu )); <nl> if ( err_cpu == cpu ) <nl> break ; <nl> }
void exynos4_jpeg_set_enc_out_fmt ( void __iomem * base , unsigned int out_fmt ) <nl>  <nl> void exynos4_jpeg_set_interrupt ( void __iomem * base ) <nl> { <nl> - unsigned int reg ; <nl> - <nl> - reg = readl ( base + EXYNOS4_INT_EN_REG ) & ~ EXYNOS4_INT_EN_MASK ; <nl> writel ( EXYNOS4_INT_EN_ALL , base + EXYNOS4_INT_EN_REG ); <nl> } <nl> 
static void sta_ps_start ( struct sta_info * sta ) <nl> for ( tid = 0 ; tid < ARRAY_SIZE ( sta -> sta . txq ); tid ++) { <nl> struct txq_info * txqi = to_txq_info ( sta -> sta . txq [ tid ]); <nl>  <nl> - if (! txqi -> tin . backlog_packets ) <nl> + if ( txqi -> tin . backlog_packets ) <nl> set_bit ( tid , & sta -> txq_buffered_tids ); <nl> else <nl> clear_bit ( tid , & sta -> txq_buffered_tids );
static int __devinit virtcons_probe ( struct virtio_device * dev ) <nl> struct virtqueue * vqs [ 2 ]; <nl> int err ; <nl>  <nl> + if ( vdev ) { <nl> + dev_warn (& vdev -> dev , <nl> + " Multiple virtio - console devices not supported yet \ n "); <nl> + return - EEXIST ; <nl> + } <nl> vdev = dev ; <nl>  <nl> /* This is the scratch page we use to receive console input */
try_mount_again : <nl>  <nl> remote_path_check : <nl> /* check if a whole path ( including prepath ) is not remote */ <nl> - if (! rc && cifs_sb -> prepathlen && tcon ) { <nl> + if (! rc && tcon ) { <nl> /* build_path_to_root works only when we have a valid tcon */ <nl> full_path = cifs_build_path_to_root ( cifs_sb , tcon ); <nl> if ( full_path == NULL ) {
static int __inject_sigp_stop ( struct kvm_s390_local_interrupt * li , int action ) <nl> inti -> type = KVM_S390_SIGP_STOP ; <nl>  <nl> spin_lock_bh (& li -> lock ); <nl> - if (( atomic_read ( li -> cpuflags ) & CPUSTAT_STOPPED )) <nl> + if (( atomic_read ( li -> cpuflags ) & CPUSTAT_STOPPED )) { <nl> + kfree ( inti ); <nl> goto out ; <nl> + } <nl> list_add_tail (& inti -> list , & li -> list ); <nl> atomic_set (& li -> active , 1 ); <nl> atomic_set_mask ( CPUSTAT_STOP_INT , li -> cpuflags );
static int cciss_bigpassthru ( ctlr_info_t * h , void __user * argp ) <nl> return - EINVAL ; <nl> if (! capable ( CAP_SYS_RAWIO )) <nl> return - EPERM ; <nl> - ioc = ( BIG_IOCTL_Command_struct *) <nl> - kmalloc ( sizeof (* ioc ), GFP_KERNEL ); <nl> + ioc = kmalloc ( sizeof (* ioc ), GFP_KERNEL ); <nl> if (! ioc ) { <nl> status = - ENOMEM ; <nl> goto cleanup1 ;
void flush_dcache_page ( struct page * page ) <nl> } <nl> EXPORT_SYMBOL ( flush_dcache_page ); <nl>  <nl> + void flush_kernel_dcache_page ( struct page * page ) <nl> +{ <nl> + __cpuc_flush_dcache_area ( page_address ( page ), PAGE_SIZE ); <nl> +} <nl> + EXPORT_SYMBOL ( flush_kernel_dcache_page ); <nl> + <nl> void copy_to_user_page ( struct vm_area_struct * vma , struct page * page , <nl> unsigned long uaddr , void * dst , const void * src , <nl> unsigned long len )
fill_write_buffer ( struct sysfs_buffer * buffer , const char __user * buf , size_t <nl> count = PAGE_SIZE - 1 ; <nl> error = copy_from_user ( buffer -> page , buf , count ); <nl> buffer -> needs_read_fill = 1 ; <nl> + /* if buf is assumed to contain a string , terminate it by \ 0 , <nl> + so e . g . sscanf () can scan the string easily */ <nl> + buffer -> page [ count ] = 0 ; <nl> return error ? - EFAULT : count ; <nl> } <nl> 
static sint _init_mlme_priv ( struct _adapter * padapter ) <nl> _init_queue (&( pmlmepriv -> scanned_queue )); <nl> set_scanned_network_val ( pmlmepriv , 0 ); <nl> memset (& pmlmepriv -> assoc_ssid , 0 , sizeof ( struct ndis_802_11_ssid )); <nl> - pbuf = kmalloc ( MAX_BSS_CNT * ( sizeof ( struct wlan_network )), <nl> - GFP_ATOMIC ); <nl> + pbuf = kmalloc_array ( MAX_BSS_CNT , sizeof ( struct wlan_network ), <nl> + GFP_ATOMIC ); <nl> if ( pbuf == NULL ) <nl> return _FAIL ; <nl> pmlmepriv -> free_bss_buf = pbuf ;
int tipc_nl_add_monitor_peer ( struct net * net , struct tipc_nl_msg * msg , <nl> u32 bearer_id , u32 * prev_node ) <nl> { <nl> struct tipc_monitor * mon = tipc_monitor ( net , bearer_id ); <nl> - struct tipc_peer * peer = mon -> self ; <nl> + struct tipc_peer * peer ; <nl>  <nl> if (! mon ) <nl> return - EINVAL ; <nl>  <nl> read_lock_bh (& mon -> lock ); <nl> + peer = mon -> self ; <nl> do { <nl> if (* prev_node ) { <nl> if ( peer -> addr == * prev_node )
void sync_timeline_signal ( struct sync_timeline * obj ) <nl> list_for_each_entry_safe ( pt , next , & obj -> active_list_head , <nl> active_list ) { <nl> if ( fence_is_signaled_locked (& pt -> base )) <nl> - list_del (& pt -> active_list ); <nl> + list_del_init (& pt -> active_list ); <nl> } <nl>  <nl> spin_unlock_irqrestore (& obj -> child_list_lock , flags );
static int orinoco_ioctl_set_auth ( struct net_device * dev , <nl> */ <nl> if ( param -> value ) { <nl> priv -> tkip_cm_active = 1 ; <nl> - ret = hermes_enable_port ( hw , 0 ); <nl> + ret = hermes_disable_port ( hw , 0 ); <nl> } else { <nl> priv -> tkip_cm_active = 0 ; <nl> - ret = hermes_disable_port ( hw , 0 ); <nl> + ret = hermes_enable_port ( hw , 0 ); <nl> } <nl> break ; <nl> 
void vmbus_close ( struct vmbus_channel * channel ) <nl> free_channel ( channel ); <nl> } <nl> } <nl> + EXPORT_SYMBOL_GPL ( vmbus_close ); <nl>  <nl> /** <nl> * vmbus_sendpacket () - Send the specified buffer on the given channel
static void blk_stat_flush_batch ( struct blk_rq_stat * stat ) <nl>  <nl> static void blk_stat_sum ( struct blk_rq_stat * dst , struct blk_rq_stat * src ) <nl> { <nl> + blk_stat_flush_batch ( src ); <nl> + <nl> if (! src -> nr_samples ) <nl> return ; <nl>  <nl> - blk_stat_flush_batch ( src ); <nl> - <nl> dst -> min = min ( dst -> min , src -> min ); <nl> dst -> max = max ( dst -> max , src -> max ); <nl> 
static int fill_buffer ( struct debug_buffer * buf ) <nl> int ret = 0 ; <nl>  <nl> if (! buf -> output_buf ) <nl> - buf -> output_buf = ( char *) vmalloc ( buf -> alloc_size ); <nl> + buf -> output_buf = vmalloc ( buf -> alloc_size ); <nl>  <nl> if (! buf -> output_buf ) { <nl> ret = - ENOMEM ;
static int __init ubi_mtd_param_parse ( const char * val , struct kernel_param * kp ) <nl> char * pbuf = & buf [ 0 ]; <nl> char * tokens [ 3 ] = { NULL , NULL , NULL }; <nl>  <nl> + if (! val ) <nl> + return - EINVAL ; <nl> + <nl> if ( mtd_devs == UBI_MAX_DEVICES ) { <nl> printk (" UBI error : too many parameters , max . is % d \ n ", <nl> UBI_MAX_DEVICES );
static int hdsp_dds_offset ( struct hdsp * hdsp ) <nl> unsigned int dds_value = hdsp -> dds_value ; <nl> int system_sample_rate = hdsp -> system_sample_rate ; <nl>  <nl> + if (! dds_value ) <nl> + return 0 ; <nl> + <nl> n = DDS_NUMERATOR ; <nl> /* <nl> * dds_value = n / rate
static int s3c2440_nand_calculate_ecc ( struct mtd_info * mtd , const u_char * dat , u <nl> ecc_code [ 1 ] = ecc >> 8 ; <nl> ecc_code [ 2 ] = ecc >> 16 ; <nl>  <nl> - pr_debug ("% s : returning ecc % 06x \ n ", __func__ , ecc ); <nl> + pr_debug ("% s : returning ecc % 06lx \ n ", __func__ , ecc ); <nl>  <nl> return 0 ; <nl> }
static void s6000_pcm_enqueue_dma ( struct snd_pcm_substream * substream ) <nl> return ; <nl> } <nl>  <nl> - BUG_ON ( period_size & 15 ); <nl> + if ( WARN_ON ( period_size & 15 )) <nl> + return ; <nl> s6dmac_put_fifo ( DMA_MASK_DMAC ( channel ), DMA_INDEX_CHNL ( channel ), <nl> src , dst , period_size ); <nl> 
int rxrpc_kernel_send_data ( struct socket * sock , struct rxrpc_call * call , <nl> ret = rxrpc_send_data ( rxrpc_sk ( sock -> sk ), call , msg , len ); <nl> break ; <nl> case RXRPC_CALL_COMPLETE : <nl> - /* It ' s too late for this call */ <nl> - ret = - ESHUTDOWN ; <nl> + read_lock_bh (& call -> state_lock ); <nl> + ret = - call -> error ; <nl> + read_unlock_bh (& call -> state_lock ); <nl> break ; <nl> default : <nl> /* Request phase complete for this client call */
# include < libunwind . h > <nl> # include " perf_regs . h " <nl> # include "../../ util / unwind . h " <nl> +# include "../../ util / debug . h " <nl>  <nl> int libunwind__arch_reg_id ( int regnum ) <nl> {
of_at91_clk_master_setup ( struct device_node * np , struct at91_pmc * pmc , <nl>  <nl> irq = irq_of_parse_and_map ( np , 0 ); <nl> if (! irq ) <nl> - return ; <nl> + goto out_free_characteristics ; <nl>  <nl> clk = at91_clk_register_master ( pmc , irq , name , num_parents , <nl> parent_names , layout ,
err1 : <nl>  <nl> static void treo680_irda_shutdown ( struct device * dev ) <nl> { <nl> - gpio_free ( GPIO_NR_TREO680_AMP_EN ); <nl> + gpio_free ( GPIO_NR_TREO680_IR_EN ); <nl> } <nl>  <nl> static struct pxaficp_platform_data treo680_ficp_info = {
unsigned long do_mremap ( unsigned long addr , <nl> map_flags |= MAP_SHARED ; <nl>  <nl> new_addr = get_unmapped_area ( vma -> vm_file , 0 , new_len , <nl> - vma -> vm_pgoff , map_flags ); <nl> + vma -> vm_pgoff + <nl> + (( addr - vma -> vm_start ) >> PAGE_SHIFT ), <nl> + map_flags ); <nl> if ( new_addr & ~ PAGE_MASK ) { <nl> ret = new_addr ; <nl> goto out ;
static int ixgbe_ndo_fdb_add ( struct ndmsg * ndm , struct nlattr * tb [], <nl> { <nl> /* guarantee we can provide a unique filter for the unicast address */ <nl> if ( is_unicast_ether_addr ( addr ) || is_link_local_ether_addr ( addr )) { <nl> - if ( IXGBE_MAX_PF_MACVLANS <= netdev_uc_count ( dev )) <nl> + struct ixgbe_adapter * adapter = netdev_priv ( dev ); <nl> + u16 pool = VMDQ_P ( 0 ); <nl> + <nl> + if ( netdev_uc_count ( dev ) >= ixgbe_available_rars ( adapter , pool )) <nl> return - ENOMEM ; <nl> } <nl> 
# define OP_31_XOP_SLBIA 498 <nl> # define OP_31_XOP_MFSR 595 <nl> # define OP_31_XOP_MFSRIN 659 <nl> +# define OP_31_XOP_DCBA 758 <nl> # define OP_31_XOP_SLBMFEV 851 <nl> # define OP_31_XOP_EIOIO 854 <nl> # define OP_31_XOP_SLBMFEE 915 <nl> int kvmppc_core_emulate_op ( struct kvm_run * run , struct kvm_vcpu * vcpu , <nl> kvmppc_set_gpr ( vcpu , get_rt ( inst ), t ); <nl> } <nl> break ; <nl> + case OP_31_XOP_DCBA : <nl> + /* Gets treated as NOP */ <nl> + break ; <nl> case OP_31_XOP_DCBZ : <nl> { <nl> ulong rb = kvmppc_get_gpr ( vcpu , get_rb ( inst ));
int cgroup_path ( const struct cgroup * cgrp , char * buf , int buflen ) <nl> return 0 ; <nl> } <nl>  <nl> - start = buf + buflen ; <nl> + start = buf + buflen - 1 ; <nl>  <nl> - *-- start = '\ 0 '; <nl> + * start = '\ 0 '; <nl> for (;;) { <nl> int len = dentry -> d_name . len ; <nl> 
static int addrconf_notify ( struct notifier_block * this , unsigned long event , <nl> if ( dev -> flags & IFF_SLAVE ) <nl> break ; <nl>  <nl> + if ( idev && idev -> cnf . disable_ipv6 ) <nl> + break ; <nl> + <nl> if ( event == NETDEV_UP ) { <nl> if (! addrconf_qdisc_ok ( dev )) { <nl> /* device is not ready yet . */
void __init tcp_tasklet_init ( void ) <nl> * We cant xmit new skbs from this context , as we might already <nl> * hold qdisc lock . <nl> */ <nl> - void tcp_wfree ( struct sk_buff * skb ) <nl> + static void tcp_wfree ( struct sk_buff * skb ) <nl> { <nl> struct sock * sk = skb -> sk ; <nl> struct tcp_sock * tp = tcp_sk ( sk );
static struct neighbour * fake_neigh_lookup ( const struct dst_entry * dst , const vo <nl> return NULL ; <nl> } <nl>  <nl> + static unsigned int fake_mtu ( const struct dst_entry * dst ) <nl> +{ <nl> + return dst -> dev -> mtu ; <nl> +} <nl> + <nl> static struct dst_ops fake_dst_ops = { <nl> . family = AF_INET , <nl> . protocol = cpu_to_be16 ( ETH_P_IP ), <nl> . update_pmtu = fake_update_pmtu , <nl> . cow_metrics = fake_cow_metrics , <nl> . neigh_lookup = fake_neigh_lookup , <nl> + . mtu = fake_mtu , <nl> }; <nl>  <nl> /*
static int __init pasic3_probe ( struct platform_device * pdev ) <nl> } <nl>  <nl> if ( pdata && pdata -> led_pdata ) { <nl> + led_cell . platform_data = pdata -> led_pdata ; <nl> + led_cell . pdata_size = sizeof ( struct pasic3_leds_machinfo ); <nl> ret = mfd_add_devices (& pdev -> dev , pdev -> id , & led_cell , 1 , r , 0 ); <nl> if ( ret < 0 ) <nl> dev_warn ( dev , " failed to register LED device \ n ");
int symbol__init ( void ) <nl> if ( symbol_conf . initialized ) <nl> return 0 ; <nl>  <nl> + symbol_conf . priv_size = ALIGN ( symbol_conf . priv_size , sizeof ( u64 )); <nl> + <nl> elf_version ( EV_CURRENT ); <nl> if ( symbol_conf . sort_by_name ) <nl> symbol_conf . priv_size += ( sizeof ( struct symbol_name_rb_node ) -
struct vpif_disp_buffer { <nl> }; <nl>  <nl> struct common_obj { <nl> - /* Buffer specific parameters */ <nl> - u8 * fbuffers [ VIDEO_MAX_FRAME ]; /* List of buffer pointers for <nl> - * storing frames */ <nl> u32 numbuffers ; /* number of buffers */ <nl> struct vpif_disp_buffer * cur_frm ; /* Pointer pointing to current <nl> * vb2_buffer */
static int s5h1420_send_master_cmd ( struct dvb_frontend * fe , <nl> int result = 0 ; <nl>  <nl> dprintk (" enter % s \ n ", __func__ ); <nl> - if ( cmd -> msg_len > 8 ) <nl> + if ( cmd -> msg_len > sizeof ( cmd -> msg )) <nl> return - EINVAL ; <nl>  <nl> /* setup for DISEQC */
static struct dma_async_tx_descriptor * edma_prep_slave_sg ( <nl> edma_alloc_slot ( EDMA_CTLR ( echan -> ch_num ), <nl> EDMA_SLOT_ANY ); <nl> if ( echan -> slot [ i ] < 0 ) { <nl> + kfree ( edesc ); <nl> dev_err ( dev , " Failed to allocate slot \ n "); <nl> kfree ( edesc ); <nl> return NULL ;
static const struct ethtool_ops dnet_ethtool_ops = { <nl> . set_settings = dnet_set_settings , <nl> . get_drvinfo = dnet_get_drvinfo , <nl> . get_link = ethtool_op_get_link , <nl> + . get_ts_info = ethtool_op_get_ts_info , <nl> }; <nl>  <nl> static const struct net_device_ops dnet_netdev_ops = {
static noinline void init_btrfs_i ( struct inode * inode ) <nl> bi -> flags = 0 ; <nl> bi -> index_cnt = ( u64 )- 1 ; <nl> bi -> last_unlink_trans = 0 ; <nl> + bi -> ordered_data_close = 0 ; <nl> extent_map_tree_init (& BTRFS_I ( inode )-> extent_tree , GFP_NOFS ); <nl> extent_io_tree_init (& BTRFS_I ( inode )-> io_tree , <nl> inode -> i_mapping , GFP_NOFS );
static int bcm2835_sdhci_probe ( struct platform_device * pdev ) <nl> goto err ; <nl> } <nl>  <nl> - return sdhci_add_host ( host ); <nl> + ret = sdhci_add_host ( host ); <nl> + if ( ret ) <nl> + goto err ; <nl>  <nl> + return 0 ; <nl> err : <nl> sdhci_pltfm_free ( pdev ); <nl> return ret ;
static int b43_wireless_core_init ( struct b43_wldev * dev ) <nl> b43_set_phytxctl_defaults ( dev ); <nl>  <nl> /* Minimum Contention Window */ <nl> - if ( phy -> type == B43_PHYTYPE_B ) { <nl> + if ( phy -> type == B43_PHYTYPE_B ) <nl> b43_shm_write16 ( dev , B43_SHM_SCRATCH , B43_SHM_SC_MINCONT , 0x1F ); <nl> - } else { <nl> + else <nl> b43_shm_write16 ( dev , B43_SHM_SCRATCH , B43_SHM_SC_MINCONT , 0xF ); <nl> - } <nl> /* Maximum Contention Window */ <nl> b43_shm_write16 ( dev , B43_SHM_SCRATCH , B43_SHM_SC_MAXCONT , 0x3FF ); <nl> 
static long intel_vgpu_ioctl ( struct mdev_device * mdev , unsigned int cmd , <nl> sparse -> areas [ 0 ]. offset = <nl> PAGE_ALIGN ( vgpu_aperture_offset ( vgpu )); <nl> sparse -> areas [ 0 ]. size = vgpu_aperture_sz ( vgpu ); <nl> - if (! caps . buf ) { <nl> - kfree ( caps . buf ); <nl> - caps . buf = NULL ; <nl> - caps . size = 0 ; <nl> - } <nl> break ; <nl>  <nl> case VFIO_PCI_BAR3_REGION_INDEX ... VFIO_PCI_BAR5_REGION_INDEX :
static int falcon_mtd_probe ( struct efx_nic * efx ) <nl>  <nl> /* Allocate space for maximum number of partitions */ <nl> parts = kcalloc ( 2 , sizeof (* parts ), GFP_KERNEL ); <nl> + if (! parts ) <nl> + return - ENOMEM ; <nl> n_parts = 0 ; <nl>  <nl> spi = & nic_data -> spi_flash ;
static int set_multi_io ( struct hda_codec * codec , int idx , bool output ) <nl> snd_hda_activate_path ( codec , path , false , true ); <nl> set_pin_target ( codec , nid , spec -> multi_io [ idx ]. ctl_in , true ); <nl> } <nl> + <nl> + /* update jack retasking in case it modifies any of them */ <nl> + snd_hda_gen_hp_automute ( codec , NULL ); <nl> + snd_hda_gen_line_automute ( codec , NULL ); <nl> + snd_hda_gen_mic_autoswitch ( codec , NULL ); <nl> + <nl> return 0 ; <nl> } <nl> 
void __iomem * __arm_ioremap_pfn_caller ( unsigned long pfn , <nl> if (! area ) <nl> return NULL ; <nl> addr = ( unsigned long ) area -> addr ; <nl> + area -> phys_addr = __pfn_to_phys ( pfn ); <nl>  <nl> # if ! defined ( CONFIG_SMP ) && ! defined ( CONFIG_ARM_LPAE ) <nl> if ( DOMAIN_IO == 0 &&
static int coredump_wait ( int exit_code , struct core_state * core_state ) <nl> core_state -> dumper . task = tsk ; <nl> core_state -> dumper . next = NULL ; <nl>  <nl> - down_write (& mm -> mmap_sem ); <nl> + if ( down_write_killable (& mm -> mmap_sem )) <nl> + return - EINTR ; <nl> + <nl> if (! mm -> core_state ) <nl> core_waiters = zap_threads ( tsk , mm , core_state , exit_code ); <nl> up_write (& mm -> mmap_sem );
static long pnv_pci_ioda2_table_alloc_pages ( int nid , __u64 bus_offset , <nl> level_shift = entries_shift + 3 ; <nl> level_shift = max_t ( unsigned , level_shift , PAGE_SHIFT ); <nl>  <nl> + if (( level_shift - 3 ) * levels + page_shift >= 60 ) <nl> + return - EINVAL ; <nl> + <nl> /* Allocate TCE table */ <nl> addr = pnv_pci_ioda2_table_do_alloc_pages ( nid , level_shift , <nl> levels , tce_table_size , & offset , & total_allocated );
static void tcp_reinit_congestion_control ( struct sock * sk , <nl> icsk -> icsk_ca_ops = ca ; <nl> icsk -> icsk_ca_setsockopt = 1 ; <nl>  <nl> - if ( sk -> sk_state != TCP_CLOSE ) <nl> + if ( sk -> sk_state != TCP_CLOSE ) { <nl> + memset ( icsk -> icsk_ca_priv , 0 , sizeof ( icsk -> icsk_ca_priv )); <nl> tcp_init_congestion_control ( sk ); <nl> + } <nl> } <nl>  <nl> /* Manage refcounts on socket close . */
static int __ext4_ext_check ( const char * function , unsigned int line , <nl> error_msg = " invalid extent entries "; <nl> goto corrupted ; <nl> } <nl> + if ( unlikely ( depth > 32 )) { <nl> + error_msg = " too large eh_depth "; <nl> + goto corrupted ; <nl> + } <nl> /* Verify checksum on non - root extent tree nodes */ <nl> if ( ext_depth ( inode ) != depth && <nl> ! ext4_extent_block_csum_verify ( inode , eh )) {
static int __devinit dwc3_omap_probe ( struct platform_device * pdev ) <nl> } <nl>  <nl> /* enable all IRQs */ <nl> - dwc3_writel ( omap -> base , USBOTGSS_IRQENABLE_SET_0 , 0x01 ); <nl> + reg = USBOTGSS_IRQO_COREIRQ_ST ; <nl> + dwc3_writel ( omap -> base , USBOTGSS_IRQENABLE_SET_0 , reg ); <nl>  <nl> reg = ( USBOTGSS_IRQ1_OEVT | <nl> USBOTGSS_IRQ1_DRVVBUS_RISE |
static int asoc_simple_card_dai_link_of ( struct device_node * node , <nl> strlen ( dai_link -> cpu_dai_name ) + <nl> strlen ( dai_link -> codec_dai_name ) + 2 , <nl> GFP_KERNEL ); <nl> + if (! name ) { <nl> + ret = - ENOMEM ; <nl> + goto dai_link_of_err ; <nl> + } <nl> + <nl> sprintf ( name , "% s -% s ", dai_link -> cpu_dai_name , <nl> dai_link -> codec_dai_name ); <nl> dai_link -> name = dai_link -> stream_name = name ;
static int dpcm_add_paths ( struct snd_soc_pcm_runtime * fe , int stream , <nl>  <nl> switch ( list -> widgets [ i ]-> id ) { <nl> case snd_soc_dapm_dai_in : <nl> + if ( stream != SNDRV_PCM_STREAM_PLAYBACK ) <nl> + continue ; <nl> + break ; <nl> case snd_soc_dapm_dai_out : <nl> + if ( stream != SNDRV_PCM_STREAM_CAPTURE ) <nl> + continue ; <nl> break ; <nl> default : <nl> continue ;
static void usb_hcd_ppc_soc_remove ( struct usb_hcd * hcd , <nl>  <nl> iounmap ( hcd -> regs ); <nl> release_mem_region ( hcd -> rsrc_start , hcd -> rsrc_len ); <nl> - usb_hcd_put ( hcd ); <nl> + usb_put_hcd ( hcd ); <nl> } <nl>  <nl> static int __devinit
static void atl1_free_ring_resources ( struct atl1_adapter * adapter ) <nl>  <nl> rrd_ring -> desc = NULL ; <nl> rrd_ring -> dma = 0 ; <nl> + <nl> + adapter -> cmb . dma = 0 ; <nl> + adapter -> cmb . cmb = NULL ; <nl> + <nl> + adapter -> smb . dma = 0 ; <nl> + adapter -> smb . smb = NULL ; <nl> } <nl>  <nl> static void atl1_setup_mac_ctrl ( struct atl1_adapter * adapter )
hauppauge_tuner [] = <nl> { TUNER_ABSENT , " MaxLinear 301 "}, <nl> { TUNER_ABSENT , " Mirics MSi001 "}, <nl> { TUNER_ABSENT , " MaxLinear MxL241SF "}, <nl> - { TUNER_ABSENT , " Xceive XC5000C "}, <nl> + { TUNER_XC5000C , " Xceive XC5000C "}, <nl> { TUNER_ABSENT , " Montage M68TS2020 "}, <nl> }; <nl> 
static int stmmac_rx ( struct stmmac_priv * priv , int limit ) <nl>  <nl> frame_len = priv -> hw -> desc -> get_rx_frame_len ( p , coe ); <nl>  <nl> + /* check if frame_len fits the preallocated memory */ <nl> + if ( frame_len > priv -> dma_buf_sz ) { <nl> + priv -> dev -> stats . rx_length_errors ++; <nl> + break ; <nl> + } <nl> + <nl> /* ACS is set ; GMAC core strips PAD / FCS for IEEE 802 . 3 <nl> * Type frames ( LLC / LLC - SNAP ) <nl> */
u32 __tcp_select_window ( struct sock * sk ) <nl> int full_space = min_t ( int , tp -> window_clamp , allowed_space ); <nl> int window ; <nl>  <nl> - if ( mss > full_space ) <nl> + if ( unlikely ( mss > full_space )) { <nl> mss = full_space ; <nl> - <nl> + if ( mss <= 0 ) <nl> + return 0 ; <nl> + } <nl> if ( free_space < ( full_space >> 1 )) { <nl> icsk -> icsk_ack . quick = 0 ; <nl> 
static void passdown_endio ( struct bio * bio ) <nl> * to unmap ( we ignore err ). <nl> */ <nl> queue_passdown_pt2 ( bio -> bi_private ); <nl> + bio_put ( bio ); <nl> } <nl>  <nl> static void process_prepared_discard_passdown_pt1 ( struct dm_thin_new_mapping * m )
static int onenand_write_ops_nolock ( struct mtd_info * mtd , loff_t to , <nl> } <nl>  <nl> /* Only check verify write turn on */ <nl> - ret = onenand_verify ( mtd , ( u_char *) wbuf , to , thislen ); <nl> + ret = onenand_verify ( mtd , buf , to , thislen ); <nl> if ( ret ) { <nl> printk ( KERN_ERR " onenand_write_ops_nolock : verify failed % d \ n ", ret ); <nl> break ;
static void si_apply_state_adjust_rules ( struct radeon_device * rdev , <nl> max_sclk = 75000 ; <nl> max_mclk = 80000 ; <nl> } <nl> + /* limit clocks on HD8600 series */ <nl> + if ( rdev -> pdev -> device == 0x6660 && <nl> + rdev -> pdev -> revision == 0x83 ) { <nl> + max_sclk = 75000 ; <nl> + max_mclk = 80000 ; <nl> + } <nl>  <nl> if ( rps -> vce_active ) { <nl> rps -> evclk = rdev -> pm . dpm . vce_states [ rdev -> pm . dpm . vce_level ]. evclk ;
SYSCALL_DEFINE2 ( delete_module , const char __user *, name_user , <nl> return - EFAULT ; <nl> name [ MODULE_NAME_LEN - 1 ] = '\ 0 '; <nl>  <nl> + audit_log_kern_module ( name ); <nl> + <nl> if ( mutex_lock_interruptible (& module_mutex ) != 0 ) <nl> return - EINTR ; <nl> 
static int menu_select ( struct cpuidle_driver * drv , struct cpuidle_device * dev ) <nl> * We want to default to C1 ( hlt ), not to busy polling <nl> * unless the timer is happening really really soon . <nl> */ <nl> - if ( data -> next_timer_us > 20 && <nl> + if ( interactivity_req > 20 && <nl> ! drv -> states [ CPUIDLE_DRIVER_STATE_START ]. disabled && <nl> dev -> states_usage [ CPUIDLE_DRIVER_STATE_START ]. disable == 0 ) <nl> data -> last_state_idx = CPUIDLE_DRIVER_STATE_START ;
static void xhci_pci_quirks ( struct device * dev , struct xhci_hcd * xhci ) <nl> xhci -> quirks |= XHCI_RESET_ON_RESUME ; <nl> xhci_dbg ( xhci , " QUIRK : Resetting on resume \ n "); <nl> } <nl> + if ( pdev -> vendor == PCI_VENDOR_ID_VIA ) <nl> + xhci -> quirks |= XHCI_RESET_ON_RESUME ; <nl> } <nl>  <nl> /* called during probe () after chip reset completes */
int activate_fd ( int irq , int fd , int type , void * dev_id ) <nl> . events = events , <nl> . current_events = 0 } ); <nl>  <nl> + err = - EBUSY ; <nl> spin_lock_irqsave (& irq_lock , flags ); <nl> for ( irq_fd = active_fds ; irq_fd != NULL ; irq_fd = irq_fd -> next ) { <nl> if (( irq_fd -> fd == fd ) && ( irq_fd -> type == type )) {
static int skl_unload_module ( struct sst_dsp * ctx , u16 mod_id ) <nl> dev_err ( ctx -> dev , " Module bad usage cnt !:% d \ n ", usage_cnt ); <nl> return - EIO ; <nl> } <nl> + <nl> + /* if module is used by others return , no need to unload */ <nl> + if ( usage_cnt > 0 ) <nl> + return 0 ; <nl> + <nl> ret = skl_ipc_unload_modules (& skl -> ipc , <nl> SKL_NUM_MODULES , & mod_id ); <nl> if ( ret < 0 ) {
int ext4_collapse_range ( struct inode * inode , loff_t offset , loff_t len ) <nl> if (! S_ISREG ( inode -> i_mode )) <nl> return - EINVAL ; <nl>  <nl> + if ( EXT4_SB ( inode -> i_sb )-> s_cluster_ratio > 1 ) <nl> + return - EOPNOTSUPP ; <nl> + <nl> trace_ext4_collapse_range ( inode , offset , len ); <nl>  <nl> punch_start = offset >> EXT4_BLOCK_SIZE_BITS ( sb );
static int perf_trace_event_perm ( struct ftrace_event_call * tp_event , <nl> { <nl> /* The ftrace function trace is allowed only for root . */ <nl> if ( ftrace_event_is_function ( tp_event ) && <nl> - perf_paranoid_kernel () && ! capable ( CAP_SYS_ADMIN )) <nl> + perf_paranoid_tracepoint_raw () && ! capable ( CAP_SYS_ADMIN )) <nl> return - EPERM ; <nl>  <nl> /* No tracing , just counting , so no obvious leak */
static int __do_request ( struct ceph_mds_client * mdsc , <nl> int mds = - 1 ; <nl> int err = - EAGAIN ; <nl>  <nl> - if ( req -> r_err || req -> r_got_result ) <nl> + if ( req -> r_err || req -> r_got_result ) { <nl> + if ( req -> r_aborted ) <nl> + __unregister_request ( mdsc , req ); <nl> goto out ; <nl> + } <nl>  <nl> if ( req -> r_timeout && <nl> time_after_eq ( jiffies , req -> r_started + req -> r_timeout )) {
static int usbvision_v4l2_close ( struct file * file ) <nl> usbvision_scratch_free ( usbvision ); <nl>  <nl> usbvision -> user --; <nl> + mutex_unlock (& usbvision -> v4l2_lock ); <nl>  <nl> if ( usbvision -> remove_pending ) { <nl> printk ( KERN_INFO "% s : Final disconnect \ n ", __func__ ); <nl> usbvision_release ( usbvision ); <nl> return 0 ; <nl> } <nl> - mutex_unlock (& usbvision -> v4l2_lock ); <nl>  <nl> PDEBUG ( DBG_IO , " success "); <nl> return v4l2_fh_release ( file );
static void clear_subscriber_list ( struct snd_seq_client * client , <nl> list_del (& subs -> dest_list ); <nl> else <nl> list_del (& subs -> src_list ); <nl> + up_write (& agrp -> list_mutex ); <nl> unsubscribe_port ( c , aport , agrp , & subs -> info , 1 ); <nl> kfree ( subs ); <nl> - up_write (& agrp -> list_mutex ); <nl> snd_seq_port_unlock ( aport ); <nl> snd_seq_client_unlock ( c ); <nl> }
static long swap_inode_boot_loader ( struct super_block * sb , <nl> handle = ext4_journal_start ( inode_bl , EXT4_HT_MOVE_EXTENTS , 2 ); <nl> if ( IS_ERR ( handle )) { <nl> err = - EINVAL ; <nl> - goto swap_boot_out ; <nl> + goto journal_err_out ; <nl> } <nl>  <nl> /* Protect extent tree against block allocations via delalloc */ <nl> static long swap_inode_boot_loader ( struct super_block * sb , <nl>  <nl> ext4_double_up_write_data_sem ( inode , inode_bl ); <nl>  <nl> + journal_err_out : <nl> ext4_inode_resume_unlocked_dio ( inode ); <nl> ext4_inode_resume_unlocked_dio ( inode_bl ); <nl> 
static int tridentfb_pan_display ( struct fb_var_screeninfo * var , <nl> unsigned int offset ; <nl>  <nl> debug (" enter \ n "); <nl> - offset = ( var -> xoffset + ( var -> yoffset * var -> xres_virtual )) <nl> - * var -> bits_per_pixel / 32 ; <nl> + offset = ( var -> xoffset + ( var -> yoffset * info -> var . xres_virtual )) <nl> + * info -> var . bits_per_pixel / 32 ; <nl> set_screen_start ( par , offset ); <nl> debug (" exit \ n "); <nl> return 0 ;
static int ccdc_config_vdfc ( struct ccdc_vertical_dft * dfc ) <nl> */ <nl> static void ccdc_config_csc ( struct ccdc_csc * csc ) <nl> { <nl> - u32 val1 , val2 ; <nl> + u32 val1 = 0 , val2 ; <nl> int i ; <nl>  <nl> if (! csc -> enable )
do_sigbus ( struct pt_regs * regs , unsigned long error_code , unsigned long address , <nl> up_read (& mm -> mmap_sem ); <nl>  <nl> /* Kernel mode ? Handle exceptions or die : */ <nl> - if (!( error_code & PF_USER )) <nl> + if (!( error_code & PF_USER )) { <nl> no_context ( regs , error_code , address ); <nl> + return ; <nl> + } <nl>  <nl> /* User - space => ok to do another page fault : */ <nl> if ( is_prefetch ( regs , error_code , address ))
static int mspro_block_read_attributes ( struct memstick_dev * card ) <nl> snprintf ( s_attr -> name , sizeof ( s_attr -> name ), <nl> " attr_x % 02x ", attr -> entries [ cnt ]. id ); <nl>  <nl> + sysfs_attr_init (& s_attr -> dev_attr . attr ); <nl> s_attr -> dev_attr . attr . name = s_attr -> name ; <nl> s_attr -> dev_attr . attr . mode = S_IRUGO ; <nl> s_attr -> dev_attr . show = mspro_block_attr_show ( s_attr -> id );
static void smsc_ircc_sir_wait_hw_transmitter_finish ( struct smsc_ircc_cb * self ) <nl> while ( count -- > 0 && !( inb ( iobase + UART_LSR ) & UART_LSR_TEMT )) <nl> udelay ( 1 ); <nl>  <nl> - if ( count == 0 ) <nl> + if ( count < 0 ) <nl> IRDA_DEBUG ( 0 , "% s (): stuck transmitter \ n ", __func__ ); <nl> } <nl> 
static int device_authorization ( struct hdpvr_device * dev ) <nl> hex_dump_to_buffer ( response , 8 , 16 , 1 , print_buf , 5 * buf_size + 1 , 0 ); <nl> v4l2_dbg ( MSG_INFO , hdpvr_debug , & dev -> v4l2_dev , " response : % s \ n ", <nl> print_buf ); <nl> + kfree ( print_buf ); <nl> # endif <nl>  <nl> msleep ( 100 );
static void qusb2_phy_set_tune2_param ( struct qusb2_phy * qphy ) <nl> const struct qusb2_phy_cfg * cfg = qphy -> cfg ; <nl> u8 * val ; <nl>  <nl> + /* efuse register is optional */ <nl> + if (! qphy -> cell ) <nl> + return ; <nl> + <nl> /* <nl> * Read efuse register having TUNE2 / 1 parameter ' s high nibble . <nl> * If efuse register shows value as 0x0 , or if we fail to find
static int usbat_probe ( struct usb_interface * intf , <nl> us -> transport_name = " Shuttle USBAT "; <nl> us -> transport = usbat_flash_transport ; <nl> us -> transport_reset = usb_stor_CB_reset ; <nl> - us -> max_lun = 1 ; <nl> + us -> max_lun = 0 ; <nl>  <nl> result = usb_stor_probe2 ( us ); <nl> return result ;
struct snd_usb_endpoint * snd_usb_add_endpoint ( struct snd_usb_audio * chip , <nl> struct snd_usb_endpoint * ep ; <nl> int is_playback = direction == SNDRV_PCM_STREAM_PLAYBACK ; <nl>  <nl> + if ( WARN_ON (! alts )) <nl> + return NULL ; <nl> + <nl> mutex_lock (& chip -> mutex ); <nl>  <nl> list_for_each_entry ( ep , & chip -> ep_list , list ) {
static int usb_hcd_fsl_probe ( const struct hc_driver * driver , <nl> */ <nl> if ( pdata -> init && pdata -> init ( pdev )) { <nl> retval = - ENODEV ; <nl> - goto err3 ; <nl> + goto err4 ; <nl> } <nl>  <nl> /* Enable USB controller , 83xx or 8536 */
static int ad7877_rx ( struct ad7877 * ts ) <nl> Rt /= z1 ; <nl> Rt = ( Rt + 2047 ) >> 12 ; <nl>  <nl> + /* <nl> + * Sample found inconsistent , pressure is beyond <nl> + * the maximum . Don ' t report it to user space . <nl> + */ <nl> + if ( Rt > ts -> pressure_max ) <nl> + return - EINVAL ; <nl> + <nl> if (! timer_pending (& ts -> timer )) <nl> input_report_key ( input_dev , BTN_TOUCH , 1 ); <nl> 
static unsigned char GetXG27FPBits ( struct vb_device_info * pVBInfo ) <nl> /* enable GPIOA / B / C read */ <nl> xgifb_reg_and_or ( pVBInfo -> P3d4 , 0x4A , ~ 0x03 , 0x03 ); <nl> temp = xgifb_reg_get ( pVBInfo -> P3d4 , 0x48 ); <nl> - if ( temp <= 2 ) <nl> - temp &= 0x03 ; <nl> - else <nl> + if ( temp > 2 ) <nl> temp = (( temp & 0x04 ) >> 1 ) | ((~ temp ) & 0x01 ); <nl>  <nl> xgifb_reg_set ( pVBInfo -> P3d4 , 0x4A , CR4A );
static int acm_probe ( struct usb_interface * intf , <nl> } <nl>  <nl>  <nl> - if ( data_interface -> cur_altsetting -> desc . bNumEndpoints < 2 ) <nl> + if ( data_interface -> cur_altsetting -> desc . bNumEndpoints < 2 || <nl> + control_interface -> cur_altsetting -> desc . bNumEndpoints == 0 ) <nl> return - EINVAL ; <nl>  <nl> epctrl = & control_interface -> cur_altsetting -> endpoint [ 0 ]. desc ;
static void m_stop ( struct seq_file * m , void * v ) <nl> struct proc_maps_private * priv = m -> private ; <nl> struct vm_area_struct * vma = v ; <nl>  <nl> - vma_stop ( priv , vma ); <nl> + if (! IS_ERR ( vma )) <nl> + vma_stop ( priv , vma ); <nl> if ( priv -> task ) <nl> put_task_struct ( priv -> task ); <nl> }
void hpsb_packet_received ( struct hpsb_host * host , quadlet_t * data , size_t size , <nl> /* return the index ( within a minor number block ) of a file */ <nl> static inline unsigned char ieee1394_file_to_instance ( struct file * file ) <nl> { <nl> - return file -> f_dentry -> d_inode -> i_cindex ; <nl> + return file -> f_path . dentry -> d_inode -> i_cindex ; <nl> } <nl>  <nl> extern int hpsb_disable_irm ;
static ssize_t rng_dev_read ( struct file * filp , char __user * buf , <nl> err = - EAGAIN ; <nl> if (! bytes_read && ( filp -> f_flags & O_NONBLOCK )) <nl> goto out ; <nl> + if ( bytes_read < 0 ) { <nl> + err = bytes_read ; <nl> + goto out ; <nl> + } <nl>  <nl> err = - EFAULT ; <nl> while ( bytes_read && size ) {
struct ata_host * ata_host_alloc ( struct device * dev , int max_ports ) <nl> return NULL ; <nl>  <nl> if (! devres_open_group ( dev , NULL , GFP_KERNEL )) <nl> - return NULL ; <nl> + goto err_free ; <nl>  <nl> dr = devres_alloc ( ata_devres_release , 0 , GFP_KERNEL ); <nl> if (! dr ) <nl> struct ata_host * ata_host_alloc ( struct device * dev , int max_ports ) <nl>  <nl> err_out : <nl> devres_release_group ( dev , NULL ); <nl> + err_free : <nl> + kfree ( host ); <nl> return NULL ; <nl> } <nl> 
static u32 slic_card_locate ( struct adapter * adapter ) <nl> if (! physcard ) { <nl> /* no structure allocated for this physical card yet */ <nl> physcard = kzalloc ( sizeof ( struct physcard ), GFP_ATOMIC ); <nl> - if (! physcard ) <nl> + if (! physcard ) { <nl> + if ( card_hostid == SLIC_HOSTID_DEFAULT ) <nl> + kfree ( card ); <nl> return - ENOMEM ; <nl> + } <nl>  <nl> physcard -> next = slic_global . phys_card ; <nl> slic_global . phys_card = physcard ;
acpi_ps_get_next_arg ( struct acpi_walk_state * walk_state , <nl> ACPI_POSSIBLE_METHOD_CALL ); <nl>  <nl> if ( arg -> common . aml_opcode == AML_INT_METHODCALL_OP ) { <nl> + <nl> + /* Free method call op and corresponding namestring sub - ob */ <nl> + <nl> + acpi_ps_free_op ( arg -> common . value . arg ); <nl> acpi_ps_free_op ( arg ); <nl> arg = NULL ; <nl> walk_state -> arg_count = 1 ;
struct ttm_tt * ttm_tt_create ( struct ttm_bo_device * bdev , unsigned long size , <nl> ttm -> dummy_read_page = dummy_read_page ; <nl>  <nl> ttm_tt_alloc_page_directory ( ttm ); <nl> - if (! ttm -> pages ) { <nl> + if (! ttm -> pages || ! ttm -> dma_address ) { <nl> ttm_tt_destroy ( ttm ); <nl> printk ( KERN_ERR TTM_PFX " Failed allocating page table \ n "); <nl> return NULL ;
static int acpi_battery_technology ( struct acpi_battery * battery ) <nl> return POWER_SUPPLY_TECHNOLOGY_NiMH ; <nl> if (! strcasecmp (" LION ", battery -> type )) <nl> return POWER_SUPPLY_TECHNOLOGY_LION ; <nl> + if (! strcasecmp (" LI - ION ", battery -> type )) <nl> + return POWER_SUPPLY_TECHNOLOGY_LION ; <nl> if (! strcasecmp (" LiP ", battery -> type )) <nl> return POWER_SUPPLY_TECHNOLOGY_LIPO ; <nl> return POWER_SUPPLY_TECHNOLOGY_UNKNOWN ;
static int ixgbe_xdp ( struct net_device * dev , struct netdev_xdp * xdp ) <nl> return ixgbe_xdp_setup ( dev , xdp -> prog ); <nl> case XDP_QUERY_PROG : <nl> xdp -> prog_attached = !!( adapter -> xdp_prog ); <nl> + xdp -> prog_id = adapter -> xdp_prog ? <nl> + adapter -> xdp_prog -> aux -> id : 0 ; <nl> return 0 ; <nl> default : <nl> return - EINVAL ;
int intel_atomic_check ( struct drm_device * dev , <nl> state -> allow_modeset = false ; <nl> for ( i = 0 ; i < ncrtcs ; i ++) { <nl> struct intel_crtc * crtc = to_intel_crtc ( state -> crtcs [ i ]); <nl> + if ( crtc ) <nl> + memset (& crtc -> atomic , 0 , sizeof ( crtc -> atomic )); <nl> if ( crtc && crtc -> pipe != nuclear_pipe ) <nl> not_nuclear = true ; <nl> }
int ext4_setattr ( struct dentry * dentry , struct iattr * attr ) <nl> /* ( user + group )*( old + new ) structure , inode write ( sb , <nl> * inode block , ? - but truncate inode update has it ) */ <nl> handle = ext4_journal_start ( inode , ( EXT4_MAXQUOTAS_INIT_BLOCKS ( inode -> i_sb )+ <nl> - EXT4_QUOTA_DEL_BLOCKS ( inode -> i_sb ))+ 3 ); <nl> + EXT4_MAXQUOTAS_DEL_BLOCKS ( inode -> i_sb ))+ 3 ); <nl> if ( IS_ERR ( handle )) { <nl> error = PTR_ERR ( handle ); <nl> goto err_out ;
static void tilcdc_crtc_destroy ( struct drm_crtc * crtc ) <nl> struct tilcdc_crtc * tilcdc_crtc = to_tilcdc_crtc ( crtc ); <nl> struct tilcdc_drm_private * priv = crtc -> dev -> dev_private ; <nl>  <nl> + drm_modeset_lock_crtc ( crtc , NULL ); <nl> tilcdc_crtc_disable ( crtc ); <nl> + drm_modeset_unlock_crtc ( crtc ); <nl>  <nl> flush_workqueue ( priv -> wq ); <nl> 
xfs_dialloc_ag_inobt ( <nl>  <nl> /* free inodes to the left ? */ <nl> if ( useleft && trec . ir_freecount ) { <nl> - rec = trec ; <nl> xfs_btree_del_cursor ( cur , XFS_BTREE_NOERROR ); <nl> cur = tcur ; <nl>  <nl> pag -> pagl_leftrec = trec . ir_startino ; <nl> pag -> pagl_rightrec = rec . ir_startino ; <nl> pag -> pagl_pagino = pagino ; <nl> + rec = trec ; <nl> goto alloc_inode ; <nl> } <nl> 
static int dvb_ca_ioctl ( struct file * file , unsigned int cmd , void * parg ) <nl> { <nl> ca_slot_info_t * info =( ca_slot_info_t *) parg ; <nl>  <nl> - if ( info -> num > 1 ) <nl> + if ( info -> num < 0 || info -> num > 1 ) <nl> return - EINVAL ; <nl> av7110 -> ci_slot [ info -> num ]. num = info -> num ; <nl> av7110 -> ci_slot [ info -> num ]. type = FW_CI_LL_SUPPORT ( av7110 -> arm_app ) ?
static int alc662_parse_auto_config ( struct hda_codec * codec ) <nl> if ( codec -> vendor_id == 0x10ec0663 ) <nl> spec -> init_verbs [ spec -> num_init_verbs ++] = <nl> alc663_auto_init_verbs ; <nl> + <nl> + err = alc_auto_add_mic_boost ( codec ); <nl> + if ( err < 0 ) <nl> + return err ; <nl> + <nl> spec -> mixers [ spec -> num_mixers ] = alc662_capture_mixer ; <nl> spec -> num_mixers ++; <nl> return 1 ;
static void __orinoco_ev_info ( struct net_device * dev , hermes_t * hw ) <nl> /* Read scan data */ <nl> err = hermes_bap_pread ( hw , IRQ_BAP , ( void *) buf , len , <nl> infofid , sizeof ( info )); <nl> - if ( err ) <nl> + if ( err ) { <nl> + kfree ( buf ); <nl> break ; <nl> + } <nl>  <nl> # ifdef ORINOCO_DEBUG <nl> {
int tipc_nl_publ_dump ( struct sk_buff * skb , struct netlink_callback * cb ) <nl> if ( err ) <nl> return err ; <nl>  <nl> + if (! attrs [ TIPC_NLA_SOCK ]) <nl> + return - EINVAL ; <nl> + <nl> err = nla_parse_nested ( sock , TIPC_NLA_SOCK_MAX , <nl> attrs [ TIPC_NLA_SOCK ], <nl> tipc_nl_sock_policy );
static int __f2fs_setxattr ( struct inode * inode , int index , <nl> goto exit ; <nl> } <nl>  <nl> - if ( f2fs_xattr_value_same ( here , value , size )) <nl> + if ( value && f2fs_xattr_value_same ( here , value , size )) <nl> goto exit ; <nl> } else if (( flags & XATTR_REPLACE )) { <nl> error = - ENODATA ;
int nvdimm_namespace_attach_btt ( struct nd_namespace_common * ndns ) <nl> } <nl>  <nl> btt_sb = devm_kzalloc (& nd_btt -> dev , sizeof (* btt_sb ), GFP_KERNEL ); <nl> + if (! btt_sb ) <nl> + return - ENOMEM ; <nl>  <nl> /* <nl> * If this returns < 0 , that is ok as it just means there wasn ' t
static void __wl1271_op_remove_interface ( struct wl1271 * wl , <nl> wl1271_free_ap_keys ( wl , wlvif ); <nl> } <nl>  <nl> + dev_kfree_skb ( wlvif -> probereq ); <nl> + wlvif -> probereq = NULL ; <nl> wl12xx_tx_reset_wlvif ( wl , wlvif ); <nl> if ( wl -> last_wlvif == wlvif ) <nl> wl -> last_wlvif = NULL ;
static int pwm_setup_backlight ( struct intel_connector * connector , <nl> return - ENODEV ; <nl> } <nl>  <nl> + /* <nl> + * FIXME : pwm_apply_args () should be removed when switching to <nl> + * the atomic PWM API . <nl> + */ <nl> + pwm_apply_args ( panel -> backlight . pwm ); <nl> + <nl> retval = pwm_config ( panel -> backlight . pwm , CRC_PMIC_PWM_PERIOD_NS , <nl> CRC_PMIC_PWM_PERIOD_NS ); <nl> if ( retval < 0 ) {
static int cciss_ioctl32_big_passthru ( struct block_device * bdev , fmode_t mode , <nl> int err ; <nl> u32 cp ; <nl>  <nl> + memset (& arg64 , 0 , sizeof ( arg64 )); <nl> err = 0 ; <nl> err |= <nl> copy_from_user (& arg64 . LUN_info , & arg32 -> LUN_info ,
int kvm_timer_hyp_init ( void ) <nl> info = arch_timer_get_kvm_info (); <nl> timecounter = & info -> timecounter ; <nl>  <nl> + if (! timecounter -> cc ) { <nl> + kvm_err (" kvm_arch_timer : uninitialized timecounter \ n "); <nl> + return - ENODEV ; <nl> + } <nl> + <nl> if ( info -> virtual_irq <= 0 ) { <nl> kvm_err (" kvm_arch_timer : invalid virtual timer IRQ : % d \ n ", <nl> info -> virtual_irq );
long keyctl_read_key ( key_serial_t keyid , char __user * buffer , size_t buflen ) <nl>  <nl> key = key_ref_to_ptr ( key_ref ); <nl>  <nl> + if ( test_bit ( KEY_FLAG_NEGATIVE , & key -> flags )) { <nl> + ret = - ENOKEY ; <nl> + goto error2 ; <nl> + } <nl> + <nl> /* see if we can read it directly */ <nl> ret = key_permission ( key_ref , KEY_NEED_READ ); <nl> if ( ret == 0 )
static int __inet6_check_established ( struct inet_timewait_death_row * death_row , <nl>  <nl> if ( twp != NULL ) { <nl> * twp = tw ; <nl> - NET_INC_STATS_BH ( twsk_net ( tw ), LINUX_MIB_TIMEWAITRECYCLED ); <nl> + NET_INC_STATS_BH ( net , LINUX_MIB_TIMEWAITRECYCLED ); <nl> } else if ( tw != NULL ) { <nl> /* Silly . Should hash - dance instead ... */ <nl> inet_twsk_deschedule ( tw , death_row ); <nl> - NET_INC_STATS_BH ( twsk_net ( tw ), LINUX_MIB_TIMEWAITRECYCLED ); <nl> + NET_INC_STATS_BH ( net , LINUX_MIB_TIMEWAITRECYCLED ); <nl>  <nl> inet_twsk_put ( tw ); <nl> }
static int corsair_input_mapping ( struct hid_device * dev , <nl> { <nl> int gkey ; <nl>  <nl> + if (( usage -> hid & HID_USAGE_PAGE ) != HID_UP_KEYBOARD ) <nl> + return 0 ; <nl> + <nl> gkey = corsair_usage_to_gkey ( usage -> hid & HID_USAGE ); <nl> if ( gkey != 0 ) { <nl> hid_map_usage_clear ( input , usage , bit , max , EV_KEY ,
int rtllib_rx ( struct rtllib_device * ieee , struct sk_buff * skb , <nl> return ret ; <nl>  <nl> rx_dropped : <nl> - ieee -> stats . rx_dropped ++; <nl> + if ( ieee ) <nl> + ieee -> stats . rx_dropped ++; <nl> return 0 ; <nl> } <nl> EXPORT_SYMBOL ( rtllib_rx );
void spu_deactivate ( struct spu_context * ctx ) <nl> */ <nl> void spu_yield ( struct spu_context * ctx ) <nl> { <nl> - mutex_lock (& ctx -> state_mutex ); <nl> - __spu_deactivate ( ctx , 0 , MAX_PRIO ); <nl> - mutex_unlock (& ctx -> state_mutex ); <nl> + if (!( ctx -> flags & SPU_CREATE_NOSCHED )) { <nl> + mutex_lock (& ctx -> state_mutex ); <nl> + __spu_deactivate ( ctx , 0 , MAX_PRIO ); <nl> + mutex_unlock (& ctx -> state_mutex ); <nl> + } <nl> } <nl>  <nl> void spu_sched_tick ( struct work_struct * work )
nouveau_connector_set_encoder ( struct drm_connector * connector , <nl> return ; <nl> nv_connector -> detected_encoder = nv_encoder ; <nl>  <nl> + if ( dev_priv -> card_type >= NV_50 ) { <nl> + connector -> interlace_allowed = true ; <nl> + connector -> doublescan_allowed = true ; <nl> + } else <nl> if ( nv_encoder -> dcb -> type == OUTPUT_LVDS || <nl> nv_encoder -> dcb -> type == OUTPUT_TMDS ) { <nl> connector -> doublescan_allowed = false ;
static int find_fsync_dnodes ( struct f2fs_sb_info * sbi , struct list_head * head ) <nl> if ( IS_ERR ( entry -> inode )) { <nl> err = PTR_ERR ( entry -> inode ); <nl> kmem_cache_free ( fsync_entry_slab , entry ); <nl> - if ( err == - ENOENT ) <nl> + if ( err == - ENOENT ) { <nl> + err = 0 ; <nl> goto next ; <nl> + } <nl> break ; <nl> } <nl> list_add_tail (& entry -> list , head );
static void mem_cgroup_usage_unregister_event ( struct cgroup * cgrp , <nl> */ <nl> BUG_ON (! thresholds ); <nl>  <nl> + if (! thresholds -> primary ) <nl> + goto unlock ; <nl> + <nl> usage = mem_cgroup_usage ( memcg , type == _MEMSWAP ); <nl>  <nl> /* Check if a threshold crossed before removing */ <nl> static void mem_cgroup_usage_unregister_event ( struct cgroup * cgrp , <nl>  <nl> /* To be sure that nobody uses thresholds */ <nl> synchronize_rcu (); <nl> - <nl> + unlock : <nl> mutex_unlock (& memcg -> thresholds_lock ); <nl> } <nl> 
MODULE_FIRMWARE (" digiface_firmware_rev11 . bin "); <nl> # define HDSP_DMA_AREA_BYTES (( HDSP_MAX_CHANNELS + 1 ) * HDSP_CHANNEL_BUFFER_BYTES ) <nl> # define HDSP_DMA_AREA_KILOBYTES ( HDSP_DMA_AREA_BYTES / 1024 ) <nl>  <nl> -/* use hotplug firmeare loader ? */ <nl> +/* use hotplug firmware loader ? */ <nl> # if defined ( CONFIG_FW_LOADER ) || defined ( CONFIG_FW_LOADER_MODULE ) <nl> -# if ! defined ( HDSP_USE_HWDEP_LOADER ) && ! defined ( CONFIG_SND_HDSP ) <nl> +# if ! defined ( HDSP_USE_HWDEP_LOADER ) <nl> # define HDSP_FW_LOADER <nl> # endif <nl> # endif
static int amdgpu_cs_wait_any_fence ( struct amdgpu_device * adev , <nl> wait -> out . status = ( r > 0 ); <nl> wait -> out . first_signaled = first ; <nl>  <nl> - if ( array [ first ]) <nl> + if ( first < fence_count && array [ first ]) <nl> r = array [ first ]-> error ; <nl> else <nl> r = 0 ;
int ext4_orphan_del ( handle_t * handle , struct inode * inode ) <nl> struct ext4_iloc iloc ; <nl> int err = 0 ; <nl>  <nl> - if (! EXT4_SB ( inode -> i_sb )-> s_journal ) <nl> + if ((! EXT4_SB ( inode -> i_sb )-> s_journal ) && <nl> + !( EXT4_SB ( inode -> i_sb )-> s_mount_state & EXT4_ORPHAN_FS )) <nl> return 0 ; <nl>  <nl> mutex_lock (& EXT4_SB ( inode -> i_sb )-> s_orphan_lock );
int dso__load_sym ( struct dso * dso , struct map * map , const char * name , int fd , <nl> goto new_symbol ; <nl> } <nl>  <nl> - if ( curr_dso -> adjust_symbols ) { <nl> + if ( curr_dso -> adjust_symbols && sym . st_value ) { <nl> pr_debug4 ("% s : adjusting symbol : st_value : %#" PRIx64 " " <nl> " sh_addr : %#" PRIx64 " sh_offset : %#" PRIx64 "\ n ", __func__ , <nl> ( u64 ) sym . st_value , ( u64 ) shdr . sh_addr ,
static int __devinit snd_vt1724_read_eeprom ( struct snd_ice1712 * ice , <nl> static void __devinit snd_vt1724_chip_reset ( struct snd_ice1712 * ice ) <nl> { <nl> outb ( VT1724_RESET , ICEREG1724 ( ice , CONTROL )); <nl> + inb ( ICEREG1724 ( ice , CONTROL )); /* pci posting flush */ <nl> msleep ( 10 ); <nl> outb ( 0 , ICEREG1724 ( ice , CONTROL )); <nl> + inb ( ICEREG1724 ( ice , CONTROL )); /* pci posting flush */ <nl> msleep ( 10 ); <nl> } <nl> 
static struct console udbg_console = { <nl> . index = - 1 , <nl> }; <nl>  <nl> + static int early_console_initialized ; <nl> + <nl> void __init disable_early_printk ( void ) <nl> { <nl> + if (! early_console_initialized ) <nl> + return ; <nl> unregister_console (& udbg_console ); <nl> + early_console_initialized = 0 ; <nl> } <nl>  <nl> /* called by setup_system */ <nl> void register_early_udbg_console ( void ) <nl> { <nl> + early_console_initialized = 1 ; <nl> register_console (& udbg_console ); <nl> } <nl> 
static int skl_probe ( struct pci_dev * pci , <nl> if ( err < 0 ) <nl> goto out_free ; <nl>  <nl> + skl -> nhlt = skl_nhlt_init ( bus -> dev ); <nl> + <nl> + if ( skl -> nhlt == NULL ) <nl> + goto out_free ; <nl> + <nl> pci_set_drvdata ( skl -> pci , ebus ); <nl>  <nl> /* check if dsp is there */
bool seg6_validate_srh ( struct ipv6_sr_hdr * srh , int len ) <nl> struct sr6_tlv * tlv ; <nl> unsigned int tlv_len ; <nl>  <nl> + if ( trailing < sizeof (* tlv )) <nl> + return false ; <nl> + <nl> tlv = ( struct sr6_tlv *)(( unsigned char *) srh + tlv_offset ); <nl> tlv_len = sizeof (* tlv ) + tlv -> len ; <nl> 
static void azx_pcm_free ( struct snd_pcm * pcm ) <nl>  <nl> # define MAX_PREALLOC_SIZE ( 32 * 1024 * 1024 ) <nl>  <nl> - int azx_attach_pcm_stream ( struct hda_bus * bus , struct hda_codec * codec , <nl> - struct hda_pcm * cpcm ) <nl> + static int azx_attach_pcm_stream ( struct hda_bus * bus , struct hda_codec * codec , <nl> + struct hda_pcm * cpcm ) <nl> { <nl> struct azx * chip = bus -> private_data ; <nl> struct snd_pcm * pcm ;
static int raw_cmd_copyout ( int cmd , void __user * param , <nl> int ret ; <nl>  <nl> while ( ptr ) { <nl> - ret = copy_to_user ( param , ptr , sizeof (* ptr )); <nl> + struct floppy_raw_cmd cmd = * ptr ; <nl> + cmd . next = NULL ; <nl> + cmd . kernel_data = NULL ; <nl> + ret = copy_to_user ( param , & cmd , sizeof ( cmd )); <nl> if ( ret ) <nl> return - EFAULT ; <nl> param += sizeof ( struct floppy_raw_cmd );
static inline void create_debug_files ( struct ehci_hcd * ehci ) <nl> & debug_registers_fops )) <nl> goto file_error ; <nl>  <nl> - if (! debugfs_create_file (" lpm ", S_IRUGO | S_IWUGO , ehci -> debug_dir , bus , <nl> + if (! debugfs_create_file (" lpm ", S_IRUGO | S_IWUSR , ehci -> debug_dir , bus , <nl> & debug_lpm_fops )) <nl> goto file_error ; <nl> 
static int uwbd ( void * param ) <nl> HZ ); <nl> if ( should_stop ) <nl> break ; <nl> - try_to_freeze (); <nl>  <nl> spin_lock_irqsave (& rc -> uwbd . event_list_lock , flags ); <nl> if (! list_empty (& rc -> uwbd . event_list )) {
parser_name_get ( struct parser_context * ctx ) <nl> struct spar_controlvm_parameters_header * phdr = NULL ; <nl>  <nl> phdr = ( struct spar_controlvm_parameters_header *)( ctx -> data ); <nl> + <nl> + if ( phdr -> name_offset + phdr -> name_length > ctx -> param_bytes ) <nl> + return NULL ; <nl> + <nl> ctx -> curr = ctx -> data + phdr -> name_offset ; <nl> ctx -> bytes_remaining = phdr -> name_length ; <nl> return parser_string_get ( ctx );
static int host_start ( struct ci13xxx * ci ) <nl> else <nl> ci -> hcd = hcd ; <nl>  <nl> + if ( ci -> platdata -> flags & CI13XXX_DISABLE_STREAMING ) <nl> + hw_write ( ci , OP_USBMODE , USBMODE_CI_SDIS , USBMODE_CI_SDIS ); <nl> + <nl> return ret ; <nl> } <nl> 
int devm_request_irq ( struct device * dev , unsigned int irq , <nl>  <nl> rc = request_irq ( irq , handler , irqflags , devname , dev_id ); <nl> if ( rc ) { <nl> - kfree ( dr ); <nl> + devres_free ( dr ); <nl> return rc ; <nl> } <nl> 
static int twl4030_kp_probe ( struct platform_device * pdev ) <nl> err3 : <nl> /* mask all events - we don ' t care about the result */ <nl> ( void ) twl4030_kpwrite_u8 ( kp , 0xff , KEYP_IMR1 ); <nl> - free_irq ( kp -> irq , NULL ); <nl> + free_irq ( kp -> irq , kp ); <nl> err2 : <nl> input_unregister_device ( input ); <nl> input = NULL ;
extern int for_each_subchannel ( int (* fn )( struct subchannel_id , void *), void *); <nl> struct channel_subsystem { <nl> u8 cssid ; <nl> int valid ; <nl> - struct channel_path * chps [ __MAX_CHPID ]; <nl> + struct channel_path * chps [ __MAX_CHPID + 1 ]; <nl> struct device device ; <nl> struct pgid global_pgid ; <nl> };
static struct sctp_auth_bytes * sctp_auth_create_key ( __u32 key_len , gfp_t gfp ) <nl> struct sctp_auth_bytes * key ; <nl>  <nl> /* Verify that we are not going to overflow INT_MAX */ <nl> - if (( INT_MAX - key_len ) < sizeof ( struct sctp_auth_bytes )) <nl> + if ( key_len > ( INT_MAX - sizeof ( struct sctp_auth_bytes ))) <nl> return NULL ; <nl>  <nl> /* Allocate the shared key */
static struct sock * sctp_v6_create_accept_sk ( struct sock * sk , <nl> newnp = inet6_sk ( newsk ); <nl>  <nl> memcpy ( newnp , np , sizeof ( struct ipv6_pinfo )); <nl> + newnp -> ipv6_mc_list = NULL ; <nl> + newnp -> ipv6_ac_list = NULL ; <nl> + newnp -> ipv6_fl_list = NULL ; <nl>  <nl> rcu_read_lock (); <nl> opt = rcu_dereference ( np -> opt );
int radeon_atombios_init ( struct radeon_device * rdev ) <nl>  <nl> void radeon_atombios_fini ( struct radeon_device * rdev ) <nl> { <nl> - kfree ( rdev -> mode_info . atom_context -> scratch ); <nl> - kfree ( rdev -> mode_info . atom_context ); <nl> + if ( rdev -> mode_info . atom_context ) { <nl> + kfree ( rdev -> mode_info . atom_context -> scratch ); <nl> + kfree ( rdev -> mode_info . atom_context ); <nl> + } <nl> kfree ( rdev -> mode_info . atom_card_info ); <nl> } <nl> 
static struct scatterlist * alloc_sgtable ( int size ) <nl> if ( new_page ) <nl> __free_page ( new_page ); <nl> } <nl> + kfree ( table ); <nl> return NULL ; <nl> } <nl> alloc_size = min_t ( int , size , PAGE_SIZE );
/* to align the pointer to the ( next ) page boundary */ <nl> # define PAGE_ALIGN ( addr ) ((( addr )+ PAGE_SIZE - 1 )& PAGE_MASK ) <nl>  <nl> -# define __PHYSICAL_MASK (((( phys_addr_t ) 1 ) << __PHYSICAL_MASK_SHIFT ) - 1 ) <nl> +# define __PHYSICAL_MASK (( phys_addr_t )( 1ULL << __PHYSICAL_MASK_SHIFT ) - 1 ) <nl> # define __VIRTUAL_MASK (( 1UL << __VIRTUAL_MASK_SHIFT ) - 1 ) <nl>  <nl> # ifndef __ASSEMBLY__
static void xiic_reinit ( struct xiic_i2c * i2c ) <nl> /* Enable interrupts */ <nl> xiic_setreg32 ( i2c , XIIC_DGIER_OFFSET , XIIC_GINTR_ENABLE_MASK ); <nl>  <nl> - xiic_irq_clr_en ( i2c , XIIC_INTR_AAS_MASK | XIIC_INTR_ARB_LOST_MASK ); <nl> + xiic_irq_clr_en ( i2c , XIIC_INTR_ARB_LOST_MASK ); <nl> } <nl>  <nl> static void xiic_deinit ( struct xiic_i2c * i2c )
struct se_portal_group * tcm_loop_make_naa_tpg ( <nl> tpgt_str += 5 ; /* Skip ahead of " tpgt_ " */ <nl> tpgt = ( unsigned short int ) simple_strtoul ( tpgt_str , & end_ptr , 0 ); <nl>  <nl> - if ( tpgt > TL_TPGS_PER_HBA ) { <nl> + if ( tpgt >= TL_TPGS_PER_HBA ) { <nl> printk ( KERN_ERR " Passed tpgt : % hu exceeds TL_TPGS_PER_HBA :" <nl> " % u \ n ", tpgt , TL_TPGS_PER_HBA ); <nl> return ERR_PTR (- EINVAL );
sg_build_indirect ( Sg_scatter_hold * schp , Sg_fd * sfp , int buff_size ) <nl> num = ( rem_sz > scatter_elem_sz_prev ) ? <nl> scatter_elem_sz_prev : rem_sz ; <nl>  <nl> - schp -> pages [ k ] = alloc_pages ( gfp_mask , order ); <nl> + schp -> pages [ k ] = alloc_pages ( gfp_mask | __GFP_ZERO , order ); <nl> if (! schp -> pages [ k ]) <nl> goto out ; <nl> 
int mlxsw_sp_router_init ( struct mlxsw_sp * mlxsw_sp ) <nl> return err ; <nl> mlxsw_sp_lpm_init ( mlxsw_sp ); <nl> mlxsw_sp_vrs_init ( mlxsw_sp ); <nl> - return mlxsw_sp_neigh_init ( mlxsw_sp ); <nl> + err = mlxsw_sp_neigh_init ( mlxsw_sp ); <nl> + if ( err ) <nl> + goto err_neigh_init ; <nl> + return 0 ; <nl> + <nl> + err_neigh_init : <nl> + __mlxsw_sp_router_fini ( mlxsw_sp ); <nl> + return err ; <nl> } <nl>  <nl> void mlxsw_sp_router_fini ( struct mlxsw_sp * mlxsw_sp )
static int igb_probe ( struct pci_dev * pdev , const struct pci_device_id * ent ) <nl> if ( hw -> flash_address ) <nl> iounmap ( hw -> flash_address ); <nl> err_sw_init : <nl> + kfree ( adapter -> shadow_vfta ); <nl> igb_clear_interrupt_scheme ( adapter ); <nl> pci_iounmap ( pdev , hw -> hw_addr ); <nl> err_ioremap :
static int exec_drive_taskfile ( struct driver_data * dd , <nl> fis . device ); <nl>  <nl> /* check for erase mode support during secure erase .*/ <nl> - if (( fis . command == ATA_CMD_SEC_ERASE_UNIT ) <nl> - && ( outbuf [ 0 ] & MTIP_SEC_ERASE_MODE )) { <nl> + if (( fis . command == ATA_CMD_SEC_ERASE_UNIT ) && outbuf && <nl> + ( outbuf [ 0 ] & MTIP_SEC_ERASE_MODE )) { <nl> erasemode = 1 ; <nl> } <nl> 
static struct ctl_table sctp_net_table [] = { <nl> . mode = 0644 , <nl> . proc_handler = proc_sctp_do_auth , <nl> }, <nl> + { <nl> + . procname = " intl_enable ", <nl> + . data = & init_net . sctp . intl_enable , <nl> + . maxlen = sizeof ( int ), <nl> + . mode = 0644 , <nl> + . proc_handler = proc_dointvec , <nl> + }, <nl> { <nl> . procname = " addr_scope_policy ", <nl> . data = & init_net . sctp . scope_policy ,
static void sixpack_close ( struct tty_struct * tty ) <nl> */ <nl> netif_stop_queue ( sp -> dev ); <nl>  <nl> + unregister_netdev ( sp -> dev ); <nl> + <nl> del_timer_sync (& sp -> tx_t ); <nl> del_timer_sync (& sp -> resync_t ); <nl>  <nl> - unregister_netdev ( sp -> dev ); <nl> - <nl> /* Free all 6pack frame buffers after unreg . */ <nl> kfree ( sp -> rbuff ); <nl> kfree ( sp -> xbuff );
static inline int xfrm_replay_verify_len ( struct xfrm_replay_state_esn * replay_es <nl> if ( nla_len ( rp ) < ulen || xfrm_replay_state_esn_len ( replay_esn ) != ulen ) <nl> return - EINVAL ; <nl>  <nl> + if ( up -> replay_window > up -> bmp_len * sizeof ( __u32 ) * 8 ) <nl> + return - EINVAL ; <nl> + <nl> return 0 ; <nl> } <nl> 
flush_signal_handlers ( struct task_struct * t , int force_default ) <nl> if ( force_default || ka -> sa . sa_handler != SIG_IGN ) <nl> ka -> sa . sa_handler = SIG_DFL ; <nl> ka -> sa . sa_flags = 0 ; <nl> +# ifdef SA_RESTORER <nl> + ka -> sa . sa_restorer = NULL ; <nl> +# endif <nl> sigemptyset (& ka -> sa . sa_mask ); <nl> ka ++; <nl> }
static int quota_setinfo ( struct super_block * sb , int type , void __user * addr ) <nl>  <nl> static void copy_to_if_dqblk ( struct if_dqblk * dst , struct fs_disk_quota * src ) <nl> { <nl> + memset ( dst , 0 , sizeof (* dst )); <nl> dst -> dqb_bhardlimit = src -> d_blk_hardlimit ; <nl> dst -> dqb_bsoftlimit = src -> d_blk_softlimit ; <nl> dst -> dqb_curspace = src -> d_bcount ;
void rcu_check_callbacks ( int cpu , int user ) <nl> static void rcu_init_percpu_data ( int cpu , struct rcu_ctrlblk * rcp , <nl> struct rcu_data * rdp ) <nl> { <nl> - long flags ; <nl> + unsigned long flags ; <nl>  <nl> spin_lock_irqsave (& rcp -> lock , flags ); <nl> memset ( rdp , 0 , sizeof (* rdp ));
set_pte_phys ( unsigned long vaddr , unsigned long phys , pgprot_t prot ) <nl> new_pte = pfn_pte ( phys >> PAGE_SHIFT , prot ); <nl>  <nl> pte = pte_offset_kernel ( pmd , vaddr ); <nl> - if (! pte_none (* pte ) && <nl> + if (! pte_none (* pte ) && pte_val ( new_pte ) && <nl> pte_val (* pte ) != ( pte_val ( new_pte ) & __supported_pte_mask )) <nl> pte_ERROR (* pte ); <nl> set_pte ( pte , new_pte );
static int ax25_release ( struct socket * sock ) <nl> ax25_destroy_socket ( ax25 ); <nl> } <nl> if ( ax25_dev ) { <nl> + del_timer_sync (& ax25 -> timer ); <nl> + del_timer_sync (& ax25 -> t1timer ); <nl> + del_timer_sync (& ax25 -> t2timer ); <nl> + del_timer_sync (& ax25 -> t3timer ); <nl> + del_timer_sync (& ax25 -> idletimer ); <nl> dev_put_track ( ax25_dev -> dev , & ax25_dev -> dev_tracker ); <nl> ax25_dev_put ( ax25_dev ); <nl> }
static int ttm_mem_init_dma32_zone ( struct ttm_mem_global * glob , <nl> * No special dma32 zone needed . <nl> */ <nl>  <nl> - if ( mem <= (( uint64_t ) 1ULL << 32 )) <nl> + if ( mem <= (( uint64_t ) 1ULL << 32 )) { <nl> + kfree ( zone ); <nl> return 0 ; <nl> + } <nl>  <nl> /* <nl> * Limit max dma32 memory to 4GB for now
static int get_port_device_capability ( struct pci_dev * dev ) <nl> if ( reg32 & SLOT_HP_CAPABLE_MASK ) <nl> services |= PCIE_PORT_SERVICE_HP ; <nl> } <nl> - /* PME Capable */ <nl> - pos = pci_find_capability ( dev , PCI_CAP_ID_PME ); <nl> - if ( pos ) <nl> + /* PME Capable - root port capability */ <nl> + if ((( reg16 >> 4 ) & PORT_TYPE_MASK ) == PCIE_RC_PORT ) <nl> services |= PCIE_PORT_SERVICE_PME ; <nl>  <nl> pos = PCI_CFG_SPACE_SIZE ;
xlog_finish_defer_ops ( <nl> 0 , XFS_TRANS_RESERVE , & tp ); <nl> if ( error ) <nl> return error ; <nl> + /* dfops is already populated so assign it manually */ <nl> + tp -> t_dfops = dfops ; <nl>  <nl> error = xfs_defer_finish (& tp , dfops ); <nl> if ( error )
void e1000e_reset ( struct e1000_adapter * adapter ) <nl> e1000e_reset_adaptive ( hw ); <nl> e1000_get_phy_info ( hw ); <nl>  <nl> - if (!( adapter -> flags & FLAG_SMART_POWER_DOWN )) { <nl> + if (( adapter -> flags & FLAG_HAS_SMART_POWER_DOWN ) && <nl> + !( adapter -> flags & FLAG_SMART_POWER_DOWN )) { <nl> u16 phy_data = 0 ; <nl> /* <nl> * speed up time to link by disabling smart power down , ignore
static int tegra_output_hdmi_check_mode ( struct tegra_output * output , <nl> parent = clk_get_parent ( hdmi -> clk_parent ); <nl>  <nl> err = clk_round_rate ( parent , pclk * 4 ); <nl> - if ( err < 0 ) <nl> + if ( err <= 0 ) <nl> * status = MODE_NOCLOCK ; <nl> else <nl> * status = MODE_OK ;
unsigned long parse_tag_value ( const char * str , struct parse_tag * tags ) <nl> if ( s != endptr ) <nl> break ; <nl>  <nl> + if ( value > ULONG_MAX / i -> mult ) <nl> + break ; <nl> value *= i -> mult ; <nl> return value ; <nl> }
static ssize_t bat_socket_read ( struct file * file , char __user * buf , <nl>  <nl> spin_unlock_bh (& socket_client -> lock ); <nl>  <nl> - error = copy_to_user ( buf , & socket_packet -> icmp_packet , <nl> - socket_packet -> icmp_len ); <nl> + packet_len = min ( count , socket_packet -> icmp_len ); <nl> + error = copy_to_user ( buf , & socket_packet -> icmp_packet , packet_len ); <nl>  <nl> - packet_len = socket_packet -> icmp_len ; <nl> kfree ( socket_packet ); <nl>  <nl> if ( error )
xfs_getbmap ( <nl> break ; <nl> } <nl>  <nl> + kmem_free ( out ); <nl> return error ; <nl> } <nl> 
static void nhmex_uncore_msr_enable_event ( struct intel_uncore_box * box , struct p <nl> { <nl> struct hw_perf_event * hwc = & event -> hw ; <nl>  <nl> - if ( hwc -> idx >= UNCORE_PMC_IDX_FIXED ) <nl> + if ( hwc -> idx == UNCORE_PMC_IDX_FIXED ) <nl> wrmsrl ( hwc -> config_base , NHMEX_PMON_CTL_EN_BIT0 ); <nl> else if ( box -> pmu -> type -> event_mask & NHMEX_PMON_CTL_EN_BIT0 ) <nl> wrmsrl ( hwc -> config_base , hwc -> config | NHMEX_PMON_CTL_EN_BIT22 );
static int cpufreq_online ( unsigned int cpu ) <nl> if ( new_policy ) { <nl> /* related_cpus should at least include policy -> cpus . */ <nl> cpumask_copy ( policy -> related_cpus , policy -> cpus ); <nl> - /* Clear mask of registered CPUs */ <nl> - cpumask_clear ( policy -> real_cpus ); <nl> } <nl>  <nl> /*
xfs_rtfree_range ( <nl> */ <nl> error = xfs_rtfind_forw ( mp , tp , end , mp -> m_sb . sb_rextents - 1 , <nl> & postblock ); <nl> + if ( error ) <nl> + return error ; <nl> /* <nl> * If there are blocks not being freed at the front of the <nl> * old extent , add summary data for them to be allocated .
static void pwmled_brightness ( struct led_classdev * cdev , enum led_brightness b ) <nl> * NOTE : we reuse the platform_data structure of GPIO leds , <nl> * but repurpose its " gpio " number as a PWM channel number . <nl> */ <nl> - static int __init pwmled_probe ( struct platform_device * pdev ) <nl> + static int __devinit pwmled_probe ( struct platform_device * pdev ) <nl> { <nl> const struct gpio_led_platform_data * pdata ; <nl> struct pwmled * leds ;
static int smsdvb_hotplug ( struct smscore_device_t * coredev , <nl> switch ( smscore_get_device_mode ( coredev )) { <nl> case DEVICE_MODE_DVBT : <nl> case DEVICE_MODE_DVBT_BDA : <nl> - smsdvb_fe_ops . delsys [ 0 ] = SYS_DVBT ; <nl> + client -> frontend . ops . delsys [ 0 ] = SYS_DVBT ; <nl> break ; <nl> case DEVICE_MODE_ISDBT : <nl> case DEVICE_MODE_ISDBT_BDA : <nl> - smsdvb_fe_ops . delsys [ 0 ] = SYS_ISDBT ; <nl> + client -> frontend . ops . delsys [ 0 ] = SYS_ISDBT ; <nl> break ; <nl> } <nl> 
static ssize_t field ## _show ( struct device * dev , \ <nl> char * buf ) \ <nl> { \ <nl> struct gb_interface * intf = to_gb_interface ( dev ); \ <nl> - return sprintf ( buf , "%"# type "\ n ", intf -> field ); \ <nl> + return scnprintf ( buf , PAGE_SIZE , "%"# type "\ n ", intf -> field ); \ <nl> } \ <nl> static DEVICE_ATTR_RO ( field ) <nl> 
int kvm_arch_vcpu_init ( struct kvm_vcpu * vcpu ) <nl> } <nl> vcpu -> arch . mcg_cap = KVM_MAX_MCE_BANKS ; <nl>  <nl> - if (! zalloc_cpumask_var (& vcpu -> arch . wbinvd_dirty_mask , GFP_KERNEL )) <nl> + if (! zalloc_cpumask_var (& vcpu -> arch . wbinvd_dirty_mask , GFP_KERNEL )) { <nl> + r = - ENOMEM ; <nl> goto fail_free_mce_banks ; <nl> + } <nl>  <nl> r = fx_init ( vcpu ); <nl> if ( r )
static void walk_linearmapping ( struct pg_state * st ) <nl> unsigned long psize = 1 << mmu_psize_defs [ mmu_linear_psize ]. shift ; <nl>  <nl> for ( addr = PAGE_OFFSET ; addr < PAGE_OFFSET + <nl> - memblock_phys_mem_size (); addr += psize ) <nl> + memblock_end_of_DRAM (); addr += psize ) <nl> hpte_find ( st , addr , mmu_linear_psize ); <nl> } <nl> 
static int sun8i_vi_layer_atomic_check ( struct drm_plane * plane , <nl> clip . x2 = crtc_state -> adjusted_mode . hdisplay ; <nl> clip . y2 = crtc_state -> adjusted_mode . vdisplay ; <nl>  <nl> + min_scale = DRM_PLANE_HELPER_NO_SCALING ; <nl> + max_scale = DRM_PLANE_HELPER_NO_SCALING ; <nl> + <nl> if ( layer -> mixer -> cfg -> scaler_mask & BIT ( layer -> channel )) { <nl> min_scale = SUN8I_VI_SCALER_SCALE_MIN ; <nl> max_scale = SUN8I_VI_SCALER_SCALE_MAX ;
void perf_callchain_user ( struct perf_callchain_entry * entry , <nl> return ; <nl> } <nl>  <nl> + perf_callchain_store ( entry , regs -> pc ); <nl> tail = ( struct frame_tail __user *) regs -> regs [ 29 ]; <nl>  <nl> while ( entry -> nr < PERF_MAX_STACK_DEPTH &&
static int picolcd_raw_event ( struct hid_device * hdev , <nl> if (! data ) <nl> return 1 ; <nl>  <nl> + if ( size > 64 ) { <nl> + hid_warn ( hdev , " invalid size value (% d ) for picolcd raw event \ n ", <nl> + size ); <nl> + return 0 ; <nl> + } <nl> + <nl> if ( report -> id == REPORT_KEY_STATE ) { <nl> if ( data -> input_keys ) <nl> ret = picolcd_raw_keypad ( data , report , raw_data + 1 , size - 1 );
int ___ieee80211_stop_tx_ba_session ( struct sta_info * sta , u16 tid , <nl>  <nl> spin_lock_bh (& sta -> lock ); <nl>  <nl> + /* free struct pending for start , if present */ <nl> + tid_tx = sta -> ampdu_mlme . tid_start_tx [ tid ]; <nl> + kfree ( tid_tx ); <nl> + sta -> ampdu_mlme . tid_start_tx [ tid ] = NULL ; <nl> + <nl> tid_tx = rcu_dereference_protected_tid_tx ( sta , tid ); <nl> if (! tid_tx ) { <nl> spin_unlock_bh (& sta -> lock );
static int pfkey_register ( struct sock * sk , struct sk_buff * skb , const struct sad <nl> pfk -> registered |= ( 1 << hdr -> sadb_msg_satype ); <nl> } <nl>  <nl> + mutex_lock (& pfkey_mutex ); <nl> xfrm_probe_algs (); <nl>  <nl> supp_skb = compose_sadb_supported ( hdr , GFP_KERNEL | __GFP_ZERO ); <nl> + mutex_unlock (& pfkey_mutex ); <nl> + <nl> if (! supp_skb ) { <nl> if ( hdr -> sadb_msg_satype != SADB_SATYPE_UNSPEC ) <nl> pfk -> registered &= ~( 1 << hdr -> sadb_msg_satype );
static ssize_t oz_cdev_write ( struct file * filp , const char __user * buf , <nl> struct oz_app_hdr * app_hdr ; <nl> struct oz_serial_ctx * ctx ; <nl>  <nl> + if ( count > sizeof ( ei -> data ) - sizeof (* elt ) - sizeof (* app_hdr )) <nl> + return - EINVAL ; <nl> + <nl> spin_lock_bh (& g_cdev . lock ); <nl> pd = g_cdev . active_pd ; <nl> if ( pd )
static void bpf_tcp_release ( struct sock * sk ) <nl> psock -> cork = NULL ; <nl> } <nl>  <nl> - sk -> sk_prot = psock -> sk_proto ; <nl> - psock -> sk_proto = NULL ; <nl> + if ( psock -> sk_proto ) { <nl> + sk -> sk_prot = psock -> sk_proto ; <nl> + psock -> sk_proto = NULL ; <nl> + } <nl> out : <nl> rcu_read_unlock (); <nl> }
static int spi_ppc4xx_of_probe ( struct platform_device * op ) <nl> if ( num_gpios > 0 ) { <nl> int i ; <nl>  <nl> - hw -> gpios = kzalloc ( sizeof ( int ) * num_gpios , GFP_KERNEL ); <nl> + hw -> gpios = kcalloc ( num_gpios , sizeof (* hw -> gpios ), GFP_KERNEL ); <nl> if (! hw -> gpios ) { <nl> ret = - ENOMEM ; <nl> goto free_master ;
static long tce_iommu_register_pages ( struct tce_container * container , <nl> return ret ; <nl>  <nl> tcemem = kzalloc ( sizeof (* tcemem ), GFP_KERNEL ); <nl> + if (! tcemem ) { <nl> + mm_iommu_put ( container -> mm , mem ); <nl> + return - ENOMEM ; <nl> + } <nl> + <nl> tcemem -> mem = mem ; <nl> list_add (& tcemem -> next , & container -> prereg_list ); <nl> 
pxa3xx_gcu_write ( struct file * file , const char * buff , <nl> struct pxa3xx_gcu_batch * buffer ; <nl> struct pxa3xx_gcu_priv * priv = to_pxa3xx_gcu_priv ( file ); <nl>  <nl> - int words = count / 4 ; <nl> + size_t words = count / 4 ; <nl>  <nl> /* Does not need to be atomic . There ' s a lock in user space , <nl> * but anyhow , this is just for statistics . */
int btrfs_search_slot_for_read ( struct btrfs_root * root , <nl> if ( ret < 0 ) <nl> return ret ; <nl> if (! ret ) { <nl> - p -> slots [ 0 ] = btrfs_header_nritems ( leaf ) - 1 ; <nl> + leaf = p -> nodes [ 0 ]; <nl> + if ( p -> slots [ 0 ] == btrfs_header_nritems ( leaf )) <nl> + p -> slots [ 0 ]--; <nl> return 0 ; <nl> } <nl> if (! return_any )
static const char * alc_get_line_out_pfx ( const struct auto_pin_cfg * cfg , <nl>  <nl> switch ( cfg -> line_out_type ) { <nl> case AUTO_PIN_SPEAKER_OUT : <nl> - return " Speaker "; <nl> + if ( cfg -> line_outs == 1 ) <nl> + return " Speaker "; <nl> + break ; <nl> case AUTO_PIN_HP_OUT : <nl> return " Headphone "; <nl> default :
ssize_t btrfs_listxattr ( struct dentry * dentry , char * buffer , size_t size ) <nl>  <nl> if (! buffer || ( name_len + 1 ) > size_left ) { <nl> ret = - ERANGE ; <nl> - break ; <nl> + goto err ; <nl> } <nl>  <nl> name_ptr = ( unsigned long )( di + 1 );
int jbd2__journal_restart ( handle_t * handle , int nblocks , gfp_t gfp_mask ) <nl>  <nl> rwsem_release (& journal -> j_trans_commit_map , 1 , _THIS_IP_ ); <nl> handle -> h_buffer_credits = nblocks ; <nl> + /* <nl> + * Restore the original nofs context because the journal restart <nl> + * is basically the same thing as journal stop and start . <nl> + * start_this_handle will start a new nofs context . <nl> + */ <nl> + memalloc_nofs_restore ( handle -> saved_alloc_context ); <nl> ret = start_this_handle ( journal , handle , gfp_mask ); <nl> return ret ; <nl> }
aoenet_xmit ( struct sk_buff_head * queue ) <nl> { <nl> struct sk_buff * skb , * tmp ; <nl>  <nl> - skb_queue_walk_safe ( queue , skb , tmp ) <nl> + skb_queue_walk_safe ( queue , skb , tmp ) { <nl> + __skb_unlink ( skb , queue ); <nl> dev_queue_xmit ( skb ); <nl> + } <nl> } <nl>  <nl> /*
static int fuse_fill_super ( struct super_block * sb , void * data , int silent ) <nl> err_put_root : <nl> dput ( root_dentry ); <nl> err_put_conn : <nl> + bdi_destroy (& fc -> bdi ); <nl> fuse_conn_put ( fc ); <nl> err_fput : <nl> fput ( file );
static int __init alloc_node_page_cgroup ( int nid ) <nl> start_pfn = NODE_DATA ( nid )-> node_start_pfn ; <nl> nr_pages = NODE_DATA ( nid )-> node_spanned_pages ; <nl>  <nl> + if (! nr_pages ) <nl> + return 0 ; <nl> + <nl> table_size = sizeof ( struct page_cgroup ) * nr_pages ; <nl>  <nl> base = __alloc_bootmem_node_nopanic ( NODE_DATA ( nid ),
static void flush_tlb_others_ipi ( const struct cpumask * cpumask , <nl> * We have to send the IPI only to <nl> * CPUs affected . <nl> */ <nl> - send_IPI_mask ( cpumask , INVALIDATE_TLB_VECTOR_START + sender ); <nl> + send_IPI_mask ( f -> flush_cpumask , INVALIDATE_TLB_VECTOR_START + sender ); <nl>  <nl> while (! cpumask_empty ( to_cpumask ( f -> flush_cpumask ))) <nl> cpu_relax ();
static int tsi721_rio_map_inb_mem ( struct rio_mport * mport , dma_addr_t lstart , <nl> } else if ( ibw_start < ( ib_win -> rstart + ib_win -> size ) && <nl> ( ibw_start + ibw_size ) > ib_win -> rstart ) { <nl> /* Return error if address translation involved */ <nl> - if ( direct && ib_win -> xlat ) { <nl> + if (! direct || ib_win -> xlat ) { <nl> ret = - EFAULT ; <nl> break ; <nl> }
static int sst_platform_open ( struct snd_pcm_substream * substream ) <nl> ret_val = register_sst_card ( stream -> sstdrv_ops ); <nl> if ( ret_val ) { <nl> pr_err (" sst : sst card registration failed \ n "); <nl> + kfree ( stream -> sstdrv_ops ); <nl> + kfree ( stream ); <nl> return ret_val ; <nl> } <nl> runtime -> private_data = stream ;
static int palmas_i2c_probe ( struct i2c_client * i2c , <nl> ret = - ENOMEM ; <nl> goto err ; <nl> } <nl> + palmas -> i2c_clients [ i ]-> dev . of_node = of_node_get ( node ); <nl> } <nl> palmas -> regmap [ i ] = devm_regmap_init_i2c ( palmas -> i2c_clients [ i ], <nl> & palmas_regmap_config [ i ]);
static int llc_ui_sendmsg ( struct socket * sock , struct msghdr * msg , size_t len ) <nl> if ( size > llc -> dev -> mtu ) <nl> size = llc -> dev -> mtu ; <nl> copied = size - hdrlen ; <nl> + rc = - EINVAL ; <nl> + if ( copied < 0 ) <nl> + goto release ; <nl> release_sock ( sk ); <nl> skb = sock_alloc_send_skb ( sk , size , noblock , & rc ); <nl> lock_sock ( sk );
static int kvm_vcpu_ioctl_enable_cap ( struct kvm_vcpu * vcpu , <nl>  <nl> switch ( cap -> cap ) { <nl> case KVM_CAP_HYPERV_SYNIC : <nl> + if (! irqchip_in_kernel ( vcpu -> kvm )) <nl> + return - EINVAL ; <nl> return kvm_hv_activate_synic ( vcpu ); <nl> default : <nl> return - EINVAL ;
static void igb_reset_q_vector ( struct igb_adapter * adapter , int v_idx ) <nl> { <nl> struct igb_q_vector * q_vector = adapter -> q_vector [ v_idx ]; <nl>  <nl> + /* Coming from igb_set_interrupt_capability , the vectors are not yet <nl> + * allocated . So , q_vector is NULL so we should stop here . <nl> + */ <nl> + if (! q_vector ) <nl> + return ; <nl> + <nl> if ( q_vector -> tx . ring ) <nl> adapter -> tx_ring [ q_vector -> tx . ring -> queue_index ] = NULL ; <nl> 
void dlm_lowcomms_stop ( void ) <nl> con = __nodeid2con ( i , 0 ); <nl> if ( con ) { <nl> close_connection ( con , true ); <nl> + if ( con -> othercon ) <nl> + kmem_cache_free ( con_cache , con -> othercon ); <nl> kmem_cache_free ( con_cache , con ); <nl> } <nl> }
int snd_timer_stop ( struct snd_timer_instance * timeri ) <nl> if ( err < 0 ) <nl> return err ; <nl> timer = timeri -> timer ; <nl> + if (! timer ) <nl> + return - EINVAL ; <nl> spin_lock_irqsave (& timer -> lock , flags ); <nl> timeri -> cticks = timeri -> ticks ; <nl> timeri -> pticks = 0 ;
int dccp_rcv_state_process ( struct sock * sk , struct sk_buff * skb , <nl> if ( inet_csk ( sk )-> icsk_af_ops -> conn_request ( sk , <nl> skb ) < 0 ) <nl> return 1 ; <nl> - goto discard ; <nl> + consume_skb ( skb ); <nl> + return 0 ; <nl> } <nl> if ( dh -> dccph_type == DCCP_PKT_RESET ) <nl> goto discard ;
static int usbduxsigma_auto_attach ( struct comedi_device * dev , <nl> } <nl>  <nl> ret = usbduxsigma_alloc_usb_buffers ( dev ); <nl> - if ( ret ) { <nl> - tidy_up ( devpriv ); <nl> + if ( ret ) <nl> return ret ; <nl> - } <nl>  <nl> ret = comedi_load_firmware ( dev , & usb -> dev , FIRMWARE , <nl> usbduxsigma_firmware_upload , 0 );
static struct fileIdentDesc * udf_find_entry ( struct inode * dir , <nl> } <nl>  <nl> if (( cfi -> fileCharacteristics & FID_FILE_CHAR_PARENT ) && <nl> - isdotdot ) { <nl> - brelse ( epos . bh ); <nl> - return fi ; <nl> - } <nl> + isdotdot ) <nl> + goto out_ok ; <nl>  <nl> if (! lfi ) <nl> continue ;
void init_tg_cfs_entry ( struct task_group * tg , struct cfs_rq * cfs_rq , <nl> se -> cfs_rq = parent -> my_q ; <nl>  <nl> se -> my_q = cfs_rq ; <nl> - update_load_set (& se -> load , 0 ); <nl> + /* guarantee group entities always have weight */ <nl> + update_load_set (& se -> load , NICE_0_LOAD ); <nl> se -> parent = parent ; <nl> } <nl> 
acpi_status acpi_os_initialize1 ( void ); <nl> int init_acpi_device_notify ( void ); <nl> int acpi_scan_init ( void ); <nl> -# ifdef CONFIG_ACPI_PCI_SLOT <nl> - void acpi_pci_slot_init ( void ); <nl> -# else <nl> - static inline void acpi_pci_slot_init ( void ) { } <nl> -# endif <nl> void acpi_pci_root_init ( void ); <nl> void acpi_pci_link_init ( void ); <nl> void acpi_pci_root_hp_init ( void );
static int disable_periodic ( struct ehci_hcd * ehci ) <nl> ehci_writel ( ehci , cmd , & ehci -> regs -> command ); <nl> /* posted write ... */ <nl>  <nl> + free_cached_itd_list ( ehci ); <nl> + <nl> ehci -> next_uframe = - 1 ; <nl> return 0 ; <nl> }
int btrfs_defrag_file ( struct inode * inode , struct file * file , <nl> i = range -> start >> PAGE_CACHE_SHIFT ; <nl> } <nl> if (! max_to_defrag ) <nl> - max_to_defrag = last_index - 1 ; <nl> + max_to_defrag = last_index ; <nl>  <nl> while ( i <= last_index && defrag_count < max_to_defrag ) { <nl> /*
nvmet_fc_find_target_queue ( struct nvmet_fc_tgtport * tgtport , <nl> u16 qid = nvmet_fc_getqueueid ( connection_id ); <nl> unsigned long flags ; <nl>  <nl> + if ( qid > NVMET_NR_QUEUES ) <nl> + return NULL ; <nl> + <nl> spin_lock_irqsave (& tgtport -> lock , flags ); <nl> list_for_each_entry ( assoc , & tgtport -> assoc_list , a_list ) { <nl> if ( association_id == assoc -> association_id ) {
smb2_query_symlink ( const unsigned int xid , struct cifs_tcon * tcon , <nl> & resp_buftype ); <nl> if (! rc || ! err_iov . iov_base ) { <nl> rc = - ENOENT ; <nl> - goto querty_exit ; <nl> + goto free_path ; <nl> } <nl>  <nl> err_buf = err_iov . iov_base ; <nl> smb2_query_symlink ( const unsigned int xid , struct cifs_tcon * tcon , <nl>  <nl> querty_exit : <nl> free_rsp_buf ( resp_buftype , err_buf ); <nl> + free_path : <nl> kfree ( utf16_path ); <nl> return rc ; <nl> }
static bool gen8_ppgtt_clear_pt ( struct i915_address_space * vm , <nl> GEM_BUG_ON ( pte_end > GEN8_PTES ); <nl>  <nl> bitmap_clear ( pt -> used_ptes , pte , num_entries ); <nl> - <nl> - if ( bitmap_empty ( pt -> used_ptes , GEN8_PTES )) <nl> - return true ; <nl> + if ( USES_FULL_PPGTT ( vm -> i915 )) { <nl> + if ( bitmap_empty ( pt -> used_ptes , GEN8_PTES )) <nl> + return true ; <nl> + } <nl>  <nl> pt_vaddr = kmap_px ( pt ); <nl> 
static int nvme_nvm_submit_user_cmd ( struct request_queue * q , <nl>  <nl> rq -> timeout = timeout ? timeout : ADMIN_TIMEOUT ; <nl>  <nl> - rq -> cmd_flags &= ~ REQ_FAILFAST_DRIVER ; <nl> - <nl> if ( ppa_buf && ppa_len ) { <nl> ppa_list = dma_pool_alloc ( dev -> dma_pool , GFP_KERNEL , & ppa_dma ); <nl> if (! ppa_list ) {
static long evdev_do_ioctl ( struct file * file , unsigned int cmd , <nl> return - EFAULT ; <nl>  <nl> error = input_ff_upload ( dev , & effect , file ); <nl> + if ( error ) <nl> + return error ; <nl>  <nl> if ( put_user ( effect . id , &((( struct ff_effect __user *) p )-> id ))) <nl> return - EFAULT ; <nl>  <nl> - return error ; <nl> + return 0 ; <nl> } <nl>  <nl> /* Multi - number variable - length handlers */
static void qedi_get_boot_tgt_info ( struct nvm_iscsi_block * block , <nl> ipv6_en = !!( block -> generic . ctrl_flags & <nl> NVM_ISCSI_CFG_GEN_IPV6_ENABLED ); <nl>  <nl> - snprintf ( tgt -> iscsi_name , NVM_ISCSI_CFG_ISCSI_NAME_MAX_LEN , "% s \ n ", <nl> + snprintf ( tgt -> iscsi_name , sizeof ( tgt -> iscsi_name ), "% s \ n ", <nl> block -> target [ index ]. target_name . byte ); <nl>  <nl> tgt -> ipv6_en = ipv6_en ;
static void mtk_drm_unbind ( struct device * dev ) <nl> { <nl> struct mtk_drm_private * private = dev_get_drvdata ( dev ); <nl>  <nl> - drm_put_dev ( private -> drm ); <nl> + drm_dev_unregister ( private -> drm ); <nl> + drm_dev_unref ( private -> drm ); <nl> private -> drm = NULL ; <nl> } <nl> 
static int orinoco_ioctl_set_auth ( struct net_device * dev , <nl> */ <nl> if ( param -> value ) { <nl> priv -> tkip_cm_active = 1 ; <nl> - ret = hermes_enable_port ( hw , 0 ); <nl> + ret = hermes_disable_port ( hw , 0 ); <nl> } else { <nl> priv -> tkip_cm_active = 0 ; <nl> - ret = hermes_disable_port ( hw , 0 ); <nl> + ret = hermes_enable_port ( hw , 0 ); <nl> } <nl> break ; <nl> 
void drm_sysfs_destroy ( void ) <nl> */ <nl> static void drm_sysfs_device_release ( struct device * dev ) <nl> { <nl> + memset ( dev , 0 , sizeof ( struct device )); <nl> return ; <nl> } <nl> 
static int snd_timer_user_params ( struct file * file , <nl> if ( tu -> timeri -> flags & SNDRV_TIMER_IFLG_EARLY_EVENT ) { <nl> if ( tu -> tread ) { <nl> struct snd_timer_tread tread ; <nl> + memset (& tread , 0 , sizeof ( tread )); <nl> tread . event = SNDRV_TIMER_EVENT_EARLY ; <nl> tread . tstamp . tv_sec = 0 ; <nl> tread . tstamp . tv_nsec = 0 ;
static void ar5008_hw_init_bb ( struct ath_hw * ah , <nl> else <nl> synthDelay /= 10 ; <nl>  <nl> + if ( IS_CHAN_HALF_RATE ( chan )) <nl> + synthDelay *= 2 ; <nl> + else if ( IS_CHAN_QUARTER_RATE ( chan )) <nl> + synthDelay *= 4 ; <nl> + <nl> REG_WRITE ( ah , AR_PHY_ACTIVE , AR_PHY_ACTIVE_EN ); <nl>  <nl> udelay ( synthDelay + BASE_ACTIVATE_DELAY );
__cpuinit int unsynchronized_tsc ( void ) <nl> if ( boot_cpu_data . x86_vendor == X86_VENDOR_INTEL ) { <nl> # ifdef CONFIG_ACPI <nl> /* But TSC doesn ' t tick in C3 so don ' t use it there */ <nl> - if ( acpi_fadt . length > 0 && acpi_fadt . plvl3_lat < 100 ) <nl> + if ( acpi_fadt . length > 0 && acpi_fadt . plvl3_lat < 1000 ) <nl> return 1 ; <nl> # endif <nl> return 0 ;
snd_usb_audio_probe ( struct usb_device * dev , <nl> __error : <nl> if ( chip && ! chip -> num_interfaces ) <nl> snd_card_free ( chip -> card ); <nl> + chip -> probing = 0 ; <nl> mutex_unlock (& register_mutex ); <nl> __err_val : <nl> return NULL ;
static __inline__ void atomic64_set_mask ( unsigned long mask , atomic64_t * v ) <nl> __CSG_LOOP ( v , mask , " ogr "); <nl> } <nl>  <nl> +# define atomic64_xchg ( v , new ) ( xchg (&(( v )-> counter ), new )) <nl> + <nl> static __inline__ long long atomic64_cmpxchg ( atomic64_t * v , <nl> long long old , long long new ) <nl> {
static void __init early_identify_cpu ( struct cpuinfo_x86 * c ) <nl>  <nl> setup_force_cpu_cap ( X86_FEATURE_ALWAYS ); <nl>  <nl> - /* Assume for now that ALL x86 CPUs are insecure */ <nl> - setup_force_cpu_bug ( X86_BUG_CPU_INSECURE ); <nl> + if ( c -> x86_vendor != X86_VENDOR_AMD ) <nl> + setup_force_cpu_bug ( X86_BUG_CPU_INSECURE ); <nl>  <nl> fpu__init_system ( c ); <nl> 
bool drm_i2c_encoder_mode_fixup ( struct drm_encoder * encoder , <nl> const struct drm_display_mode * mode , <nl> struct drm_display_mode * adjusted_mode ) <nl> { <nl> + if (! get_slave_funcs ( encoder )-> mode_fixup ) <nl> + return true ; <nl> + <nl> return get_slave_funcs ( encoder )-> mode_fixup ( encoder , mode , adjusted_mode ); <nl> } <nl> EXPORT_SYMBOL ( drm_i2c_encoder_mode_fixup );
int sst_hsw_stream_get_volume ( struct sst_hsw * hsw , struct sst_hsw_stream * stream <nl> return - EINVAL ; <nl>  <nl> sst_dsp_read ( hsw -> dsp , volume , <nl> - stream -> reply . volume_register_address [ channel ], sizeof ( volume )); <nl> + stream -> reply . volume_register_address [ channel ], <nl> + sizeof (* volume )); <nl>  <nl> return 0 ; <nl> }
static inline bool kvm_apic_vid_enabled ( struct kvm * kvm ) <nl>  <nl> static inline bool kvm_apic_has_events ( struct kvm_vcpu * vcpu ) <nl> { <nl> - return vcpu -> arch . apic -> pending_events ; <nl> + return kvm_vcpu_has_lapic ( vcpu ) && vcpu -> arch . apic -> pending_events ; <nl> } <nl>  <nl> static inline bool kvm_lowest_prio_delivery ( struct kvm_lapic_irq * irq )
xfs_acl_from_disk ( struct xfs_acl * aclp ) <nl> int count , i ; <nl>  <nl> count = be32_to_cpu ( aclp -> acl_cnt ); <nl> + if ( count > XFS_ACL_MAX_ENTRIES ) <nl> + return ERR_PTR (- EFSCORRUPTED ); <nl>  <nl> acl = posix_acl_alloc ( count , GFP_KERNEL ); <nl> if (! acl )
int skl_bind_modules ( struct skl_sst * ctx , <nl>  <nl> skl_dump_bind_info ( ctx , src_mcfg , dst_mcfg ); <nl>  <nl> - if ( src_mcfg -> m_state < SKL_MODULE_INIT_DONE && <nl> + if ( src_mcfg -> m_state < SKL_MODULE_INIT_DONE || <nl> dst_mcfg -> m_state < SKL_MODULE_INIT_DONE ) <nl> return 0 ; <nl> 
static int s5p64x0_alloc_gc ( void ) <nl> } <nl>  <nl> ct = gc -> chip_types ; <nl> - ct -> chip . irq_ack = irq_gc_ack ; <nl> + ct -> chip . irq_ack = irq_gc_ack_set_bit ; <nl> ct -> chip . irq_mask = irq_gc_mask_set_bit ; <nl> ct -> chip . irq_unmask = irq_gc_mask_clr_bit ; <nl> ct -> chip . irq_set_type = s5p64x0_irq_eint_set_type ;
static int wl1271_op_hw_scan ( struct ieee80211_hw * hw , <nl> static int wl1271_op_set_rts_threshold ( struct ieee80211_hw * hw , u32 value ) <nl> { <nl> struct wl1271 * wl = hw -> priv ; <nl> - int ret ; <nl> + int ret = 0 ; <nl>  <nl> mutex_lock (& wl -> mutex ); <nl>  <nl> + if ( unlikely ( wl -> state == WL1271_STATE_OFF )) <nl> + goto out ; <nl> + <nl> ret = wl1271_ps_elp_wakeup ( wl , false ); <nl> if ( ret < 0 ) <nl> goto out ;
static int __sock_diag_rcv_msg ( struct sk_buff * skb , struct nlmsghdr * nlh ) <nl> if ( nlmsg_len ( nlh ) < sizeof (* req )) <nl> return - EINVAL ; <nl>  <nl> + if ( req -> sdiag_family >= AF_MAX ) <nl> + return - EINVAL ; <nl> + <nl> hndl = sock_diag_lock_handler ( req -> sdiag_family ); <nl> if ( hndl == NULL ) <nl> err = - ENOENT ;
scsi_reset_provider ( struct scsi_device * dev , int flag ) <nl> rtn = FAILED ; <nl> } <nl>  <nl> - scsi_delete_timer ( scmd ); <nl> scsi_next_command ( scmd ); <nl> return rtn ; <nl> }
static int fnic_fcpio_fw_reset_cmpl_handler ( struct fnic * fnic , <nl>  <nl> atomic64_set (& fnic -> fnic_stats . fw_stats . active_fw_reqs , 0 ); <nl> atomic64_set (& fnic -> fnic_stats . io_stats . active_ios , 0 ); <nl> + atomic64_set (& fnic -> io_cmpl_skip , 0 ); <nl>  <nl> spin_lock_irqsave (& fnic -> fnic_lock , flags ); <nl> 
static int nodemgr_host_thread ( void * data ) <nl> g = get_hpsb_generation ( host ); <nl> for ( i = 0 ; i < 4 ; i ++) { <nl> msleep_interruptible ( 63 ); <nl> + try_to_freeze (); <nl> if ( kthread_should_stop ()) <nl> goto exit ; <nl>  <nl> static int nodemgr_host_thread ( void * data ) <nl> /* Sleep 3 seconds */ <nl> for ( i = 3000 / 200 ; i ; i --) { <nl> msleep_interruptible ( 200 ); <nl> + try_to_freeze (); <nl> if ( kthread_should_stop ()) <nl> goto exit ; <nl> 
static loff_t fuse_file_llseek ( struct file * file , loff_t offset , int origin ) <nl> mutex_lock (& inode -> i_mutex ); <nl> switch ( origin ) { <nl> case SEEK_END : <nl> + retval = fuse_update_attributes ( inode , NULL , file , NULL ); <nl> + if ( retval ) <nl> + return retval ; <nl> offset += i_size_read ( inode ); <nl> break ; <nl> case SEEK_CUR :
static void __init clk_sp810_of_setup ( struct device_node * node ) <nl>  <nl> if ( of_clk_parent_fill ( node , parent_names , num ) != num ) { <nl> pr_warn (" Failed to obtain parent clocks for SP810 !\ n "); <nl> + kfree ( sp810 ); <nl> return ; <nl> } <nl> 
static int mv643xx_eth_set_mac_address ( struct net_device * dev , void * addr ) <nl> { <nl> struct sockaddr * sa = addr ; <nl>  <nl> + if (! is_valid_ether_addr ( sa -> sa_data )) <nl> + return - EINVAL ; <nl> + <nl> memcpy ( dev -> dev_addr , sa -> sa_data , ETH_ALEN ); <nl>  <nl> netif_addr_lock_bh ( dev );
static int cachefiles_mark_object_active ( struct cachefiles_cache * cache , <nl> /* an old object from a previous incarnation is hogging the slot - we <nl> * need to wait for it to be destroyed */ <nl> wait_for_old_object : <nl> - if ( fscache_object_is_live (& object -> fscache )) { <nl> + if ( fscache_object_is_live (& xobject -> fscache )) { <nl> pr_err ("\ n "); <nl> pr_err (" Error : Unexpected object collision \ n "); <nl> cachefiles_printk_object ( object , xobject );
static long gntalloc_ioctl_alloc ( struct gntalloc_file_private_data * priv , <nl> goto out ; <nl> } <nl>  <nl> - gref_ids = kzalloc ( sizeof ( gref_ids [ 0 ]) * op . count , GFP_TEMPORARY ); <nl> + gref_ids = kcalloc ( op . count , sizeof ( gref_ids [ 0 ]), GFP_TEMPORARY ); <nl> if (! gref_ids ) { <nl> rc = - ENOMEM ; <nl> goto out ;
int kvm_timer_enable ( struct kvm_vcpu * vcpu ) <nl> return ret ; <nl>  <nl> no_vgic : <nl> + preempt_disable (); <nl> timer -> enabled = 1 ; <nl> + kvm_timer_vcpu_load_vgic ( vcpu ); <nl> + preempt_enable (); <nl> + <nl> return 0 ; <nl> } <nl> 
static int aac_send_raw_srb ( struct aac_dev * dev , void __user * arg ) <nl> goto cleanup ; <nl> } <nl>  <nl> - user_srbcmd = kmalloc ( GFP_KERNEL , fibsize ); <nl> + user_srbcmd = kmalloc ( fibsize , GFP_KERNEL ); <nl> if (! user_srbcmd ) { <nl> dprintk (( KERN_DEBUG " aacraid : Could not make a copy of the srb \ n ")); <nl> rcode = - ENOMEM ;
static void ath9k_htc_send_buffered ( struct ath9k_htc_priv * priv , <nl> } <nl>  <nl> tx_slot = ath9k_htc_tx_get_slot ( priv ); <nl> - if ( tx_slot != 0 ) { <nl> + if ( tx_slot < 0 ) { <nl> ath_dbg ( common , ATH_DBG_XMIT , " No free CAB slot \ n "); <nl> dev_kfree_skb_any ( skb ); <nl> goto next ;
static ktime_t tick_nohz_stop_sched_tick ( struct tick_sched * ts , <nl> */ <nl> if ( delta == 0 ) { <nl> tick_nohz_restart ( ts , now ); <nl> + /* <nl> + * Make sure next tick stop doesn ' t get fooled by past <nl> + * clock deadline <nl> + */ <nl> + ts -> next_tick = 0 ; <nl> goto out ; <nl> } <nl> }
int perf_cpu_time_max_percent_handler ( struct ctl_table * table , int write , <nl> void __user * buffer , size_t * lenp , <nl> loff_t * ppos ) <nl> { <nl> - int ret = proc_dointvec ( table , write , buffer , lenp , ppos ); <nl> + int ret = proc_dointvec_minmax ( table , write , buffer , lenp , ppos ); <nl>  <nl> if ( ret || ! write ) <nl> return ret ;
static void hpfs_write_failed ( struct address_space * mapping , loff_t to ) <nl> { <nl> struct inode * inode = mapping -> host ; <nl>  <nl> + hpfs_lock ( inode -> i_sb ); <nl> + <nl> if ( to > inode -> i_size ) { <nl> truncate_pagecache ( inode , to , inode -> i_size ); <nl> hpfs_truncate ( inode ); <nl> } <nl> + <nl> + hpfs_unlock ( inode -> i_sb ); <nl> } <nl>  <nl> static int hpfs_write_begin ( struct file * file , struct address_space * mapping ,
static struct hardwall_info * hardwall_create ( <nl> /* Allocate a new rectangle optimistically . */ <nl> rect = kmalloc ( sizeof ( struct hardwall_info ), <nl> GFP_KERNEL | __GFP_ZERO ); <nl> + if ( rect == NULL ) <nl> + return ERR_PTR (- ENOMEM ); <nl> INIT_LIST_HEAD (& rect -> task_head ); <nl>  <nl> /* Compute the rectangle size and validate that it ' s plausible . */
static struct gfs2_leaf * new_leaf ( struct inode * inode , struct buffer_head ** pbh , <nl> leaf = ( struct gfs2_leaf *) bh -> b_data ; <nl> leaf -> lf_depth = cpu_to_be16 ( depth ); <nl> leaf -> lf_entries = 0 ; <nl> - leaf -> lf_dirent_format = cpu_to_be16 ( GFS2_FORMAT_DE ); <nl> + leaf -> lf_dirent_format = cpu_to_be32 ( GFS2_FORMAT_DE ); <nl> leaf -> lf_next = 0 ; <nl> memset ( leaf -> lf_reserved , 0 , sizeof ( leaf -> lf_reserved )); <nl> dent = ( struct gfs2_dirent *)( leaf + 1 );
static struct i2c_board_info __initdata snapper9260_i2c_devices [] = { <nl> { <nl> /* RTC */ <nl> I2C_BOARD_INFO (" isl1208 ", 0x6f ), <nl> + . irq = gpio_to_irq ( AT91_PIN_PA31 ), <nl> }, <nl> }; <nl> 
struct device * driver_find_device ( struct device_driver * drv , <nl> struct klist_iter i ; <nl> struct device * dev ; <nl>  <nl> - if (! drv ) <nl> + if (! drv || ! drv -> p ) <nl> return NULL ; <nl>  <nl> klist_iter_init_node (& drv -> p -> klist_devices , & i ,
static long compat_ipmi_ioctl ( struct file * filep , unsigned int cmd , <nl> struct ipmi_recv __user * precv64 ; <nl> struct ipmi_recv recv64 ; <nl>  <nl> + memset (& recv64 , 0 , sizeof ( recv64 )); <nl> if ( get_compat_ipmi_recv (& recv64 , compat_ptr ( arg ))) <nl> return - EFAULT ; <nl> 
static void tcm_loop_submission_work ( struct work_struct * work ) <nl> return ; <nl>  <nl> out_done : <nl> + kmem_cache_free ( tcm_loop_cmd_cache , tl_cmd ); <nl> sc -> scsi_done ( sc ); <nl> return ; <nl> }
static void ufs_mtk_init_va09_pwr_ctrl ( struct ufs_hba * hba ) <nl> struct ufs_mtk_host * host = ufshcd_get_variant ( hba ); <nl>  <nl> host -> reg_va09 = regulator_get ( hba -> dev , " va09 "); <nl> - if (! host -> reg_va09 ) <nl> + if ( IS_ERR ( host -> reg_va09 )) <nl> dev_info ( hba -> dev , " failed to get va09 "); <nl> else <nl> host -> caps |= UFS_MTK_CAP_VA09_PWR_CTRL ;
struct rxrpc_connection * rxrpc_find_service_conn_rcu ( struct rxrpc_peer * peer , <nl> else if ( conn -> proto . index_key > k . index_key ) <nl> p = rcu_dereference_raw ( p -> rb_right ); <nl> else <nl> - goto done ; <nl> + break ; <nl> conn = NULL ; <nl> } <nl> } while ( need_seqretry (& peer -> service_conn_lock , seq )); <nl>  <nl> - done : <nl> done_seqretry (& peer -> service_conn_lock , seq ); <nl> _leave (" = % d ", conn ? conn -> debug_id : - 1 ); <nl> return conn ;
xfs_dir2_leafn_remove ( <nl> /* <nl> * One less used entry in the free table . <nl> */ <nl> - free -> hdr . nused = cpu_to_be32 (- 1 ); <nl> + be32_add (& free -> hdr . nused , - 1 ); <nl> xfs_dir2_free_log_header ( tp , fbp ); <nl> /* <nl> * If this was the last entry in the table , we can
static int perf_event__repipe_attr ( struct perf_tool * tool , <nl> union perf_event * event , <nl> struct perf_evlist ** pevlist ) <nl> { <nl> + struct perf_inject * inject = container_of ( tool , struct perf_inject , <nl> + tool ); <nl> int ret ; <nl>  <nl> ret = perf_event__process_attr ( tool , event , pevlist ); <nl> if ( ret ) <nl> return ret ; <nl>  <nl> + if (! inject -> pipe_output ) <nl> + return 0 ; <nl> + <nl> return perf_event__repipe_synth ( tool , event ); <nl> } <nl> 
void __key_link_end ( struct key * keyring , <nl> if ( index_key -> type == & key_type_keyring ) <nl> up_write (& keyring_serialise_link_sem ); <nl>  <nl> - if ( edit && ! edit -> dead_leaf ) { <nl> - key_payload_reserve ( keyring , <nl> - keyring -> datalen - KEYQUOTA_LINK_BYTES ); <nl> + if ( edit ) { <nl> + if (! edit -> dead_leaf ) { <nl> + key_payload_reserve ( keyring , <nl> + keyring -> datalen - KEYQUOTA_LINK_BYTES ); <nl> + } <nl> assoc_array_cancel_edit ( edit ); <nl> } <nl> up_write (& keyring -> sem );
ip_vs_new_dest ( struct ip_vs_service * svc , struct ip_vs_dest_user_kern * udest , <nl> # ifdef CONFIG_IP_VS_IPV6 <nl> if ( svc -> af == AF_INET6 ) { <nl> atype = ipv6_addr_type (& udest -> addr . in6 ); <nl> - if (!( atype & IPV6_ADDR_UNICAST ) && <nl> + if ((!( atype & IPV6_ADDR_UNICAST ) || <nl> + atype & IPV6_ADDR_LINKLOCAL ) && <nl> ! __ip_vs_addr_is_local_v6 (& udest -> addr . in6 )) <nl> return - EINVAL ; <nl> } else
static int alc_mux_select ( struct hda_codec * codec , unsigned int adc_idx , <nl> int i , type , num_conns ; <nl> hda_nid_t nid ; <nl>  <nl> + if (! spec -> input_mux ) <nl> + return 0 ; <nl> + <nl> mux_idx = adc_idx >= spec -> num_mux_defs ? 0 : adc_idx ; <nl> imux = & spec -> input_mux [ mux_idx ]; <nl> if (! imux -> num_items && mux_idx > 0 )
void wil_halp_vote ( struct wil6210_priv * wil ) <nl> wil -> halp . ref_cnt ); <nl>  <nl> if (++ wil -> halp . ref_cnt == 1 ) { <nl> + reinit_completion (& wil -> halp . comp ); <nl> wil6210_set_halp ( wil ); <nl> rc = wait_for_completion_timeout (& wil -> halp . comp , to_jiffies ); <nl> if (! rc ) {
static int pch_dma_probe ( struct pci_dev * pdev , <nl>  <nl> if (!( pci_resource_flags ( pdev , 1 ) & IORESOURCE_MEM )) { <nl> dev_err (& pdev -> dev , " Cannot find proper base address \ n "); <nl> + err = - ENODEV ; <nl> goto err_disable_pdev ; <nl> } <nl> 
static int clk_fetch_parent_index ( struct clk_core * core , <nl> { <nl> int i ; <nl>  <nl> + if (! parent ) <nl> + return - EINVAL ; <nl> + <nl> /* <nl> * find index of new parent clock using cached parent ptrs , <nl> * or if not yet cached , use string name comparison and cache
static struct irq_info * info_for_irq ( unsigned irq ) <nl>  <nl> static unsigned int evtchn_from_irq ( unsigned irq ) <nl> { <nl> + if ( unlikely ( WARN ( irq < 0 || irq >= nr_irqs , " Invalid irq % d !\ n ", irq ))) <nl> + return 0 ; <nl> + <nl> return info_for_irq ( irq )-> evtchn ; <nl> } <nl> 
void recalc_intercepts ( struct vcpu_svm * svm ) <nl> /* If SMI is not intercepted , ignore guest SMI intercept as well */ <nl> if (! intercept_smi ) <nl> vmcb_clr_intercept ( c , INTERCEPT_SMI ); <nl> + <nl> + vmcb_set_intercept ( c , INTERCEPT_VMLOAD ); <nl> + vmcb_set_intercept ( c , INTERCEPT_VMSAVE ); <nl> } <nl>  <nl> static void copy_vmcb_control_area ( struct vmcb_control_area * dst ,
static int __devinit gab_probe ( struct platform_device * pdev ) <nl> ret = request_any_context_irq ( irq , gab_charged , <nl> IRQF_TRIGGER_RISING | IRQF_TRIGGER_FALLING , <nl> " battery charged ", adc_bat ); <nl> - if ( ret ) <nl> + if ( ret < 0 ) <nl> goto err_gpio ; <nl> } <nl> 
static inline void nfs4_stateid_downgrade ( struct nfs4_ol_stateid * stp , u32 to_ac <nl> } <nl>  <nl> static void <nl> - reset_union_bmap_deny ( unsigned long deny , struct nfs4_ol_stateid * stp ) <nl> + reset_union_bmap_deny ( u32 deny , struct nfs4_ol_stateid * stp ) <nl> { <nl> int i ; <nl> - for ( i = 0 ; i < 4 ; i ++) { <nl> + <nl> + for ( i = 1 ; i < 4 ; i ++) { <nl> if (( i & deny ) != i ) <nl> clear_deny ( i , stp ); <nl> }
static struct rds_connection * __rds_conn_create ( struct net * net , <nl> } <nl> } <nl>  <nl> + if ( trans == NULL ) { <nl> + kmem_cache_free ( rds_conn_slab , conn ); <nl> + conn = ERR_PTR (- ENODEV ); <nl> + goto out ; <nl> + } <nl> + <nl> conn -> c_trans = trans ; <nl>  <nl> ret = trans -> conn_alloc ( conn , gfp );
static int ptrace_bts_config ( struct task_struct * child , <nl> if (! cfg . signal ) <nl> return - EINVAL ; <nl>  <nl> - return - EOPNOTSUPP ; <nl> - <nl> child -> thread . bts_ovfl_signal = cfg . signal ; <nl> + return - EOPNOTSUPP ; <nl> } <nl>  <nl> if (( cfg . flags & PTRACE_BTS_O_ALLOC ) &&
int btrfs_add_inode_defrag ( struct btrfs_trans_handle * trans , <nl> spin_lock (& root -> fs_info -> defrag_inodes_lock ); <nl> if (! BTRFS_I ( inode )-> in_defrag ) <nl> __btrfs_add_inode_defrag ( inode , defrag ); <nl> + else <nl> + kfree ( defrag ); <nl> spin_unlock (& root -> fs_info -> defrag_inodes_lock ); <nl> return 0 ; <nl> }
static inline u32 skb_mstamp_us_delta ( const struct skb_mstamp * t1 , <nl> return delta_us ; <nl> } <nl>  <nl> + static inline bool skb_mstamp_after ( const struct skb_mstamp * t1 , <nl> + const struct skb_mstamp * t0 ) <nl> +{ <nl> + s32 diff = t1 -> stamp_jiffies - t0 -> stamp_jiffies ; <nl> + <nl> + if (! diff ) <nl> + diff = t1 -> stamp_us - t0 -> stamp_us ; <nl> + return diff > 0 ; <nl> +} <nl>  <nl> /** <nl> * struct sk_buff - socket buffer
enum vnt_cmd_state { <nl>  <nl> struct vnt_private ; <nl>  <nl> - void vnt_reset_command_timer ( struct vnt_private *); <nl> + void vnt_reset_command_timer ( struct vnt_private * priv ); <nl>  <nl> - int vnt_schedule_command ( struct vnt_private *, enum vnt_cmd ); <nl> + int vnt_schedule_command ( struct vnt_private * priv , enum vnt_cmd ); <nl>  <nl> void vnt_run_command ( struct work_struct * work ); <nl> 
static LIST_HEAD ( dev_map_list ); <nl>  <nl> static u64 dev_map_bitmap_size ( const union bpf_attr * attr ) <nl> { <nl> - return BITS_TO_LONGS ( attr -> max_entries ) * sizeof ( unsigned long ); <nl> + return BITS_TO_LONGS (( u64 ) attr -> max_entries ) * sizeof ( unsigned long ); <nl> } <nl>  <nl> static struct bpf_map * dev_map_alloc ( union bpf_attr * attr )
struct simple_xattr * simple_xattr_alloc ( const void * value , size_t size ) <nl>  <nl> /* wrap around ? */ <nl> len = sizeof (* new_xattr ) + size ; <nl> - if ( len <= sizeof (* new_xattr )) <nl> + if ( len < sizeof (* new_xattr )) <nl> return NULL ; <nl>  <nl> new_xattr = kmalloc ( len , GFP_KERNEL );
static int atmel_nand_probe ( struct platform_device * pdev ) <nl> } <nl>  <nl> nand_chip -> ecc . mode = host -> board . ecc_mode ; <nl> - nand_chip -> chip_delay = 20 ; /* 20us command delay time */ <nl> + nand_chip -> chip_delay = 40 ; /* 40us command delay time */ <nl>  <nl> if ( host -> board . bus_width_16 ) /* 16 - bit bus width */ <nl> nand_chip -> options |= NAND_BUSWIDTH_16 ;
enum siginfo_layout siginfo_layout ( int sig , int si_code ) <nl> [ SIGSEGV ] = { NSIGSEGV , SIL_FAULT }, <nl> [ SIGBUS ] = { NSIGBUS , SIL_FAULT }, <nl> [ SIGTRAP ] = { NSIGTRAP , SIL_FAULT }, <nl> -# if defined ( SIGMET ) && defined ( NSIGEMT ) <nl> +# if defined ( SIGEMT ) && defined ( NSIGEMT ) <nl> [ SIGEMT ] = { NSIGEMT , SIL_FAULT }, <nl> # endif <nl> [ SIGCHLD ] = { NSIGCHLD , SIL_CHLD },
static int crb_recv ( struct tpm_chip * chip , u8 * buf , size_t count ) <nl>  <nl> memcpy_fromio ( buf , priv -> rsp , 6 ); <nl> expected = be32_to_cpup (( __be32 *) & buf [ 2 ]); <nl> - <nl> - if ( expected > count ) <nl> + if ( expected > count || expected < 6 ) <nl> return - EIO ; <nl>  <nl> memcpy_fromio (& buf [ 6 ], & priv -> rsp [ 6 ], expected - 6 );
static int das1800_attach ( struct comedi_device * dev , <nl> if ( dev -> irq & it -> options [ 2 ]) <nl> das1800_init_dma ( dev , it ); <nl>  <nl> - devpriv -> fifo_buf = kmalloc ( FIFO_SIZE * sizeof ( uint16_t ), GFP_KERNEL ); <nl> + devpriv -> fifo_buf = kmalloc_array ( FIFO_SIZE , sizeof ( uint16_t ), GFP_KERNEL ); <nl> if (! devpriv -> fifo_buf ) <nl> return - ENOMEM ; <nl> 
int key_reject_and_link ( struct key * key , <nl>  <nl> mutex_unlock (& key_construction_mutex ); <nl>  <nl> - if ( keyring ) <nl> + if ( keyring && link_ret == 0 ) <nl> __key_link_end ( keyring , & key -> index_key , edit ); <nl>  <nl> /* wake up anyone waiting for a key to be constructed */
static int ipxitf_ioctl ( unsigned int cmd , void __user * arg ) <nl> sipx -> sipx_network = ipxif -> if_netnum ; <nl> memcpy ( sipx -> sipx_node , ipxif -> if_node , <nl> sizeof ( sipx -> sipx_node )); <nl> - rc = - EFAULT ; <nl> + rc = 0 ; <nl> if ( copy_to_user ( arg , & ifr , sizeof ( ifr ))) <nl> - break ; <nl> + rc = - EFAULT ; <nl> ipxitf_put ( ipxif ); <nl> - rc = 0 ; <nl> break ; <nl> } <nl> case SIOCAIPXITFCRT :
static inline void ipv6_store_devconf ( struct ipv6_devconf * cnf , <nl> # endif <nl> array [ DEVCONF_DISABLE_IPV6 ] = cnf -> disable_ipv6 ; <nl> array [ DEVCONF_ACCEPT_DAD ] = cnf -> accept_dad ; <nl> + array [ DEVCONF_FORCE_TLLAO ] = cnf -> force_tllao ; <nl> } <nl>  <nl> static inline size_t inet6_if_nlmsg_size ( void )
static void intel_pt_insn_decoder ( struct insn * insn , <nl> enum intel_pt_insn_branch branch = INTEL_PT_BR_NO_BRANCH ; <nl> int ext ; <nl>  <nl> + intel_pt_insn -> rel = 0 ; <nl> + <nl> if ( insn_is_avx ( insn )) { <nl> intel_pt_insn -> op = INTEL_PT_OP_OTHER ; <nl> intel_pt_insn -> branch = INTEL_PT_BR_NO_BRANCH ;
bfad_im_get_stats ( struct Scsi_Host * shost ) <nl> rc = bfa_port_get_stats ( BFA_FCPORT (& bfad -> bfa ), <nl> fcstats , bfad_hcb_comp , & fcomp ); <nl> spin_unlock_irqrestore (& bfad -> bfad_lock , flags ); <nl> - if ( rc != BFA_STATUS_OK ) <nl> + if ( rc != BFA_STATUS_OK ) { <nl> + kfree ( fcstats ); <nl> return NULL ; <nl> + } <nl>  <nl> wait_for_completion (& fcomp . comp ); <nl> 
int vfs_quota_on_mount ( struct super_block * sb , char * qf_name , <nl> if ( IS_ERR ( dentry )) <nl> return PTR_ERR ( dentry ); <nl>  <nl> + if (! dentry -> d_inode ) { <nl> + error = - ENOENT ; <nl> + goto out ; <nl> + } <nl> + <nl> error = security_quota_on ( dentry ); <nl> if (! error ) <nl> error = vfs_quota_on_inode ( dentry -> d_inode , type , format_id ); <nl>  <nl> + out : <nl> dput ( dentry ); <nl> return error ; <nl> }
static int virtio_gpu_object_shmem_init ( struct virtio_gpu_device * vgdev , <nl> * since virtio_gpu doesn ' t support dma - buf import from other devices . <nl> */ <nl> shmem -> pages = drm_gem_shmem_get_sg_table (& bo -> base ); <nl> - if (! shmem -> pages ) { <nl> + if ( IS_ERR ( shmem -> pages )) { <nl> drm_gem_shmem_unpin (& bo -> base ); <nl> - return - EINVAL ; <nl> + return PTR_ERR ( shmem -> pages ); <nl> } <nl>  <nl> if ( use_dma_api ) {
struct edac_pci_ctl_info * edac_pci_create_generic_ctl ( struct device * dev , <nl>  <nl> pci -> mod_name = mod_name ; <nl> pci -> ctl_name = EDAC_PCI_GENCTL_NAME ; <nl> - pci -> edac_check = edac_pci_generic_check ; <nl> + if ( edac_op_state == EDAC_OPSTATE_POLL ) <nl> + pci -> edac_check = edac_pci_generic_check ; <nl>  <nl> pdata -> edac_idx = edac_pci_idx ++; <nl> 
static int pulse8_cec_adap_transmit ( struct cec_adapter * adap , u8 attempts , <nl> int err ; <nl>  <nl> cmd [ 0 ] = MSGCODE_TRANSMIT_IDLETIME ; <nl> - cmd [ 1 ] = 3 ; <nl> + cmd [ 1 ] = signal_free_time ; <nl> err = pulse8_send_and_wait ( pulse8 , cmd , 2 , <nl> MSGCODE_COMMAND_ACCEPTED , 1 ); <nl> cmd [ 0 ] = MSGCODE_TRANSMIT_ACK_POLARITY ;
static int efx_ef10_probe ( struct efx_nic * efx ) <nl> EFX_MAX_CHANNELS , <nl> resource_size (& efx -> pci_dev -> resource [ EFX_MEM_BAR ]) / <nl> ( EFX_VI_PAGE_SIZE * EFX_TXQ_TYPES )); <nl> - BUG_ON ( efx -> max_channels == 0 ); <nl> + if ( WARN_ON ( efx -> max_channels == 0 )) <nl> + return - EIO ; <nl>  <nl> nic_data = kzalloc ( sizeof (* nic_data ), GFP_KERNEL ); <nl> if (! nic_data )
static const struct { <nl> . bDescriptorType = USB_DT_ENDPOINT , <nl> . bEndpointAddress = 1 | USB_DIR_IN , <nl> . bmAttributes = USB_ENDPOINT_XFER_BULK , <nl> + . wMaxPacketSize = htole16 ( 512 ), <nl> }, <nl> . bulk_source = { <nl> . bLength = sizeof ( descriptors . hs_descs . bulk_source ), <nl> . bDescriptorType = USB_DT_ENDPOINT , <nl> . bEndpointAddress = 2 | USB_DIR_OUT , <nl> . bmAttributes = USB_ENDPOINT_XFER_BULK , <nl> + . wMaxPacketSize = htole16 ( 512 ), <nl> }, <nl> }, <nl> };
void ide_do_drive_cmd ( ide_drive_t * drive , struct request * rq ) <nl>  <nl> spin_lock_irqsave ( q -> queue_lock , flags ); <nl> __elv_add_request ( q , rq , ELEVATOR_INSERT_FRONT , 0 ); <nl> - blk_start_queueing ( q ); <nl> spin_unlock_irqrestore ( q -> queue_lock , flags ); <nl> } <nl> EXPORT_SYMBOL ( ide_do_drive_cmd );
static void kick_tx ( int fd ) <nl> int ret ; <nl>  <nl> ret = sendto ( fd , NULL , 0 , MSG_DONTWAIT , NULL , 0 ); <nl> - if ( ret >= 0 || errno == ENOBUFS || errno == EAGAIN ) <nl> + if ( ret >= 0 || errno == ENOBUFS || errno == EAGAIN || errno == EBUSY ) <nl> return ; <nl> lassert ( 0 ); <nl> }
static int ipmi_fasync ( int fd , struct file * file , int on ) <nl> struct ipmi_file_private * priv = file -> private_data ; <nl> int result ; <nl>  <nl> + lock_kernel (); /* could race against open () otherwise */ <nl> result = fasync_helper ( fd , file , on , & priv -> fasync_queue ); <nl> + unlock_kernel (); <nl>  <nl> return ( result ); <nl> }
void drm_modeset_acquire_init ( struct drm_modeset_acquire_ctx * ctx , <nl> uint32_t flags ) <nl> { <nl> + memset ( ctx , 0 , sizeof (* ctx )); <nl> ww_acquire_init (& ctx -> ww_ctx , & crtc_ww_class ); <nl> INIT_LIST_HEAD (& ctx -> locked ); <nl> }
struct qcom_glink * qcom_glink_native_probe ( struct device * dev , <nl> idr_init (& glink -> rcids ); <nl>  <nl> glink -> mbox_client . dev = dev ; <nl> + glink -> mbox_client . knows_txdone = true ; <nl> glink -> mbox_chan = mbox_request_channel (& glink -> mbox_client , 0 ); <nl> if ( IS_ERR ( glink -> mbox_chan )) { <nl> if ( PTR_ERR ( glink -> mbox_chan ) != - EPROBE_DEFER )
efx_mcdi_mon_add_attr ( struct efx_nic * efx , const char * name , <nl> attr -> index = index ; <nl> attr -> type = type ; <nl> attr -> limit_value = limit_value ; <nl> + sysfs_attr_init (& attr -> dev_attr . attr ); <nl> attr -> dev_attr . attr . name = attr -> name ; <nl> attr -> dev_attr . attr . mode = S_IRUGO ; <nl> attr -> dev_attr . show = reader ;
long vhost_dev_ioctl ( struct vhost_dev * d , unsigned int ioctl , void __user * argp ) <nl> } <nl> if ( eventfp != d -> log_file ) { <nl> filep = d -> log_file ; <nl> + d -> log_file = eventfp ; <nl> ctx = d -> log_ctx ; <nl> d -> log_ctx = eventfp ? <nl> eventfd_ctx_fileget ( eventfp ) : NULL ;
static int qeth_query_card_info ( struct qeth_card * card , <nl>  <nl> static inline int qeth_get_qdio_q_format ( struct qeth_card * card ) <nl> { <nl> - switch ( card -> info . type ) { <nl> - case QETH_CARD_TYPE_IQD : <nl> - return 2 ; <nl> - default : <nl> - return 0 ; <nl> - } <nl> + if ( card -> info . type == QETH_CARD_TYPE_IQD ) <nl> + return QDIO_IQDIO_QFMT ; <nl> + else <nl> + return QDIO_QETH_QFMT ; <nl> } <nl>  <nl> static void qeth_determine_capabilities ( struct qeth_card * card )
static int perf_sched__process_tracepoint_sample ( struct perf_tool * tool __maybe_ <nl> struct perf_evsel * evsel , <nl> struct machine * machine ) <nl> { <nl> - struct thread * thread = machine__findnew_thread ( machine , sample -> pid ); <nl> + struct thread * thread = machine__findnew_thread ( machine , sample -> tid ); <nl> int err = 0 ; <nl>  <nl> if ( thread == NULL ) {
static void __init setup_lowcore ( void ) <nl> + PAGE_SIZE - STACK_FRAME_OVERHEAD - sizeof ( struct pt_regs ); <nl> lc -> current_task = ( unsigned long ) init_thread_union . thread_info . task ; <nl> lc -> thread_info = ( unsigned long ) & init_thread_union ; <nl> + lc -> lpp = LPP_MAGIC ; <nl> lc -> machine_flags = S390_lowcore . machine_flags ; <nl> lc -> stfl_fac_list = S390_lowcore . stfl_fac_list ; <nl> memcpy ( lc -> stfle_fac_list , S390_lowcore . stfle_fac_list ,
static inline int init_new_context ( struct task_struct * tsk , <nl> mm -> context . execute_only_pkey = - 1 ; <nl> } <nl> # endif <nl> - init_new_context_ldt ( tsk , mm ); <nl> - <nl> - return 0 ; <nl> + return init_new_context_ldt ( tsk , mm ); <nl> } <nl> static inline void destroy_context ( struct mm_struct * mm ) <nl> {
static int option_probe ( struct usb_serial * serial , <nl> serial -> interface -> cur_altsetting -> desc . bInterfaceNumber , <nl> OPTION_BLACKLIST_RESERVED_IF , <nl> ( const struct option_blacklist_info *) id -> driver_info )) <nl> + return - ENODEV ; <nl>  <nl> /* Don ' t bind network interface on Samsung GT - B3730 , it is handled by a separate module */ <nl> if ( serial -> dev -> descriptor . idVendor == SAMSUNG_VENDOR_ID &&
static void restore_custom_reg_settings ( struct wiphy * wiphy ) <nl> chan -> flags = chan -> orig_flags ; <nl> chan -> max_antenna_gain = chan -> orig_mag ; <nl> chan -> max_power = chan -> orig_mpwr ; <nl> + chan -> beacon_found = false ; <nl> } <nl> } <nl> }
int iwl_mvm_mac_setup_register ( struct iwl_mvm * mvm ) <nl> else <nl> hw -> wiphy -> flags &= ~ WIPHY_FLAG_PS_ON_BY_DEFAULT ; <nl>  <nl> - if ( mvm -> fw -> ucode_capa . flags & IWL_UCODE_TLV_FLAGS_SCHED_SCAN ) { <nl> + if ( 0 && mvm -> fw -> ucode_capa . flags & IWL_UCODE_TLV_FLAGS_SCHED_SCAN ) { <nl> hw -> wiphy -> flags |= WIPHY_FLAG_SUPPORTS_SCHED_SCAN ; <nl> hw -> wiphy -> max_sched_scan_ssids = PROBE_OPTION_MAX ; <nl> hw -> wiphy -> max_match_sets = IWL_SCAN_MAX_PROFILES ;
static int nr_listen ( struct socket * sock , int backlog ) <nl> struct sock * sk = sock -> sk ; <nl>  <nl> lock_sock ( sk ); <nl> + if ( sock -> state != SS_UNCONNECTED ) { <nl> + release_sock ( sk ); <nl> + return - EINVAL ; <nl> + } <nl> + <nl> if ( sk -> sk_state != TCP_LISTEN ) { <nl> memset (& nr_sk ( sk )-> user_addr , 0 , AX25_ADDR_LEN ); <nl> sk -> sk_max_ack_backlog = backlog ;
rio_dma_transfer ( struct file * filp , u32 transfer_mode , <nl> goto err_req ; <nl> } <nl>  <nl> - pinned = get_user_pages_unlocked ( <nl> + pinned = get_user_pages_fast ( <nl> ( unsigned long ) xfer -> loc_addr & PAGE_MASK , <nl> - nr_pages , <nl> - page_list , <nl> - dir == DMA_FROM_DEVICE ? FOLL_WRITE : 0 ); <nl> + nr_pages , dir == DMA_FROM_DEVICE , page_list ); <nl>  <nl> if ( pinned != nr_pages ) { <nl> if ( pinned < 0 ) {
static int set_gamma ( struct fbtft_par * par , u32 * curves ) <nl> * The masks are the same for both positive and negative voltage <nl> * gamma curves . <nl> */ <nl> - const u8 gamma_par_mask [] = { <nl> + static const u8 gamma_par_mask [] = { <nl> 0xFF , /* V63 [ 3 : 0 ], V0 [ 3 : 0 ]*/ <nl> 0x3F , /* V1 [ 5 : 0 ] */ <nl> 0x3F , /* V2 [ 5 : 0 ] */
int iwlagn_mac_setup_register ( struct iwl_priv * priv , <nl> ARRAY_SIZE ( iwlagn_iface_combinations_dualmode ); <nl> } <nl>  <nl> - hw -> wiphy -> max_remain_on_channel_duration = 1000 ; <nl> + hw -> wiphy -> max_remain_on_channel_duration = 500 ; <nl>  <nl> hw -> wiphy -> flags |= WIPHY_FLAG_CUSTOM_REGULATORY | <nl> WIPHY_FLAG_DISABLE_BEACON_HINTS |
static void do_fault ( struct work_struct * work ) <nl> goto out ; <nl> } <nl>  <nl> + if (!( vma -> vm_flags & ( VM_READ | VM_EXEC | VM_WRITE ))) { <nl> + /* handle_mm_fault would BUG_ON () */ <nl> + up_read (& mm -> mmap_sem ); <nl> + handle_fault_error ( fault ); <nl> + goto out ; <nl> + } <nl> + <nl> ret = handle_mm_fault ( mm , vma , address , write ); <nl> if ( ret & VM_FAULT_ERROR ) { <nl> /* failed to service fault */
static inline clock_t jiffies_delta_to_clock_t ( long delta ) <nl> return jiffies_to_clock_t ( max ( 0L , delta )); <nl> } <nl>  <nl> + static inline unsigned int jiffies_delta_to_msecs ( long delta ) <nl> +{ <nl> + return jiffies_to_msecs ( max ( 0L , delta )); <nl> +} <nl> + <nl> extern unsigned long clock_t_to_jiffies ( unsigned long x ); <nl> extern u64 jiffies_64_to_clock_t ( u64 x ); <nl> extern u64 nsec_to_clock_t ( u64 x );
static SIMPLE_DEV_PM_OPS ( ds1374_pm , ds1374_suspend , ds1374_resume ); <nl> static struct i2c_driver ds1374_driver = { <nl> . driver = { <nl> . name = " rtc - ds1374 ", <nl> + . of_match_table = of_match_ptr ( ds1374_of_match ), <nl> . pm = & ds1374_pm , <nl> }, <nl> . probe = ds1374_probe ,
static int nvmet_rdma_queue_connect ( struct rdma_cm_id * cm_id , <nl> } <nl> queue -> port = cm_id -> context ; <nl>  <nl> + if ( queue -> host_qid == 0 ) { <nl> + /* Let inflight controller teardown complete */ <nl> + flush_scheduled_work (); <nl> + } <nl> + <nl> ret = nvmet_rdma_cm_accept ( cm_id , queue , & event -> param . conn ); <nl> if ( ret ) <nl> goto release_queue ;
static int usb_console_setup ( struct console * co , char * options ) <nl> tty_kref_put ( tty ); <nl> reset_open_count : <nl> port -> port . count = 0 ; <nl> + info -> port = NULL ; <nl> usb_autopm_put_interface ( serial -> interface ); <nl> error_get_interface : <nl> usb_serial_put ( serial );
bool ath9k_hw_eeprom_set_board_values ( struct ath_hal * ah , <nl>  <nl> txRxAttenLocal = IS_CHAN_2GHZ ( chan ) ? 23 : 44 ; <nl>  <nl> - ath9k_hw_get_eeprom_antenna_cfg ( ah , chan , 1 , & ant_config ); <nl> + ath9k_hw_get_eeprom_antenna_cfg ( ah , chan , 0 , & ant_config ); <nl> REG_WRITE ( ah , AR_PHY_SWITCH_COM , ant_config ); <nl>  <nl> for ( i = 0 ; i < AR5416_MAX_CHAINS ; i ++) {
int ipv6_find_hdr ( const struct sk_buff * skb , unsigned int * offset , <nl> found = ( nexthdr == target ); <nl>  <nl> if ((! ipv6_ext_hdr ( nexthdr )) || nexthdr == NEXTHDR_NONE ) { <nl> - if ( target < 0 ) <nl> + if ( target < 0 || found ) <nl> break ; <nl> return - ENOENT ; <nl> }
int thermal_add_hwmon_sysfs ( struct thermal_zone_device * tz ) <nl>  <nl> INIT_LIST_HEAD (& hwmon -> tz_list ); <nl> strlcpy ( hwmon -> type , tz -> type , THERMAL_NAME_LENGTH ); <nl> - hwmon -> device = hwmon_device_register ( NULL ); <nl> + hwmon -> device = hwmon_device_register (& tz -> device ); <nl> if ( IS_ERR ( hwmon -> device )) { <nl> result = PTR_ERR ( hwmon -> device ); <nl> goto free_mem ;
static int copy_to_user_auth ( struct xfrm_algo_auth * auth , struct sk_buff * skb ) <nl> return - EMSGSIZE ; <nl>  <nl> algo = nla_data ( nla ); <nl> - strcpy ( algo -> alg_name , auth -> alg_name ); <nl> + strncpy ( algo -> alg_name , auth -> alg_name , sizeof ( algo -> alg_name )); <nl> memcpy ( algo -> alg_key , auth -> alg_key , ( auth -> alg_key_len + 7 ) / 8 ); <nl> algo -> alg_key_len = auth -> alg_key_len ; <nl> 
int radeon_suspend_kms ( struct drm_device * dev , bool suspend , <nl> radeon_agp_suspend ( rdev ); <nl>  <nl> pci_save_state ( dev -> pdev ); <nl> - if ( freeze && rdev -> family >= CHIP_R600 ) { <nl> + if ( freeze && rdev -> family >= CHIP_CEDAR ) { <nl> rdev -> asic -> asic_reset ( rdev , true ); <nl> pci_restore_state ( dev -> pdev ); <nl> } else if ( suspend ) {
static int sdhci_probe ( struct platform_device * pdev ) <nl> host -> hw_name = " sdhci "; <nl> host -> ops = & sdhci_pltfm_ops ; <nl> host -> irq = platform_get_irq ( pdev , 0 ); <nl> + if ( host -> irq <= 0 ) { <nl> + ret = - EINVAL ; <nl> + goto err_host ; <nl> + } <nl> host -> quirks = SDHCI_QUIRK_BROKEN_ADMA ; <nl>  <nl> sdhci = sdhci_priv ( host );
static int mlxsw_sp_ageing_set ( struct mlxsw_sp * mlxsw_sp , u32 ageing_time ) <nl>  <nl> static int mlxsw_sp_port_attr_br_ageing_set ( struct mlxsw_sp_port * mlxsw_sp_port , <nl> struct switchdev_trans * trans , <nl> - unsigned long ageing_jiffies ) <nl> + unsigned long ageing_clock_t ) <nl> { <nl> struct mlxsw_sp * mlxsw_sp = mlxsw_sp_port -> mlxsw_sp ; <nl> + unsigned long ageing_jiffies = clock_t_to_jiffies ( ageing_clock_t ); <nl> u32 ageing_time = jiffies_to_msecs ( ageing_jiffies ) / 1000 ; <nl>  <nl> if ( switchdev_trans_ph_prepare ( trans ))
static void ieee80211_iface_work ( struct work_struct * work ) <nl> if ( sta ) { <nl> u16 last_seq ; <nl>  <nl> - last_seq = le16_to_cpu ( <nl> - sta -> last_seq_ctrl [ rx_agg -> tid ]); <nl> + last_seq = IEEE80211_SEQ_TO_SN ( le16_to_cpu ( <nl> + sta -> last_seq_ctrl [ rx_agg -> tid ])); <nl>  <nl> __ieee80211_start_rx_ba_session ( sta , <nl> 0 , 0 ,
void stmmac_remove_config_dt ( struct platform_device * pdev , <nl> if ( of_phy_is_fixed_link ( np )) <nl> of_phy_deregister_fixed_link ( np ); <nl> of_node_put ( plat -> phy_node ); <nl> + of_node_put ( plat -> mdio_node ); <nl> } <nl> # else <nl> struct plat_stmmacenet_data *
int iio_buffer_register ( struct iio_dev * indio_dev , <nl> if ( channels ) { <nl> /* new magic */ <nl> for ( i = 0 ; i < num_channels ; i ++) { <nl> + if ( channels [ i ]. scan_index < 0 ) <nl> + continue ; <nl> + <nl> /* Establish necessary mask length */ <nl> if ( channels [ i ]. scan_index > <nl> ( int ) indio_dev -> masklength - 1 )
# ifndef HPSB_DEBUG_TLABELS <nl> static <nl> # endif <nl> - spinlock_t hpsb_tlabel_lock = SPIN_LOCK_UNLOCKED ; <nl> + DEFINE_SPINLOCK ( hpsb_tlabel_lock ); <nl>  <nl> static DECLARE_WAIT_QUEUE_HEAD ( tlabel_wq ); <nl> 
static int e1000_set_ringparam ( struct net_device * netdev , <nl> err_alloc_rx : <nl> kfree ( txdr ); <nl> err_alloc_tx : <nl> - e1000_up ( adapter ); <nl> + if ( netif_running ( adapter -> netdev )) <nl> + e1000_up ( adapter ); <nl> err_setup : <nl> clear_bit ( __E1000_RESETTING , & adapter -> flags ); <nl> return err ;
static int __posix_lock_file ( struct inode * inode , struct file_lock * request , str <nl> } <nl> locks_copy_lock ( new_fl , request ); <nl> locks_insert_lock_ctx ( new_fl , & fl -> fl_list ); <nl> + fl = new_fl ; <nl> new_fl = NULL ; <nl> } <nl> if ( right ) {
int install_user_keyrings ( void ) <nl>  <nl> kenter ("% p {% u }", user , uid ); <nl>  <nl> - if ( user -> uid_keyring ) { <nl> + if ( user -> uid_keyring && user -> session_keyring ) { <nl> kleave (" = 0 [ exist ]"); <nl> return 0 ; <nl> }
static long cgroup_create ( struct cgroup * parent , struct dentry * dentry , <nl> } <nl>  <nl> err = percpu_ref_init (& css -> refcnt , css_release ); <nl> - if ( err ) <nl> + if ( err ) { <nl> + ss -> css_free ( cgrp ); <nl> goto err_free_all ; <nl> + } <nl>  <nl> init_cgroup_css ( css , ss , cgrp ); <nl> 
xmaddr_t arbitrary_virt_to_machine ( void * vaddr ) <nl> } <nl> EXPORT_SYMBOL_GPL ( arbitrary_virt_to_machine ); <nl>  <nl> - void xen_flush_tlb_all ( void ) <nl> + static void xen_flush_tlb_all ( void ) <nl> { <nl> struct mmuext_op * op ; <nl> struct multicall_space mcs ;
static int find_first_block_group ( struct btrfs_root * root , <nl> } else { <nl> ret = 0 ; <nl> } <nl> + free_extent_map ( em ); <nl> goto out ; <nl> } <nl> path -> slots [ 0 ]++;
static byte connect_res ( dword Id , word Number , DIVA_CAPI_ADAPTER * a , <nl> add_ai ( plci , & parms [ 5 ]); <nl> sig_req ( plci , REJECT , 0 ); <nl> } <nl> - else if ( Reject == 1 || Reject > 9 ) <nl> + else if ( Reject == 1 || Reject >= 9 ) <nl> { <nl> add_ai ( plci , & parms [ 5 ]); <nl> sig_req ( plci , HANGUP , 0 );
ssize_t tomoyo_write_control ( struct tomoyo_io_buffer * head , <nl> return - EFAULT ; <nl> if ( mutex_lock_interruptible (& head -> io_sem )) <nl> return - EINTR ; <nl> + head -> read_user_buf_avail = 0 ; <nl> idx = tomoyo_read_lock (); <nl> /* Read a line and dispatch it to the policy handler . */ <nl> while ( avail_len > 0 ) {
int wusbhc_chid_set ( struct wusbhc * wusbhc , const struct wusb_ckhdid * chid ) <nl> { <nl> int result = 0 ; <nl>  <nl> - if ( memcmp ( chid , & wusb_ckhdid_zero , sizeof ( chid )) == 0 ) <nl> + if ( memcmp ( chid , & wusb_ckhdid_zero , sizeof (* chid )) == 0 ) <nl> chid = NULL ; <nl>  <nl> mutex_lock (& wusbhc -> mutex );
struct kvm_pit * kvm_create_pit ( struct kvm * kvm ) <nl> mutex_lock (& kvm -> lock ); <nl> pit -> irq_source_id = kvm_request_irq_source_id ( kvm ); <nl> mutex_unlock (& kvm -> lock ); <nl> - if ( pit -> irq_source_id < 0 ) <nl> + if ( pit -> irq_source_id < 0 ) { <nl> + kfree ( pit ); <nl> return NULL ; <nl> + } <nl>  <nl> mutex_init (& pit -> pit_state . lock ); <nl> mutex_lock (& pit -> pit_state . lock );
static struct mtd_partition davinci_ntosd2_nandflash_partition [] = { <nl> }; <nl>  <nl> static struct davinci_nand_pdata davinci_ntosd2_nandflash_data = { <nl> + . core_chipsel = 0 , <nl> . parts = davinci_ntosd2_nandflash_partition , <nl> . nr_parts = ARRAY_SIZE ( davinci_ntosd2_nandflash_partition ), <nl> . ecc_mode = NAND_ECC_HW ,
static int proc_do_submiturb ( struct usb_dev_state * ps , struct usbdevfs_urb * uurb <nl> u = ( is_in ? URB_DIR_IN : URB_DIR_OUT ); <nl> if ( uurb -> flags & USBDEVFS_URB_ISO_ASAP ) <nl> u |= URB_ISO_ASAP ; <nl> - if ( uurb -> flags & USBDEVFS_URB_SHORT_NOT_OK ) <nl> + if ( uurb -> flags & USBDEVFS_URB_SHORT_NOT_OK && is_in ) <nl> u |= URB_SHORT_NOT_OK ; <nl> if ( uurb -> flags & USBDEVFS_URB_NO_FSBR ) <nl> u |= URB_NO_FSBR ;
void fuse_conn_kill ( struct fuse_conn * fc ) <nl> kill_fasync (& fc -> fasync , SIGIO , POLL_IN ); <nl> wake_up_all (& fc -> waitq ); <nl> wake_up_all (& fc -> blocked_waitq ); <nl> - wake_up_all (& fc -> reserved_req_waitq ); <nl> } <nl> EXPORT_SYMBOL_GPL ( fuse_conn_kill ); <nl> 
static int whiteheat_attach ( struct usb_serial * serial ) <nl> err ("% s : Unable to retrieve firmware version , try replugging \ n ", serial -> type -> description ); <nl> err ("% s : If the firmware is not running ( status led not blinking )\ n ", serial -> type -> description ); <nl> err ("% s : please contact support @ connecttech . com \ n ", serial -> type -> description ); <nl> + kfree ( result ); <nl> return - ENODEV ; <nl>  <nl> no_command_private :
static cycle_t sb1250_hpt_read ( void ) <nl> } <nl>  <nl> struct clocksource bcm1250_clocksource = { <nl> - . name = " MIPS ", <nl> + . name = " bcm1250 - counter - 3 ", <nl> . rating = 200 , <nl> . read = sb1250_hpt_read , <nl> . mask = CLOCKSOURCE_MASK ( 23 ),
static void fcopy_send_data ( struct work_struct * dummy ) <nl> out_src = smsg_out ; <nl> break ; <nl>  <nl> + case WRITE_TO_FILE : <nl> + out_src = fcopy_transaction . fcopy_msg ; <nl> + out_len = sizeof ( struct hv_do_fcopy ); <nl> + break ; <nl> default : <nl> out_src = fcopy_transaction . fcopy_msg ; <nl> out_len = fcopy_transaction . recv_len ;
int __cpufreq_driver_target ( struct cpufreq_policy * policy , <nl>  <nl> pr_debug (" target for CPU % u : % u kHz , relation % u \ n ", policy -> cpu , <nl> target_freq , relation ); <nl> + <nl> + if ( target_freq == policy -> cur ) <nl> + return 0 ; <nl> + <nl> if ( cpu_online ( policy -> cpu ) && cpufreq_driver -> target ) <nl> retval = cpufreq_driver -> target ( policy , target_freq , relation ); <nl> 
static int pppoe_rcv_core ( struct sock * sk , struct sk_buff * skb ) <nl> * can ' t change . <nl> */ <nl>  <nl> + if ( skb -> pkt_type == PACKET_OTHERHOST ) <nl> + goto abort_kfree ; <nl> + <nl> if ( sk -> sk_state & PPPOX_BOUND ) { <nl> ppp_input (& po -> chan , skb ); <nl> } else if ( sk -> sk_state & PPPOX_RELAY ) {
struct thread_map * thread_map__new_by_uid ( uid_t uid ) <nl> { <nl> DIR * proc ; <nl> int max_threads = 32 , items , i ; <nl> - char path [ 256 ]; <nl> + char path [ NAME_MAX + 1 + 6 ]; <nl> struct dirent * dirent , ** namelist = NULL ; <nl> struct thread_map * threads = thread_map__alloc ( max_threads ); <nl> 
minstrel_get_rate ( void * priv , struct ieee80211_sta * sta , <nl> return ; <nl> # endif <nl>  <nl> + /* Don ' t use EAPOL frames for sampling on non - mrr hw */ <nl> + if ( mp -> hw -> max_rates == 1 && <nl> + ( info -> control . flags & IEEE80211_TX_CTRL_PORT_CTRL_PROTO )) <nl> + return ; <nl> + <nl> delta = ( mi -> total_packets * sampling_ratio / 100 ) - <nl> ( mi -> sample_packets + mi -> sample_deferred / 2 ); <nl> 
static int fc_lport_els_request ( struct fc_bsg_job * job , <nl> char * pp ; <nl> int len ; <nl>  <nl> - fp = fc_frame_alloc ( lport , sizeof ( struct fc_frame_header ) + <nl> - job -> request_payload . payload_len ); <nl> + fp = fc_frame_alloc ( lport , job -> request_payload . payload_len ); <nl> if (! fp ) <nl> return - ENOMEM ; <nl> 
ext4_mb_load_buddy ( struct super_block * sb , ext4_group_t group , <nl> grp = ext4_get_group_info ( sb , group ); <nl>  <nl> e4b -> bd_blkbits = sb -> s_blocksize_bits ; <nl> - e4b -> bd_info = ext4_get_group_info ( sb , group ); <nl> + e4b -> bd_info = grp ; <nl> e4b -> bd_sb = sb ; <nl> e4b -> bd_group = group ; <nl> e4b -> bd_buddy_page = NULL ;
static int ieee80211_change_bss ( struct wiphy * wiphy , <nl> sdata -> flags &= ~ IEEE80211_SDATA_DONT_BRIDGE_PACKETS ; <nl> } <nl>  <nl> + if ( params -> ht_opmode >= 0 ) { <nl> + sdata -> vif . bss_conf . ht_operation_mode = <nl> + ( u16 ) params -> ht_opmode ; <nl> + changed |= BSS_CHANGED_HT ; <nl> + } <nl> + <nl> ieee80211_bss_info_change_notify ( sdata , changed ); <nl>  <nl> return 0 ;
static void __init imx6sl_init_late ( void ) <nl> if ( IS_ENABLED ( CONFIG_ARM_IMX6Q_CPUFREQ )) <nl> platform_device_register_simple (" imx6q - cpufreq ", - 1 , NULL , 0 ); <nl>  <nl> - if ( cpu_is_imx6sl ()) <nl> + if ( IS_ENABLED ( CONFIG_SOC_IMX6SL ) && cpu_is_imx6sl ()) <nl> imx6sl_cpuidle_init (); <nl> - else <nl> + else if ( IS_ENABLED ( CONFIG_SOC_IMX6SLL )) <nl> imx6sx_cpuidle_init (); <nl> } <nl> 
int sctp_packet_transmit ( struct sctp_packet * packet ) <nl> return err ; <nl> no_route : <nl> kfree_skb ( nskb ); <nl> - IP_INC_STATS_BH ( sock_net ( asoc -> base . sk ), IPSTATS_MIB_OUTNOROUTES ); <nl> + IP_INC_STATS ( sock_net ( asoc -> base . sk ), IPSTATS_MIB_OUTNOROUTES ); <nl>  <nl> /* FIXME : Returning the ' err ' will effect all the associations <nl> * associated with a socket , although only one of the paths of the
int dss_mgr_enable ( struct omap_overlay_manager * mgr ) <nl> if (! mgr_manual_update ( mgr )) <nl> mp -> updating = true ; <nl>  <nl> + if (! dss_data . irq_enabled && need_isr ()) <nl> + dss_register_vsync_isr (); <nl> + <nl> spin_unlock_irqrestore (& data_lock , flags ); <nl>  <nl> if (! mgr_manual_update ( mgr ))
static int vt8500lcd_remove ( struct platform_device * pdev ) <nl> res = platform_get_resource ( pdev , IORESOURCE_MEM , 0 ); <nl> release_mem_region ( res -> start , resource_size ( res )); <nl>  <nl> - kfree ( fbi ); <nl> - <nl> return 0 ; <nl> } <nl> 
static int handle_vmcall ( struct kvm_vcpu * vcpu ) <nl> return 1 ; <nl> } <nl>  <nl> - static int handle_vmx_insn ( struct kvm_vcpu * vcpu ) <nl> -{ <nl> - kvm_queue_exception ( vcpu , UD_VECTOR ); <nl> - return 1 ; <nl> -} <nl> - <nl> static int handle_invd ( struct kvm_vcpu * vcpu ) <nl> { <nl> return emulate_instruction ( vcpu , 0 ) == EMULATE_DONE ;
static int try_smi_init ( struct smi_info * new_smi ) <nl> */ <nl> new_smi -> pdev = platform_device_alloc (" ipmi_si ", <nl> new_smi -> intf_num ); <nl> - if ( rv ) { <nl> + if (! new_smi -> pdev ) { <nl> printk ( KERN_ERR <nl> " ipmi_si_intf :" <nl> " Unable to allocate platform device \ n ");
static struct dmi_system_id __initdata acpisleep_dmi_table [] = { <nl> }, <nl> { <nl> . callback = init_nvs_nosave , <nl> + . ident = " Sony Vaio VGN - FW41E_H ", <nl> + . matches = { <nl> + DMI_MATCH ( DMI_SYS_VENDOR , " Sony Corporation "), <nl> + DMI_MATCH ( DMI_PRODUCT_NAME , " VGN - FW41E_H "), <nl> + }, <nl> + }, <nl> + { <nl> + . callback = init_nvs_nosave , <nl> . ident = " Sony Vaio VGN - FW21E ", <nl> . matches = { <nl> DMI_MATCH ( DMI_SYS_VENDOR , " Sony Corporation "),
static int ioctl_send_response ( struct client * client , void * buffer ) <nl> if ( copy_from_user ( r -> data , u64_to_uptr ( request -> data ), <nl> r -> length )) { <nl> ret = - EFAULT ; <nl> + kfree ( r -> request ); <nl> goto out ; <nl> } <nl> fw_send_response ( client -> device -> card , r -> request ,
static int iscsi_login_zero_tsih_s1 ( <nl> if ( IS_ERR ( sess -> se_sess )) { <nl> iscsit_tx_login_rsp ( conn , ISCSI_STATUS_CLS_TARGET_ERR , <nl> ISCSI_LOGIN_STATUS_NO_RESOURCES ); <nl> + kfree ( sess -> sess_ops ); <nl> kfree ( sess ); <nl> return - ENOMEM ; <nl> }
int __init musb_platform_init ( struct musb * musb , void * board_data ) <nl>  <nl> usb_nop_xceiv_register (); <nl> musb -> xceiv = otg_get_transceiver (); <nl> - if (! musb -> xceiv ) <nl> + if (! musb -> xceiv ) { <nl> + gpio_free ( musb -> config -> gpio_vrsel ); <nl> return - ENODEV ; <nl> + } <nl>  <nl> if ( ANOMALY_05000346 ) { <nl> bfin_write_USB_APHY_CALIB ( ANOMALY_05000346_value );
static int au_ide_probe ( struct device * dev ) <nl> goto out ; <nl> } <nl>  <nl> - /* FIXME : This might possibly break PCMCIA IDE devices */ <nl> - <nl> - hwif = & ide_hwifs [ pdev -> id ]; <nl> + hwif = ide_find_port (); <nl> + if ( hwif == NULL ) { <nl> + ret = - ENOENT ; <nl> + goto out ; <nl> + } <nl>  <nl> memset (& hw , 0 , sizeof ( hw )); <nl> auide_setup_ports (& hw , ahwif );
static int create_tracing_map_fields ( struct hist_trigger_data * hist_data ) <nl> struct tracing_map * map = hist_data -> map ; <nl> struct ftrace_event_field * field ; <nl> struct hist_field * hist_field ; <nl> - int i , idx ; <nl> + int i , idx = 0 ; <nl>  <nl> for_each_hist_field ( i , hist_data ) { <nl> hist_field = hist_data -> fields [ i ];
static void remap_cell_to_origin_clear_discard ( struct cache * cache , <nl> remap_to_origin ( cache , bio ); <nl> issue ( cache , bio ); <nl> } <nl> + <nl> + free_prison_cell ( cache , cell ); <nl> } <nl>  <nl> static void remap_cell_to_cache_dirty ( struct cache * cache , struct dm_bio_prison_cell * cell , <nl> static void remap_cell_to_cache_dirty ( struct cache * cache , struct dm_bio_prison_ <nl> remap_to_cache ( cache , bio , cblock ); <nl> issue ( cache , bio ); <nl> } <nl> + <nl> + free_prison_cell ( cache , cell ); <nl> } <nl>  <nl> /*----------------------------------------------------------------*/
static int rcar_gen2_usb_phy_probe ( struct platform_device * pdev ) <nl> priv -> phy . shutdown = rcar_gen2_usb_phy_shutdown ; <nl> priv -> phy . set_suspend = rcar_gen2_usb_phy_set_suspend ; <nl>  <nl> - retval = usb_add_phy (& priv -> phy , USB_PHY_TYPE_USB2 ); <nl> + retval = usb_add_phy_dev (& priv -> phy ); <nl> if ( retval < 0 ) { <nl> dev_err ( dev , " Failed to add USB phy \ n "); <nl> return retval ;
int rds_cmsg_atomic ( struct rds_sock * rs , struct rds_message * rm , <nl> err : <nl> if ( page ) <nl> put_page ( page ); <nl> + rm -> atomic . op_active = 0 ; <nl> kfree ( rm -> atomic . op_notifier ); <nl>  <nl> return ret ;
static struct page ** __iommu_alloc_buffer ( struct device * dev , size_t size , <nl> int i = 0 ; <nl>  <nl> if ( array_size <= PAGE_SIZE ) <nl> - pages = kzalloc ( array_size , gfp ); <nl> + pages = kzalloc ( array_size , GFP_KERNEL ); <nl> else <nl> pages = vzalloc ( array_size ); <nl> if (! pages )
static void setup_frame_info ( struct ieee80211_hw * hw , <nl> fi -> keyix = ATH9K_TXKEYIX_INVALID ; <nl> fi -> keytype = keytype ; <nl> fi -> framelen = framelen ; <nl> + <nl> + if (! rate ) <nl> + return ; <nl> fi -> rtscts_rate = rate -> hw_value ; <nl> if ( short_preamble ) <nl> fi -> rtscts_rate |= rate -> hw_value_short ;
static void __devinit bnx2x_link_settings_supported ( struct bnx2x * bp , <nl> break ; <nl>  <nl> case PORT_HW_CFG_XGXS_EXT_PHY_TYPE_BCM8481 : <nl> - BNX2X_DEV_INFO (" ext_phy_type 0x % x ( BCM8481 )\ n ", <nl> + case PORT_HW_CFG_XGXS_EXT_PHY_TYPE_BCM84823 : <nl> + BNX2X_DEV_INFO (" ext_phy_type 0x % x ( BCM848xx )\ n ", <nl> ext_phy_type ); <nl>  <nl> bp -> port . supported |= ( SUPPORTED_10baseT_Half |
static int conf_choice ( struct menu * menu ) <nl> } <nl> if (! child ) <nl> continue ; <nl> - if ( line [ strlen ( line ) - 1 ] == '?') { <nl> + if ( line [ 0 ] && line [ strlen ( line ) - 1 ] == '?') { <nl> print_help ( child ); <nl> continue ; <nl> }
static int bcm7038_wdt_probe ( struct platform_device * pdev ) <nl> wdt -> clk = devm_clk_get ( dev , NULL ); <nl> /* If unable to get clock , use default frequency */ <nl> if (! IS_ERR ( wdt -> clk )) { <nl> - clk_prepare_enable ( wdt -> clk ); <nl> + err = clk_prepare_enable ( wdt -> clk ); <nl> + if ( err ) <nl> + return err ; <nl> wdt -> rate = clk_get_rate ( wdt -> clk ); <nl> /* Prevent divide - by - zero exception */ <nl> if (! wdt -> rate )
static int find_probe_functions ( struct map * map , char * name ) <nl> struct symbol * sym ; <nl> struct rb_node * tmp ; <nl>  <nl> + if ( map__load ( map , NULL ) < 0 ) <nl> + return 0 ; <nl> + <nl> map__for_each_symbol ( map , sym , tmp ) { <nl> if ( strglobmatch ( sym -> name , name )) <nl> found ++;
static int __init macide_init ( void ) <nl> int irq ; <nl> hw_regs_t hw ; <nl>  <nl> + if (! MACH_IS_MAC ) <nl> + return - ENODEV ; <nl> + <nl> switch ( macintosh_config -> ide_type ) { <nl> case MAC_IDE_QUADRA : <nl> base = IDE_BASE ;
static int crypt_iv_tcw_whitening ( struct crypt_config * cc , <nl> for ( i = 0 ; i < (( 1 << SECTOR_SHIFT ) / 8 ); i ++) <nl> crypto_xor ( data + i * 8 , buf , 8 ); <nl> out : <nl> - memset ( buf , 0 , sizeof ( buf )); <nl> + memzero_explicit ( buf , sizeof ( buf )); <nl> return r ; <nl> } <nl> 
__setup (" mce =", mcheck_enable ); <nl> static int mce_resume ( struct sys_device * dev ) <nl> { <nl> mce_init ( NULL ); <nl> + mce_cpu_features (& current_cpu_data ); <nl> return 0 ; <nl> } <nl> 
static long ioctl_file_dedupe_range ( struct file * file , void __user * arg ) <nl> goto out ; <nl> } <nl>  <nl> + same -> dest_count = count ; <nl> ret = vfs_dedupe_file_range ( file , same ); <nl> if ( ret ) <nl> goto out ;
int main ( int argc , char ** argv ) <nl> read_relocs ( fp ); <nl> if ( show_absolute_syms ) { <nl> print_absolute_symbols (); <nl> - return 0 ; <nl> + goto out ; <nl> } <nl> if ( show_absolute_relocs ) { <nl> print_absolute_relocs (); <nl> - return 0 ; <nl> + goto out ; <nl> } <nl> emit_relocs ( as_text , use_real_mode ); <nl> + out : <nl> + fclose ( fp ); <nl> return 0 ; <nl> }
# define USB_REQ_LOOPBACK_DATA_READ 0x16 <nl> # define USB_REQ_SET_INTERFACE_DS 0x17 <nl>  <nl> +/* specific requests for USB Power Delivery */ <nl> +# define USB_REQ_GET_PARTNER_PDO 20 <nl> +# define USB_REQ_GET_BATTERY_STATUS 21 <nl> +# define USB_REQ_SET_PDO 22 <nl> +# define USB_REQ_GET_VDM 23 <nl> +# define USB_REQ_SEND_VDM 24 <nl> + <nl> /* The Link Power Management ( LPM ) ECN defines USB_REQ_TEST_AND_SET command , <nl> * used by hubs to put ports into a new L1 suspend state , except that it <nl> * forgot to define its number ...
static int mem_cgroup_hierarchical_reclaim ( struct mem_cgroup * root_mem , <nl> ret = try_to_free_mem_cgroup_pages ( root_mem , gfp_mask , noswap ); <nl> if ( mem_cgroup_check_under_limit ( root_mem )) <nl> return 0 ; <nl> + if (! root_mem -> use_hierarchy ) <nl> + return ret ; <nl>  <nl> next_mem = mem_cgroup_get_first_node ( root_mem ); <nl> 
static void gb_svc_remove_modules ( struct gb_svc * svc ) <nl>  <nl> void gb_svc_del ( struct gb_svc * svc ) <nl> { <nl> - gb_connection_disable ( svc -> connection ); <nl> + gb_connection_disable_rx ( svc -> connection ); <nl>  <nl> /* <nl> * The SVC device and input device may have been registered <nl> void gb_svc_del ( struct gb_svc * svc ) <nl> flush_workqueue ( svc -> wq ); <nl>  <nl> gb_svc_remove_modules ( svc ); <nl> + <nl> + gb_connection_disable ( svc -> connection ); <nl> } <nl>  <nl> void gb_svc_put ( struct gb_svc * svc )
static int cfs_wi_scheduler ( void * arg ) <nl>  <nl> spin_unlock (& sched -> ws_lock ); <nl> rc = wait_event_interruptible_exclusive ( sched -> ws_waitq , <nl> - ! cfs_wi_sched_cansleep ( sched )); <nl> + ! cfs_wi_sched_cansleep ( sched )); <nl> spin_lock (& sched -> ws_lock ); <nl> } <nl> 
int expand_downwards ( struct vm_area_struct * vma , <nl> { <nl> struct mm_struct * mm = vma -> vm_mm ; <nl> struct vm_area_struct * prev ; <nl> - int error ; <nl> + int error = 0 ; <nl>  <nl> address &= PAGE_MASK ; <nl> - error = security_mmap_addr ( address ); <nl> - if ( error ) <nl> - return error ; <nl> + if ( address < mmap_min_addr ) <nl> + return - EPERM ; <nl>  <nl> /* Enforce stack_guard_gap */ <nl> prev = vma -> vm_prev ;
void radeon_atom_backlight_init ( struct radeon_encoder * radeon_encoder , <nl> u8 backlight_level ; <nl> char bl_name [ 16 ]; <nl>  <nl> + /* Mac laptops with multiple GPUs use the gmux driver for backlight <nl> + * so don ' t register a backlight device <nl> + */ <nl> + if (( rdev -> pdev -> subsystem_vendor == PCI_VENDOR_ID_APPLE ) && <nl> + ( rdev -> pdev -> device == 0x6741 )) <nl> + return ; <nl> + <nl> if (! radeon_encoder -> enc_priv ) <nl> return ; <nl> 
static void <nl> mt76x2_phy_adjust_vga_gain ( struct mt76x2_dev * dev ) <nl> { <nl> u32 false_cca ; <nl> - u8 limit = dev -> cal . low_gain > 1 ? 4 : 16 ; <nl> + u8 limit = dev -> cal . low_gain > 0 ? 16 : 4 ; <nl>  <nl> false_cca = FIELD_GET ( MT_RX_STAT_1_CCA_ERRORS , mt76_rr ( dev , MT_RX_STAT_1 )); <nl> if ( false_cca > 800 && dev -> cal . agc_gain_adjust < limit )
static int adis_update_scan_mode_burst ( struct iio_dev * indio_dev , <nl> return - ENOMEM ; <nl>  <nl> adis -> buffer = kzalloc ( burst_length + sizeof ( u16 ), GFP_KERNEL ); <nl> - if (! adis -> buffer ) <nl> + if (! adis -> buffer ) { <nl> + kfree ( adis -> xfer ); <nl> + adis -> xfer = NULL ; <nl> return - ENOMEM ; <nl> + } <nl>  <nl> tx = adis -> buffer + burst_length ; <nl> tx [ 0 ] = ADIS_READ_REG ( adis -> burst -> reg_cmd );
static int route4_change ( struct net * net , struct sk_buff * in_skb , <nl> fp = & b -> ht [ h ]; <nl> for ( pfp = rtnl_dereference (* fp ); pfp ; <nl> fp = & pfp -> next , pfp = rtnl_dereference (* fp )) { <nl> - if ( pfp == f ) { <nl> - * fp = f -> next ; <nl> + if ( pfp == fold ) { <nl> + rcu_assign_pointer (* fp , fold -> next ); <nl> break ; <nl> } <nl> }
u16 hpi_entity_alloc_and_pack ( const enum e_entity_type type , <nl> if ( hE ) <nl> return hE ; <nl>  <nl> - HPI_DEBUG_ASSERT ( role > entity_role_null && type < LAST_ENTITY_ROLE ); <nl> + HPI_DEBUG_ASSERT ( role > entity_role_null && type < LAST_ENTITY_TYPE ); <nl>  <nl> bytes_to_copy = entity_type_to_size [ type ] * item_count ; <nl> total_size = hpi_entity_header_size (* entity ) + bytes_to_copy ;
struct gpio_desc * devm_get_gpiod_from_child ( struct device * dev , <nl> suffixes [ i ]); <nl>  <nl> desc = fwnode_get_named_gpiod ( child , prop_name ); <nl> - if (! IS_ERR ( desc ) || ( PTR_ERR ( desc ) == - EPROBE_DEFER )) <nl> + if (! IS_ERR ( desc ) || ( PTR_ERR ( desc ) != - ENOENT )) <nl> break ; <nl> } <nl> if ( IS_ERR ( desc )) {
int bnx2i_send_iscsi_nopout ( struct bnx2i_conn * bnx2i_conn , <nl> bnx2i_cmd = ( struct bnx2i_cmd *) task -> dd_data ; <nl> nopout_hdr = ( struct iscsi_nopout *) task -> hdr ; <nl> nopout_wqe = ( struct bnx2i_nop_out_request *) ep -> qp . sq_prod_qe ; <nl> + <nl> + memset ( nopout_wqe , 0x00 , sizeof ( struct bnx2i_nop_out_request )); <nl> + <nl> nopout_wqe -> op_code = nopout_hdr -> opcode ; <nl> nopout_wqe -> op_attr = ISCSI_FLAG_CMD_FINAL ; <nl> memcpy ( nopout_wqe -> lun , nopout_hdr -> lun , 8 );
static int prepare_vmcs02 ( struct kvm_vcpu * vcpu , struct vmcs12 * vmcs12 , <nl> if ( exec_control & CPU_BASED_TPR_SHADOW ) { <nl> vmcs_write64 ( VIRTUAL_APIC_PAGE_ADDR , - 1ull ); <nl> vmcs_write32 ( TPR_THRESHOLD , vmcs12 -> tpr_threshold ); <nl> + } else { <nl> +# ifdef CONFIG_X86_64 <nl> + exec_control |= CPU_BASED_CR8_LOAD_EXITING | <nl> + CPU_BASED_CR8_STORE_EXITING ; <nl> +# endif <nl> } <nl>  <nl> /*
static struct snd_soc_dai_link da8xx_evm_dai = { <nl> . stream_name = " AIC3X ", <nl> . cpu_dai_name = " davinci - mcasp . 0 ", <nl> . codec_dai_name = " tlv320aic3x - hifi ", <nl> - . codec_name = " tlv320aic3x - codec . 0 - 001a ", <nl> + . codec_name = " tlv320aic3x - codec . 1 - 0018 ", <nl> . platform_name = " davinci - pcm - audio ", <nl> . init = evm_aic3x_init , <nl> . ops = & evm_ops ,
static int sh_pfc_dt_node_to_map ( struct pinctrl_dev * pctldev , <nl> for_each_child_of_node ( np , child ) { <nl> ret = sh_pfc_dt_subnode_to_map ( pctldev , child , map , num_maps , <nl> & index ); <nl> - if ( ret < 0 ) <nl> + if ( ret < 0 ) { <nl> + of_node_put ( child ); <nl> goto done ; <nl> + } <nl> } <nl>  <nl> /* If no mapping has been found in child nodes try the config node . */
void blk_mq_wake_waiters ( struct request_queue * q ) <nl> queue_for_each_hw_ctx ( q , hctx , i ) <nl> if ( blk_mq_hw_queue_mapped ( hctx )) <nl> blk_mq_tag_wakeup_all ( hctx -> tags , true ); <nl> + <nl> + /* <nl> + * If we are called because the queue has now been marked as <nl> + * dying , we need to ensure that processes currently waiting on <nl> + * the queue are notified as well . <nl> + */ <nl> + wake_up_all (& q -> mq_freeze_wq ); <nl> } <nl>  <nl> bool blk_mq_can_queue ( struct blk_mq_hw_ctx * hctx )
void __init at91_gpio_irq_setup ( void ) <nl> irq_set_chip_data ( id , this ); <nl> irq_set_chained_handler ( id , gpio_irq_handler ); <nl> } <nl> - pr_info (" AT91 : % d gpio irqs in % d banks \ n ", irq , gpio_banks ); <nl> + pr_info (" AT91 : % d gpio irqs in % d banks \ n ", irq - gpio_to_irq ( 0 ), gpio_banks ); <nl> } <nl>  <nl> /* gpiolib support */
static int drbg_fini_sym_kernel ( struct drbg_state * drbg ) <nl> drbg -> ctr_handle = NULL ; <nl>  <nl> if ( drbg -> ctr_req ) <nl> - skcipher_request_free ( drbg -> ctr_req );; <nl> + skcipher_request_free ( drbg -> ctr_req ); <nl> drbg -> ctr_req = NULL ; <nl>  <nl> kfree ( drbg -> ctr_null_value_buf );
static int ipmmu_probe ( struct platform_device * pdev ) <nl> spin_lock_init (& mmu -> lock ); <nl> bitmap_zero ( mmu -> ctx , IPMMU_CTX_MAX ); <nl> mmu -> features = of_device_get_match_data (& pdev -> dev ); <nl> + dma_set_mask_and_coherent (& pdev -> dev , DMA_BIT_MASK ( 40 )); <nl>  <nl> /* Map I / O memory and request IRQ . */ <nl> res = platform_get_resource ( pdev , IORESOURCE_MEM , 0 );
static int special_clk_ctl_put ( struct snd_kcontrol * kctl , <nl> struct special_params * params = bebob -> maudio_special_quirk ; <nl> int err , id ; <nl>  <nl> - mutex_lock (& bebob -> mutex ); <nl> - <nl> id = uval -> value . enumerated . item [ 0 ]; <nl> if ( id >= ARRAY_SIZE ( special_clk_labels )) <nl> return 0 ; <nl>  <nl> + mutex_lock (& bebob -> mutex ); <nl> + <nl> err = avc_maudio_set_special_clk ( bebob , id , <nl> params -> dig_in_fmt , <nl> params -> dig_out_fmt ,
static ssize_t dm_dp_aux_transfer ( struct drm_dp_aux * aux , <nl> enum ddc_result res ; <nl> ssize_t read_bytes ; <nl>  <nl> + if ( WARN_ON ( msg -> size > 16 )) <nl> + return - E2BIG ; <nl> + <nl> switch ( msg -> request & ~ DP_AUX_I2C_MOT ) { <nl> case DP_AUX_NATIVE_READ : <nl> read_bytes = dal_ddc_service_read_dpcd_data (
static int falcon_mtd_probe ( struct efx_nic * efx ) <nl>  <nl> /* Allocate space for maximum number of partitions */ <nl> parts = kcalloc ( 2 , sizeof (* parts ), GFP_KERNEL ); <nl> + if (! parts ) <nl> + return - ENOMEM ; <nl> n_parts = 0 ; <nl>  <nl> spi = & nic_data -> spi_flash ;
static int mt9t112_init_pll ( const struct i2c_client * client ) <nl> * I2C Master Clock Divider <nl> */ <nl> mt9t112_reg_write ( ret , client , 0x0014 , 0x3046 ); <nl> + mt9t112_reg_write ( ret , client , 0x0016 , 0x0400 ); /* JPEG initialization workaround */ <nl> mt9t112_reg_write ( ret , client , 0x0022 , 0x0190 ); <nl> mt9t112_reg_write ( ret , client , 0x3B84 , 0x0212 ); <nl> 
static int __devinit bnx2x_init_one ( struct pci_dev * pdev , <nl> bp = netdev_priv ( dev ); <nl> bp -> msglevel = debug ; <nl>  <nl> + pci_set_drvdata ( pdev , dev ); <nl> + <nl> rc = bnx2x_init_dev ( pdev , dev ); <nl> if ( rc < 0 ) { <nl> free_netdev ( dev ); <nl> return rc ; <nl> } <nl>  <nl> - pci_set_drvdata ( pdev , dev ); <nl> - <nl> rc = bnx2x_init_bp ( bp ); <nl> if ( rc ) <nl> goto init_one_exit ;
struct block_device * bdget ( dev_t dev ) <nl>  <nl> if ( inode -> i_state & I_NEW ) { <nl> bdev -> bd_contains = NULL ; <nl> + bdev -> bd_super = NULL ; <nl> bdev -> bd_inode = inode ; <nl> bdev -> bd_block_size = ( 1 << inode -> i_blkbits ); <nl> bdev -> bd_part_count = 0 ;
static const char * nand_usdhc_bus_sel [] = { " osc ", " pll_sys_pfd2_270m_clk ", <nl>  <nl> static const char * ahb_channel_sel [] = { " osc ", " pll_sys_pfd2_270m_clk ", <nl> " pll_dram_533m_clk ", " pll_sys_pfd0_392m_clk ", <nl> - " pll_enet_125m_clk ", " pll_usb_main_clk ", " pll_audio_post_div ", <nl> + " pll_enet_250m_clk ", " pll_usb_main_clk ", " pll_audio_post_div ", <nl> " pll_video_post_div ", }; <nl>  <nl> static const char * dram_phym_sel [] = { " pll_dram_main_clk ",
int ip6_forward ( struct sk_buff * skb ) <nl> if ( mtu < IPV6_MIN_MTU ) <nl> mtu = IPV6_MIN_MTU ; <nl>  <nl> - if ( skb -> len > mtu ) { <nl> + if ( skb -> len > mtu && ! skb_is_gso ( skb )) { <nl> /* Again , force OUTPUT device used as source address */ <nl> skb -> dev = dst -> dev ; <nl> icmpv6_send ( skb , ICMPV6_PKT_TOOBIG , 0 , mtu );
static int __rds_rdma_map ( struct rds_sock * rs , struct rds_get_mr_args * args , <nl> long i ; <nl> int ret ; <nl>  <nl> - if ( rs -> rs_bound_addr == 0 ) { <nl> + if ( rs -> rs_bound_addr == 0 || ! rs -> rs_transport ) { <nl> ret = - ENOTCONN ; /* XXX not a great errno */ <nl> goto out ; <nl> }
int tcp_disconnect ( struct sock * sk , int flags ) <nl> tcp_set_ca_state ( sk , TCP_CA_Open ); <nl> tcp_clear_retrans ( tp ); <nl> inet_csk_delack_init ( sk ); <nl> + /* Initialize rcv_mss to TCP_MIN_MSS to avoid division by 0 <nl> + * issue in __tcp_select_window () <nl> + */ <nl> + icsk -> icsk_ack . rcv_mss = TCP_MIN_MSS ; <nl> tcp_init_send_head ( sk ); <nl> memset (& tp -> rx_opt , 0 , sizeof ( tp -> rx_opt )); <nl> __sk_dst_reset ( sk );
unsigned long hugetlb_get_unmapped_area ( struct file * file , unsigned long addr , <nl> { <nl> struct hstate * hstate = hstate_file ( file ); <nl> int mmu_psize = shift_to_mmu_psize ( huge_page_shift ( hstate )); <nl> + <nl> + if (! mmu_huge_psizes [ mmu_psize ]) <nl> + return - EINVAL ; <nl> return slice_get_unmapped_area ( addr , len , flags , mmu_psize , 1 , 0 ); <nl> } <nl> 
static struct rpc_task * nfs4_do_unlck ( struct file_lock * fl , <nl> { <nl> struct nfs4_unlockdata * data ; <nl>  <nl> + /* Ensure this is an unlock - when canceling a lock , the <nl> + * canceled lock is passed in , and it won ' t be an unlock . <nl> + */ <nl> + fl -> fl_type = F_UNLCK ; <nl> + <nl> data = nfs4_alloc_unlockdata ( fl , ctx , lsp , seqid ); <nl> if ( data == NULL ) { <nl> nfs_free_seqid ( seqid );
int bpf_jit_enable __read_mostly ; <nl>  <nl> static void bpf_jit_fill_ill_insns ( void * area , unsigned int size ) <nl> { <nl> - int * p = area ; <nl> - <nl> - /* Fill whole space with trap instructions */ <nl> - while ( p < ( int *)(( char *) area + size )) <nl> - * p ++ = BREAKPOINT_INSTRUCTION ; <nl> + memset32 ( area , BREAKPOINT_INSTRUCTION , size / 4 ); <nl> } <nl>  <nl> static inline void bpf_flush_icache ( void * start , void * end )
vhost_user_check_and_alloc_queue_pair ( struct virtio_net * dev , <nl> case VHOST_USER_SET_VRING_ADDR : <nl> vring_idx = ctx -> msg . payload . addr . index ; <nl> break ; <nl> + case VHOST_USER_SET_INFLIGHT_FD : <nl> + vring_idx = ctx -> msg . payload . inflight . num_queues - 1 ; <nl> + break ; <nl> default : <nl> return 0 ; <nl> }
gnutls_ocsp_resp_check_crt ( gnutls_ocsp_resp_t resp , <nl> gnutls_assert (); <nl> goto cleanup ; <nl> } <nl> + cserial . size = t ; <nl>  <nl> if ( rserial . size != cserial . size <nl> || memcmp ( cserial . data , rserial . data , rserial . size ) != 0 ) {
gif_internal_decode_frame ( gif_animation * gif , <nl> unsigned int x , y , decode_y , burst_bytes ; <nl> register unsigned char colour ; <nl>  <nl> + /* If the GIF has no frame data , frame holders will not be allocated in <nl> + * gif_initialise () */ <nl> + if ( gif -> frames == NULL ) { <nl> + return GIF_INSUFFICIENT_DATA ; <nl> + } <nl> + <nl> /* Ensure this frame is supposed to be decoded */ <nl> if ( gif -> frames [ frame ]. display == false ) { <nl> return GIF_OK ;
static bool env_var_checked_p ; <nl>  <nl> # define FIELD_2DD_VECTOR ( nam , size , dxf ) \ <nl> OVERFLOW_CHECK ( nam , _obj -> size ) \ <nl> - FIELD_2RD ( nam [ 0 ], dxf ); \ <nl> + if ( _obj -> size ) \ <nl> + FIELD_2RD ( nam [ 0 ], dxf ); \ <nl> for ( vcount = 1 ; vcount < ( BITCODE_BL ) _obj -> size ; vcount ++) \ <nl> { \ <nl> FIELD_2DD ( nam [ vcount ], FIELD_VALUE ( nam [ vcount - 1 ]. x ), \
int update_timestamp ( const char * key , const struct efi_time * timestamp , char * la <nl> static uint64_t unpack_timestamp ( const struct efi_time * timestamp ) <nl> { <nl> uint64_t val = 0 ; <nl> - uint16_t year = le32_to_cpu ( timestamp -> year ); <nl> + uint16_t year = le16_to_cpu ( timestamp -> year ); <nl>  <nl> /* pad1 , nanosecond , timezone , daylight and pad2 are meant to be zero */ <nl> val |= (( uint64_t ) timestamp -> pad1 & 0xFF ) << 0 ;
static void DetectRunCleanup ( DetectEngineThreadCtx * det_ctx , <nl>  <nl> if ( pflow != NULL ) { <nl> /* update inspected tracker for raw reassembly */ <nl> - if ( p -> proto == IPPROTO_TCP && pflow -> protoctx != NULL ) { <nl> + if ( p -> proto == IPPROTO_TCP && pflow -> protoctx != NULL && <nl> + ( p -> flags & PKT_STREAM_EST )) <nl> + { <nl> StreamReassembleRawUpdateProgress ( pflow -> protoctx , p , <nl> det_ctx -> raw_stream_progress ); <nl> 
parse_again : <nl>  <nl> case ':': <nl> switch ( state ){ <nl> - case F_HOST : <nl> case F_IP6HOST : <nl> state = P_IP6HOST ; <nl> break ;
otError Commissioner :: GeneratePskc ( const char * aPassPhrase , <nl> uint16_t saltLen = 0 ; <nl>  <nl> VerifyOrExit (( strlen ( aPassPhrase ) >= OT_COMMISSIONING_PASSPHRASE_MIN_SIZE ) && <nl> - ( strlen ( aPassPhrase ) <= OT_COMMISSIONING_PASSPHRASE_MAX_SIZE ), <nl> + ( strlen ( aPassPhrase ) <= OT_COMMISSIONING_PASSPHRASE_MAX_SIZE ) && <nl> + ( strlen ( aNetworkName ) <= OT_NETWORK_NAME_MAX_SIZE ), <nl> error = OT_ERROR_INVALID_ARGS ); <nl>  <nl> memset ( salt , 0 , sizeof ( salt ));
WORD32 ih264d_mark_err_slice_skip ( dec_struct_t * ps_dec , <nl> ih264d_err_pic_dispbuf_mgr ( ps_dec ); <nl> return 0 ; <nl> } <nl> - <nl> + ps_dec -> ps_dpb_cmds -> u1_long_term_reference_flag = 0 ; <nl> if ( prev_slice_err == 1 ) <nl> { <nl> /* first slice - missing / header corruption */
status_t BnGraphicBufferProducer :: onTransact ( <nl> QueueBufferOutput * const output = <nl> reinterpret_cast < QueueBufferOutput *>( <nl> reply -> writeInplace ( sizeof ( QueueBufferOutput ))); <nl> + memset ( output , 0 , sizeof ( QueueBufferOutput )); <nl> status_t result = queueBuffer ( buf , input , output ); <nl> reply -> writeInt32 ( result ); <nl> return NO_ERROR ;
static bool MR_primality_test ( UnsignedBigInteger n , const Vector < UnsignedBigInte <nl> return n == 2 ; <nl> } <nl>  <nl> - for ( auto a : tests ) { <nl> + for ( auto & a : tests ) { <nl> // Technically : ASSERT ( 2 <= a && a <= n - 2 ) <nl> ASSERT ( a < n ); <nl> auto x = ModularPower ( a , d , n );
REGISTER_OP (" Dequantize ") <nl> if (! s . ok () && s . code () != error :: NOT_FOUND ) { <nl> return s ; <nl> } <nl> + if ( axis < - 1 ) { <nl> + return errors :: InvalidArgument (" axis should be at least - 1 , got ", <nl> + axis ); <nl> + } <nl> const int minmax_rank = ( axis == - 1 ) ? 0 : 1 ; <nl> TF_RETURN_IF_ERROR ( shape_inference :: UnchangedShape ( c )); <nl> ShapeHandle minmax ;
TfLiteStatus Eval ( TfLiteContext * context , TfLiteNode * node ) { <nl> TF_LITE_ENSURE_OK ( context , <nl> GetOutputSafe ( context , node , kOutputTensor , & output )); <nl>  <nl> + // Prevent division by 0 in the helper <nl> + TF_LITE_ENSURE ( context , NumElements ( params ) > 0 ); <nl> + <nl> switch ( indices -> type ) { <nl> case kTfLiteInt32 : <nl> return EvalGatherNd < int32_t >( context , params , indices , output );
inline void BinaryBroadcastFiveFold ( const ArithmeticParams & unswitched_params , <nl> // We have broadcast y2 * y3 * y4 of input2 data y1 times , and now move on . <nl> input2_data_reset = input2_data_ptr ; <nl> } <nl> - } else { <nl> + } else if ( input1_data_ptr != nullptr ) { <nl> // Special case of y4 == 1 , in which the innermost loop is a single <nl> // element and can be combined with the next ( y3 ) as an inner broadcast . <nl> //
class QuantizeAndDequantizeV2Op : public OpKernel { <nl>  <nl> void Compute ( OpKernelContext * ctx ) override { <nl> const Tensor & input = ctx -> input ( 0 ); <nl> + OP_REQUIRES ( <nl> + ctx , axis_ >= - 1 , <nl> + errors :: InvalidArgument (" Axis must be at least - 1 . Found ", axis_ )); <nl> OP_REQUIRES ( <nl> ctx , ( axis_ == - 1 || axis_ < input . shape (). dims ()), <nl> errors :: InvalidArgument (" Shape must be at least rank ", axis_ + 1 ,
Status ImportGenericFunction ( <nl> // Import the function attributes with a ` tf .` prefix to match the current <nl> // infrastructure expectations . <nl> for ( const auto & namedAttr : func . attr ()) { <nl> + if ( namedAttr . first . empty ()) <nl> + return InvalidArgument (" Invalid function attribute name "); <nl> const std :: string & name = " tf ." + namedAttr . first ; <nl> const AttrValue & tf_attr = namedAttr . second ; <nl> TF_ASSIGN_OR_RETURN ( Attribute attr ,
namespace drachtio { <nl> if ( complete ) { <nl> m_os . flush () ; <nl> m_sipMessage = m_os . str () ; <nl> - m_sipMessage . resize ( m_sipMessage . length () - 1 ) ; <nl> + if ( m_sipMessage . length () > 1 ) m_sipMessage . resize ( m_sipMessage . length () - 1 ) ; <nl> boost :: replace_all ( m_sipMessage , "\ n ", DR_CRLF ); <nl> } <nl> else if ( 0 == strcmp ( szLine , "\ n ") ) {
void hexdump ( msg_info msg_info , const char * mem , unsigned int len ) <nl> } <nl> str [ c ++] = '\ n '; <nl> str [ c ++] = 0 ; <nl> - print_message ( msg_info , str ); <nl> + print_message ( msg_info , "% s ", str ); <nl> c = 0 ; <nl> } <nl> }
ChildProcessTerminationInfo ChildProcessLauncherHelper :: GetTerminationInfo ( <nl> if (! java_peer_avaiable_on_client_thread_ ) <nl> return info ; <nl>  <nl> - Java_ChildProcessLauncherHelperImpl_getTerminationInfo ( <nl> + Java_ChildProcessLauncherHelperImpl_getTerminationInfoAndStop ( <nl> AttachCurrentThread (), java_peer_ , reinterpret_cast < intptr_t >(& info )); <nl>  <nl> base :: android :: ApplicationState app_state =
xmlParseAttValueComplex ( xmlParserCtxtPtr ctxt , int * attlen , int normalize ) { <nl> c = CUR_CHAR ( l ); <nl> } <nl> if (( in_space ) && ( normalize )) { <nl> - while ( buf [ len - 1 ] == 0x20 ) len --; <nl> + while (( len > 0 ) && ( buf [ len - 1 ] == 0x20 )) len --; <nl> } <nl> buf [ len ] = 0 ; <nl> if ( RAW == '<') {
WebContents * DevToolsWindow :: OpenURLFromTab ( <nl> DCHECK ( source == main_web_contents_ ); <nl> if (! params . url . SchemeIs ( content :: kChromeDevToolsScheme )) { <nl> WebContents * inspected_web_contents = GetInspectedWebContents (); <nl> - return inspected_web_contents ? <nl> - inspected_web_contents -> OpenURL ( params ) : NULL ; <nl> + if (! inspected_web_contents ) <nl> + return nullptr ; <nl> + content :: OpenURLParams modified = params ; <nl> + modified . referrer = content :: Referrer (); <nl> + return inspected_web_contents -> OpenURL ( modified ); <nl> } <nl> bindings_ -> Reload (); <nl> return main_web_contents_ ;
class PowerPopupView : public views :: Label { <nl> public : <nl> PowerPopupView () { <nl> SetHorizontalAlignment ( ALIGN_RIGHT ); <nl> + SetMultiLine ( true ); <nl> UpdateText (); <nl> } <nl> 
